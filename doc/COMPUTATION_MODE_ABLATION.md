# Computation Mode Ablation Study
# è®¡ç®—æ¨¡å¼æ¶ˆèå®éªŒ

## ğŸ“‹ Overview / æ¦‚è¿°

This document describes the **computation mode ablation study** that compares two different computation approaches in the causal reasoning framework:

æœ¬æ–‡æ¡£æè¿°äº†**è®¡ç®—æ¨¡å¼æ¶ˆèå®éªŒ**ï¼Œæ¯”è¾ƒå› æœæ¨ç†æ¡†æ¶ä¸­çš„ä¸¤ç§ä¸åŒè®¡ç®—æ–¹æ³•ï¼š

1. **Symbolic Execution** (é»˜è®¤æ–¹å¼ / Default)
   - Code Generation + Python Sandbox Execution
   - ä»£ç ç”Ÿæˆ + Pythonæ²™ç®±æ‰§è¡Œ

2. **LLM-based Computation** (æ¶ˆèå®éªŒ / Ablation Study)
   - LLM computes based on causal scaffold
   - LLMåŸºäºå› æœè„šæ‰‹æ¶è®¡ç®—

---

## ğŸ¯ Purpose / ç›®çš„

### Research Question / ç ”ç©¶é—®é¢˜

**Is symbolic execution necessary, or can LLM computation based on causal scaffolds achieve comparable accuracy?**

**ç¬¦å·æ‰§è¡Œæ˜¯å¦å¿…è¦ï¼Œæˆ–è€…åŸºäºå› æœè„šæ‰‹æ¶çš„LLMè®¡ç®—èƒ½å¦è¾¾åˆ°ç›¸å½“çš„å‡†ç¡®æ€§ï¼Ÿ**

### What This Tests / æµ‹è¯•å†…å®¹

This ablation study tests:
æ­¤æ¶ˆèå®éªŒæµ‹è¯•ï¼š

âœ… **Keeps the same** / **ä¿æŒä¸å˜**:
- Knowledge Retrieval (RAG) / çŸ¥è¯†æ£€ç´¢
- Causal Scaffolding / å› æœè„šæ‰‹æ¶ç”Ÿæˆ
- Synthesis & Validation / åˆæˆä¸éªŒè¯

ğŸ”„ **Changes** / **å˜åŒ–**:
- **Symbolic Mode**: Code Generation â†’ Symbolic Execution
  - **ç¬¦å·æ¨¡å¼**: ä»£ç ç”Ÿæˆ â†’ ç¬¦å·æ‰§è¡Œ
- **LLM Mode**: LLM Computation (based on scaffold)
  - **LLMæ¨¡å¼**: LLMè®¡ç®—ï¼ˆåŸºäºè„šæ‰‹æ¶ï¼‰

---

## ğŸ—ï¸ Architecture / æ¶æ„

### Full Pipeline Comparison / å®Œæ•´æµç¨‹å¯¹æ¯”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SYMBOLIC MODE (Default)                      â”‚
â”‚                    ç¬¦å·æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. Knowledge Retrieval       â†’  Retrieve relevant rules       â”‚
â”‚     çŸ¥è¯†æ£€ç´¢                       æ£€ç´¢ç›¸å…³è§„åˆ™                   â”‚
â”‚                                                                 â”‚
â”‚  2. Causal Scaffolding        â†’  Generate causal graph (JSON)  â”‚
â”‚     å› æœè„šæ‰‹æ¶                     ç”Ÿæˆå› æœå›¾ï¼ˆJSONï¼‰             â”‚
â”‚                                                                 â”‚
â”‚  3. Code Generation           â†’  Convert scaffold to Python    â”‚
â”‚     ä»£ç ç”Ÿæˆ                       å°†è„šæ‰‹æ¶è½¬æ¢ä¸ºPython            â”‚
â”‚                                                                 â”‚
â”‚  4. Symbolic Execution        â†’  Execute code in sandbox       â”‚
â”‚     ç¬¦å·æ‰§è¡Œ                       åœ¨æ²™ç®±ä¸­æ‰§è¡Œä»£ç                 â”‚
â”‚                                                                 â”‚
â”‚  5. Synthesis & Validation    â†’  Generate explanation          â”‚
â”‚     åˆæˆä¸éªŒè¯                     ç”Ÿæˆè§£é‡Š                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LLM MODE (Ablation)                          â”‚
â”‚                    LLMæ¨¡å¼ï¼ˆæ¶ˆèå®éªŒï¼‰                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. Knowledge Retrieval       â†’  Retrieve relevant rules       â”‚
â”‚     çŸ¥è¯†æ£€ç´¢                       æ£€ç´¢ç›¸å…³è§„åˆ™                   â”‚
â”‚                                                                 â”‚
â”‚  2. Causal Scaffolding        â†’  Generate causal graph (JSON)  â”‚
â”‚     å› æœè„šæ‰‹æ¶                     ç”Ÿæˆå› æœå›¾ï¼ˆJSONï¼‰             â”‚
â”‚                                                                 â”‚
â”‚  3. LLM Computation           â†’  LLM computes based on scaffoldâ”‚
â”‚     LLMè®¡ç®—                        LLMåŸºäºè„šæ‰‹æ¶è®¡ç®—              â”‚
â”‚                                                                 â”‚
â”‚  4. Synthesis & Validation    â†’  Generate explanation          â”‚
â”‚     åˆæˆä¸éªŒè¯                     ç”Ÿæˆè§£é‡Š                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Usage / ä½¿ç”¨æ–¹æ³•

### 1. Using main.py Directly / ç›´æ¥ä½¿ç”¨main.py

```python
from main import CausalReasoningEngine

# Symbolic Execution Mode (Default)
# ç¬¦å·æ‰§è¡Œæ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
engine_symbolic = CausalReasoningEngine(
    computation_mode="symbolic"  # Default
)

# LLM Computation Mode (Ablation)
# LLMè®¡ç®—æ¨¡å¼ï¼ˆæ¶ˆèå®éªŒï¼‰
engine_llm = CausalReasoningEngine(
    computation_mode="llm"  # Ablation
)

# Solve problem
# æ±‚è§£é—®é¢˜
problem = "What is 2 + 3 * 4?"
result_symbolic = engine_symbolic.solve_problem(problem)
result_llm = engine_llm.solve_problem(problem)

print(f"Symbolic: {result_symbolic['final_answer']}")
print(f"LLM: {result_llm['final_answer']}")
```

### 2. Using Evaluation Framework / ä½¿ç”¨è¯„ä¼°æ¡†æ¶

```bash
# Run ablation studies including NO_SYMBOLIC_EXECUTION
# è¿è¡Œæ¶ˆèå®éªŒï¼ŒåŒ…æ‹¬NO_SYMBOLIC_EXECUTION
python evaluate_framework.py \
    --dataset gsm8k \
    --limit 20 \
    --methods ablations
```

This will run:
è¿™å°†è¿è¡Œï¼š
- `NO_RETRIEVER` - No knowledge retrieval / æ— çŸ¥è¯†æ£€ç´¢
- `NO_AI_RETRIEVER` - No AI-generated rules / æ— AIç”Ÿæˆè§„åˆ™
- **`NO_SYMBOLIC_EXECUTION`** - **LLM computation instead of symbolic execution** / **LLMè®¡ç®—è€Œéç¬¦å·æ‰§è¡Œ**

### 3. Direct Comparison Test / ç›´æ¥å¯¹æ¯”æµ‹è¯•

```bash
# Run comparison test script
# è¿è¡Œå¯¹æ¯”æµ‹è¯•è„šæœ¬
python test_computation_modes.py
```

This script will:
æ­¤è„šæœ¬å°†ï¼š
- Run the same problem with both modes / ä½¿ç”¨ä¸¤ç§æ¨¡å¼è¿è¡ŒåŒä¸€é—®é¢˜
- Compare results and execution time / æ¯”è¾ƒç»“æœå’Œæ‰§è¡Œæ—¶é—´
- Show which mode is more accurate / æ˜¾ç¤ºå“ªç§æ¨¡å¼æ›´å‡†ç¡®

---

## ğŸ“Š Output Examples / è¾“å‡ºç¤ºä¾‹

### Symbolic Mode Output / ç¬¦å·æ¨¡å¼è¾“å‡º

```
--- STAGE 3: CODE GENERATION (Symbolic Mode) ---
---  3: ä»£ç ç”Ÿæˆï¼ˆç¬¦å·æ‰§è¡Œæ¨¡å¼ï¼‰---
âœ“ Code generated successfully

--- STAGE 3.5: SANDBOX EXECUTION ---
---  3.5: æ²™ç®±æ‰§è¡Œ ---
âœ“ Code executed successfully
Final Answer: 14
```

### LLM Mode Output / LLMæ¨¡å¼è¾“å‡º

```
--- STAGE 3: LLM-BASED COMPUTATION (LLM Mode) ---
---  3: åŸºäºLLMçš„è®¡ç®—ï¼ˆLLMæ¨¡å¼ï¼‰---
âœ“ LLM response received
âœ“ Final answer computed: 14
```

---

## ğŸ“ˆ Evaluation Metrics / è¯„ä¼°æŒ‡æ ‡

When comparing the two modes, consider:
æ¯”è¾ƒä¸¤ç§æ¨¡å¼æ—¶ï¼Œè€ƒè™‘ï¼š

1. **Accuracy / å‡†ç¡®æ€§**
   - How often does each mode produce the correct answer?
   - æ¯ç§æ¨¡å¼å¤šä¹…äº§ç”Ÿä¸€æ¬¡æ­£ç¡®ç­”æ¡ˆï¼Ÿ

2. **Consistency / ä¸€è‡´æ€§**
   - Do both modes produce the same answer?
   - ä¸¤ç§æ¨¡å¼æ˜¯å¦äº§ç”Ÿç›¸åŒç­”æ¡ˆï¼Ÿ

3. **Execution Time / æ‰§è¡Œæ—¶é—´**
   - Which mode is faster?
   - å“ªç§æ¨¡å¼æ›´å¿«ï¼Ÿ

4. **Error Rate / é”™è¯¯ç‡**
   - Which mode fails more often?
   - å“ªç§æ¨¡å¼æ›´å®¹æ˜“å¤±è´¥ï¼Ÿ

5. **Error Types / é”™è¯¯ç±»å‹**
   - What kinds of errors does each mode encounter?
   - æ¯ç§æ¨¡å¼é‡åˆ°ä»€ä¹ˆç±»å‹çš„é”™è¯¯ï¼Ÿ

---

## ğŸ” Expected Results / é¢„æœŸç»“æœ

### Hypothesis / å‡è®¾

**Symbolic Execution** (ç¬¦å·æ‰§è¡Œ) should be:
- More accurate for complex calculations / å¯¹å¤æ‚è®¡ç®—æ›´å‡†ç¡®
- More reliable for multi-step problems / å¯¹å¤šæ­¥éª¤é—®é¢˜æ›´å¯é 
- Deterministic and reproducible / ç¡®å®šæ€§å’Œå¯é‡ç°æ€§

**LLM Computation** (LLMè®¡ç®—) might be:
- Faster (no code generation step) / æ›´å¿«ï¼ˆæ— ä»£ç ç”Ÿæˆæ­¥éª¤ï¼‰
- More flexible for edge cases / å¯¹è¾¹ç•Œæƒ…å†µæ›´çµæ´»
- Less reliable for numerical precision / æ•°å€¼ç²¾åº¦å¯èƒ½è¾ƒä½

---

## ğŸ“ Implementation Details / å®ç°ç»†èŠ‚

### New Components / æ–°ç»„ä»¶

1. **`engine/llm_computer.py`**
   - `LLMComputer` class
   - Takes causal scaffold as input
   - Generates structured prompt for LLM
   - Extracts final answer from LLM response

2. **`main.py` - Updated**
   - Added `computation_mode` parameter
   - Conditional logic to choose computation path
   - Both paths start from causal scaffold

3. **`evaluate_framework.py` - Updated**
   - `_run_without_symbolic_execution()` now uses `computation_mode='llm'`
   - Proper ablation study (not just direct LLM call)

### Key Code / å…³é”®ä»£ç 

```python
# In main.py solve_problem()
if self.computation_mode == "symbolic":
    # Original: Code Generation + Execution
    generated_code = self.code_generator.generate_code(causal_plan)
    execution_result = self.sandbox_executor.execute_code(generated_code)
    final_answer = execution_result['result']

elif self.computation_mode == "llm":
    # Ablation: LLM Computation
    computation_result = self.llm_computer.compute_from_scaffold(
        causal_scaffold=causal_plan,
        problem_text=problem_text
    )
    final_answer = computation_result['result']
```

---

## ğŸ§ª Testing / æµ‹è¯•

### Quick Test / å¿«é€Ÿæµ‹è¯•

```bash
# Test both modes on a single problem
# åœ¨å•ä¸ªé—®é¢˜ä¸Šæµ‹è¯•ä¸¤ç§æ¨¡å¼
python test_computation_modes.py
```

### Full Evaluation / å®Œæ•´è¯„ä¼°

```bash
# Evaluate on GSM8K dataset
# åœ¨GSM8Kæ•°æ®é›†ä¸Šè¯„ä¼°
python evaluate_framework.py \
    --dataset gsm8k \
    --limit 50 \
    --methods ablations \
    --verbose
```

### Batch Evaluation / æ‰¹é‡è¯„ä¼°

```bash
# Use batch evaluator for concurrent processing
# ä½¿ç”¨æ‰¹é‡è¯„ä¼°å™¨è¿›è¡Œå¹¶å‘å¤„ç†
python batch_evaluator.py \
    --dataset gsm8k \
    --limit 100 \
    --methods ablations \
    --max-workers 4
```

---

## ğŸ“Š Results Analysis / ç»“æœåˆ†æ

After running evaluations, compare:
è¿è¡Œè¯„ä¼°åï¼Œæ¯”è¾ƒï¼š

```python
# Example results comparison
# ç¤ºä¾‹ç»“æœæ¯”è¾ƒ

FULL_FRAMEWORK (Symbolic):
  Accuracy: 85.0% (17/20)
  Avg Time: 5.2s per problem

NO_SYMBOLIC_EXECUTION (LLM):
  Accuracy: 78.0% (16/20)
  Avg Time: 3.8s per problem
```

### Analysis Questions / åˆ†æé—®é¢˜

1. Is the accuracy difference significant? / å‡†ç¡®æ€§å·®å¼‚æ˜¯å¦æ˜¾è‘—ï¼Ÿ
2. Is the time savings worth the accuracy loss? / æ—¶é—´èŠ‚çœæ˜¯å¦å€¼å¾—å‡†ç¡®æ€§æŸå¤±ï¼Ÿ
3. For which problem types does LLM mode fail? / LLMæ¨¡å¼åœ¨å“ªäº›é—®é¢˜ç±»å‹ä¸Šå¤±è´¥ï¼Ÿ
4. Can the LLM prompt be improved? / LLMæç¤ºèƒ½å¦æ”¹è¿›ï¼Ÿ

---

## ğŸ¯ Recommendations / å»ºè®®

### When to Use Symbolic Mode / ä½•æ—¶ä½¿ç”¨ç¬¦å·æ¨¡å¼

âœ… **Use Symbolic Execution when** / **åœ¨ä»¥ä¸‹æƒ…å†µä½¿ç”¨ç¬¦å·æ‰§è¡Œ**:
- High numerical precision is required / éœ€è¦é«˜æ•°å€¼ç²¾åº¦
- Multi-step calculations are involved / æ¶‰åŠå¤šæ­¥è®¡ç®—
- Reproducibility is critical / å¯é‡ç°æ€§è‡³å…³é‡è¦
- Problem involves complex formulas / é—®é¢˜æ¶‰åŠå¤æ‚å…¬å¼

### When to Use LLM Mode / ä½•æ—¶ä½¿ç”¨LLMæ¨¡å¼

âœ… **Use LLM Computation when** / **åœ¨ä»¥ä¸‹æƒ…å†µä½¿ç”¨LLMè®¡ç®—**:
- Speed is more important than precision / é€Ÿåº¦æ¯”ç²¾åº¦æ›´é‡è¦
- Problems are relatively simple / é—®é¢˜ç›¸å¯¹ç®€å•
- Code generation frequently fails / ä»£ç ç”Ÿæˆç»å¸¸å¤±è´¥
- For research/ablation purposes / ç”¨äºç ”ç©¶/æ¶ˆèç›®çš„

---

## ğŸ› Known Issues / å·²çŸ¥é—®é¢˜

### LLM Computation Limitations / LLMè®¡ç®—é™åˆ¶

1. **Numerical Precision** / **æ•°å€¼ç²¾åº¦**
   - LLM may round numbers incorrectly
   - LLMå¯èƒ½é”™è¯¯åœ°å››èˆäº”å…¥æ•°å­—

2. **Complex Calculations** / **å¤æ‚è®¡ç®—**
   - May struggle with multi-step arithmetic
   - å¯èƒ½éš¾ä»¥å¤„ç†å¤šæ­¥éª¤ç®—æœ¯

3. **Answer Extraction** / **ç­”æ¡ˆæå–**
   - Final answer extraction may fail if LLM format is unexpected
   - å¦‚æœLLMæ ¼å¼å‡ºä¹æ„æ–™ï¼Œæœ€ç»ˆç­”æ¡ˆæå–å¯èƒ½å¤±è´¥

---

## ğŸ“š Related Documentation / ç›¸å…³æ–‡æ¡£

- **Main Documentation**: `ENGINE_FRAMEWORK_DOCUMENTATION.md`
- **Evaluation Guide**: `doc/EVALUATION_GUIDE.md`
- **Retry Mechanism**: `RETRY_MECHANISM_GUIDE.md`
- **Batch Evaluation**: `doc/BATCH_EVALUATION_GUIDE.md`

---

## âœ… Checklist / æ£€æŸ¥æ¸…å•

- [x] Created `LLMComputer` class in `engine/llm_computer.py`
- [x] Added `computation_mode` parameter to `main.py`
- [x] Updated `NO_SYMBOLIC_EXECUTION` ablation in `evaluate_framework.py`
- [x] Created `test_computation_modes.py` for comparison testing
- [x] Created this documentation

---

## ğŸš€ Quick Start / å¿«é€Ÿå¼€å§‹

```bash
# 1. Test the comparison script
# 1. æµ‹è¯•å¯¹æ¯”è„šæœ¬
python test_computation_modes.py

# 2. Run ablation study
# 2. è¿è¡Œæ¶ˆèå®éªŒ
python evaluate_framework.py --dataset gsm8k --limit 20 --methods ablations

# 3. Analyze results
# 3. åˆ†æç»“æœ
# Check evaluation_results/ directory for JSON output
# æ£€æŸ¥ evaluation_results/ ç›®å½•ä¸­çš„ JSON è¾“å‡º
```

---

**Last Updated**: 2025-01-15

äº«å—æ¶ˆèå®éªŒï¼ğŸ‰ / Enjoy the ablation study! ğŸ‰
