# å®Œæ•´è¯„ä¼°æŒ‡å— (Complete Evaluation Guide)

æœ¬æŒ‡å—æ•™æ‚¨å¦‚ä½•ä½¿ç”¨è¯„ä¼°æ¡†æ¶åœ¨å„ç§æ•°æ®é›†ä¸Šæµ‹è¯•æ‚¨çš„å› æœæ¨ç†æ¡†æ¶å’ŒåŸºçº¿æ–¹æ³•ã€‚

---

## ğŸ“š ç›®å½• (Table of Contents)

1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [æ”¯æŒçš„æ•°æ®é›†](#æ”¯æŒçš„æ•°æ®é›†)
3. [æ”¯æŒçš„è¯„ä¼°æ–¹æ³•](#æ”¯æŒçš„è¯„ä¼°æ–¹æ³•)
4. [åŸºæœ¬ä½¿ç”¨](#åŸºæœ¬ä½¿ç”¨)
5. [é«˜çº§ä½¿ç”¨](#é«˜çº§ä½¿ç”¨)
6. [ç»“æœåˆ†æ](#ç»“æœåˆ†æ)
7. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
8. [å®Œæ•´ç¤ºä¾‹](#å®Œæ•´ç¤ºä¾‹)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æœ€ç®€å•çš„è¯„ä¼°å‘½ä»¤

```bash
# åœ¨ GSM8K ä¸Šè¯„ä¼° 20 ä¸ªé—®é¢˜ï¼ˆåŸºçº¿æ–¹æ³•ï¼‰
python evaluate_framework.py --dataset gsm8k --limit 20 --methods baselines
```

**è¾“å‡º**:
- å®æ—¶è¿›åº¦æ˜¾ç¤º
- å‡†ç¡®ç‡ç»Ÿè®¡
- å¹³å‡æ‰§è¡Œæ—¶é—´
- ç»“æœä¿å­˜åˆ° `evaluation_results/GSM8K_comparison.json`

### 2. äº¤äº’å¼è¯„ä¼°èœå•

```bash
python run_evaluation.py
```

**åŠŸèƒ½**:
- é€‰æ‹©æ•°æ®é›†
- é€‰æ‹©è¯„ä¼°æ–¹æ³•
- è®¾ç½®é—®é¢˜æ•°é‡
- è‡ªåŠ¨è¿è¡Œè¯„ä¼°

---

## ğŸ“Š æ”¯æŒçš„æ•°æ®é›†

### 1. GSM8K (å°å­¦æ•°å­¦æ¨ç†)
- **è·¯å¾„**: `dataset/GSM8K/grade_school_math/data/test.jsonl`
- **æ ¼å¼**: JSONL (æ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡)
- **é—®é¢˜æ•°**: ~1300
- **éš¾åº¦**: â­â­
- **è¯­è¨€**: è‹±æ–‡

**ç¤ºä¾‹å‘½ä»¤**:
```bash
python evaluate_framework.py --dataset gsm8k --limit 50 --methods baselines
```

### 2. MATH (ç«èµ›æ•°å­¦)
- **è·¯å¾„**: `dataset/Math/test-00000-of-00001.parquet.json`
- **æ ¼å¼**: JSON æ•°ç»„
- **é—®é¢˜æ•°**: ~5000
- **éš¾åº¦**: â­â­â­â­
- **è¯­è¨€**: è‹±æ–‡

**ç¤ºä¾‹å‘½ä»¤**:
```bash
python evaluate_framework.py --dataset math --limit 30 --methods baselines
```

### 3. MyData (ä¸­å›½æ•°å­¦ç«èµ›)
- **è·¯å¾„**: `dataset/mydata/data/2024A.json`
- **æ ¼å¼**: JSON æ•°ç»„
- **é—®é¢˜æ•°**: ~100
- **éš¾åº¦**: â­â­â­â­â­
- **è¯­è¨€**: ä¸­æ–‡

**ç¤ºä¾‹å‘½ä»¤**:
```bash
python evaluate_framework.py --dataset mydata --limit 20 --methods baselines
```

### 4. OlympiadBench (å¥¥æ—åŒ¹å…‹ç«èµ›) ğŸ†•

OlympiadBench åŒ…å«å¤šä¸ªå­æ•°æ®é›†ï¼š

#### æ•°å­¦ç«èµ›æ•°æ®é›†
| æ–‡ä»¶å | è¯­è¨€ | ç±»å‹ | éš¾åº¦ |
|--------|------|------|------|
| `OE_TO_maths_zh_CEE.json` | ä¸­æ–‡ | é«˜è€ƒ | â­â­â­ |
| `OE_TO_maths_zh_COMP.json` | ä¸­æ–‡ | ç«èµ› | â­â­â­â­â­ |
| `OE_TO_maths_en_COMP.json` | è‹±æ–‡ | ç«èµ› | â­â­â­â­â­ |
| `OE_MM_maths_zh_CEE.json` | ä¸­æ–‡ | é«˜è€ƒ (å¤šé€‰) | â­â­â­â­ |
| `OE_MM_maths_zh_COMP.json` | ä¸­æ–‡ | ç«èµ› (å¤šé€‰) | â­â­â­â­â­ |
| `OE_MM_maths_en_COMP.json` | è‹±æ–‡ | ç«èµ› (å¤šé€‰) | â­â­â­â­â­ |

#### ç‰©ç†ç«èµ›æ•°æ®é›†
| æ–‡ä»¶å | è¯­è¨€ | ç±»å‹ | éš¾åº¦ |
|--------|------|------|------|
| `OE_TO_physics_zh_CEE.json` | ä¸­æ–‡ | é«˜è€ƒ | â­â­â­ |
| `OE_TO_physics_en_COMP.json` | è‹±æ–‡ | ç«èµ› | â­â­â­â­â­ |
| `OE_MM_physics_zh_CEE.json` | ä¸­æ–‡ | é«˜è€ƒ (å¤šé€‰) | â­â­â­â­ |

**æ•°æ®æ ¼å¼**:
```json
{
    "id": 3103,
    "subfield": "Derivative",
    "question": "é—®é¢˜æè¿°...",
    "solution": ["è§£ç­”æ­¥éª¤..."],
    "final_answer": ["æœ€ç»ˆç­”æ¡ˆ"],
    "answer_type": "Interval",
    "unit": null
}
```

---

## ğŸ”¬ æ”¯æŒçš„è¯„ä¼°æ–¹æ³•

### åŸºçº¿æ–¹æ³• (Baselines)

#### 1. Direct LLM (ç›´æ¥ LLM)
- **æè¿°**: ç›´æ¥è®© LLM å›ç­”ï¼Œä¸ä½¿ç”¨æ€ç»´é“¾
- **ä¼˜ç‚¹**: æœ€å¿«
- **ç¼ºç‚¹**: å‡†ç¡®ç‡è¾ƒä½
- **ä»£ç **: `baselines/direct_llm.py`

#### 2. Zero-Shot CoT (é›¶æ ·æœ¬æ€ç»´é“¾)
- **æè¿°**: ä½¿ç”¨ "Let's think step by step" æç¤º
- **ä¼˜ç‚¹**: æ— éœ€ç¤ºä¾‹ï¼Œæ¨ç†èƒ½åŠ›å¼º
- **ç¼ºç‚¹**: æ¯”ç›´æ¥ LLM æ…¢
- **å‚è€ƒ**: Kojima et al., NeurIPS 2022
- **ä»£ç **: `baselines/zero_shot_cot.py`

#### 3. Few-Shot CoT (å°‘æ ·æœ¬æ€ç»´é“¾)
- **æè¿°**: æä¾›ç¤ºä¾‹åå†æ±‚è§£
- **ä¼˜ç‚¹**: å‡†ç¡®ç‡æœ€é«˜ï¼ˆåŸºçº¿ä¸­ï¼‰
- **ç¼ºç‚¹**: éœ€è¦ç²¾å¿ƒè®¾è®¡ç¤ºä¾‹
- **å‚è€ƒ**: Wei et al., NeurIPS 2022
- **ä»£ç **: `baselines/few_shot_cot.py`

#### 4. Full Framework (å®Œæ•´å› æœæ¨ç†æ¡†æ¶)
- **æè¿°**: ä½¿ç”¨å®Œæ•´çš„ 4 é˜¶æ®µæµç¨‹
- **ä¼˜ç‚¹**: æœ€é«˜å‡†ç¡®ç‡ï¼Œå¯è§£é‡Šæ€§å¼º
- **ç¼ºç‚¹**: è¾ƒæ…¢
- **é˜¶æ®µ**:
  1. æ··åˆçŸ¥è¯†æ£€ç´¢
  2. å› æœè„šæ‰‹æ¶
  3. ç¬¦å·æ‰§è¡Œ
  4. åˆæˆéªŒè¯

### æ¶ˆèå®éªŒæ–¹æ³• (Ablations)

#### 5. No Retriever (æ— æ£€ç´¢å™¨)
- **æè¿°**: ç§»é™¤çŸ¥è¯†æ£€ç´¢æ¨¡å—
- **ç›®çš„**: è¯„ä¼°çŸ¥è¯†æ£€ç´¢çš„é‡è¦æ€§

#### 6. No AI Retriever (æ—  AI æ£€ç´¢å™¨)
- **æè¿°**: ä»…ä½¿ç”¨ä¼ ç»Ÿæ£€ç´¢ï¼Œä¸ç”¨ AI ç”Ÿæˆ
- **ç›®çš„**: è¯„ä¼° AI åŠ¨æ€ç”Ÿæˆçš„ä»·å€¼

#### 7. No Symbolic Execution (æ— ç¬¦å·æ‰§è¡Œ)
- **æè¿°**: ä½¿ç”¨ LLM ç›´æ¥è®¡ç®—ï¼Œä¸ç”¨ SymPy
- **ç›®çš„**: è¯„ä¼°ç¬¦å·æ‰§è¡Œçš„å¿…è¦æ€§

---

## ğŸ’» åŸºæœ¬ä½¿ç”¨

### å‘½ä»¤è¡Œå‚æ•°è¯¦è§£

```bash
python evaluate_framework.py \
    --dataset DATASET_NAME \    # æ•°æ®é›†åç§°
    --limit N \                  # è¯„ä¼°é—®é¢˜æ•°é‡
    --methods METHOD_TYPE \      # è¯„ä¼°æ–¹æ³•ç±»å‹
    --output OUTPUT_DIR \        # è¾“å‡ºç›®å½•
    --verbose                    # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
```

### å‚æ•°è¯´æ˜

#### `--dataset` (å¿…éœ€)
é€‰æ‹©è¯„ä¼°æ•°æ®é›†ï¼š
- `gsm8k`: GSM8K æ•°æ®é›†
- `math`: MATH æ•°æ®é›†
- `mydata`: MyData æ•°æ®é›†

#### `--limit` (å¯é€‰, é»˜è®¤=20)
é™åˆ¶è¯„ä¼°çš„é—®é¢˜æ•°é‡ï¼š
```bash
--limit 10    # ä»…è¯„ä¼° 10 ä¸ªé—®é¢˜
--limit 100   # è¯„ä¼° 100 ä¸ªé—®é¢˜
--limit 0     # è¯„ä¼°æ‰€æœ‰é—®é¢˜ (å¯èƒ½å¾ˆæ…¢!)
```

#### `--methods` (å¯é€‰, é»˜è®¤=baselines)
é€‰æ‹©è¯„ä¼°æ–¹æ³•ç±»å‹ï¼š
- `baselines`: æ‰€æœ‰åŸºçº¿æ–¹æ³•
- `ablations`: æ‰€æœ‰æ¶ˆèå®éªŒ
- `all`: æ‰€æœ‰æ–¹æ³•

å¯ä»¥ç»„åˆä½¿ç”¨ï¼š
```bash
--methods baselines ablations    # åŸºçº¿ + æ¶ˆè
--methods all                     # æ‰€æœ‰æ–¹æ³•
```

#### `--output` (å¯é€‰, é»˜è®¤=evaluation_results)
æŒ‡å®šç»“æœä¿å­˜ç›®å½•ï¼š
```bash
--output my_results     # ä¿å­˜åˆ° my_results/
--output ./results      # ä¿å­˜åˆ° ./results/
```

#### `--verbose` (å¯é€‰)
æ˜¾ç¤ºè¯¦ç»†çš„æ‰§è¡Œä¿¡æ¯ï¼š
```bash
--verbose    # æ˜¾ç¤ºæ¯ä¸ªæ­¥éª¤çš„è¯¦ç»†ä¿¡æ¯
```

---

## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: å¿«é€Ÿæµ‹è¯•ï¼ˆ10ä¸ªé—®é¢˜ï¼‰

```bash
python evaluate_framework.py \
    --dataset gsm8k \
    --limit 10 \
    --methods baselines
```

**é¢„è®¡æ—¶é—´**: 2-5 åˆ†é’Ÿ
**ç”¨é€”**: å¿«é€ŸéªŒè¯ç³»ç»Ÿå·¥ä½œæ­£å¸¸

### ç¤ºä¾‹ 2: æ ‡å‡†è¯„ä¼°ï¼ˆ50ä¸ªé—®é¢˜ï¼‰

```bash
python evaluate_framework.py \
    --dataset gsm8k \
    --limit 50 \
    --methods baselines ablations
```

**é¢„è®¡æ—¶é—´**: 15-30 åˆ†é’Ÿ
**ç”¨é€”**: è·å¾—å¯é çš„æ€§èƒ½è¯„ä¼°

### ç¤ºä¾‹ 3: å®Œæ•´è¯„ä¼°ï¼ˆæ‰€æœ‰é—®é¢˜ï¼‰

```bash
python evaluate_framework.py \
    --dataset math \
    --limit 100 \
    --methods all \
    --output math_full_results
```

**é¢„è®¡æ—¶é—´**: 1-2 å°æ—¶
**ç”¨é€”**: è®ºæ–‡å®éªŒï¼Œå®Œæ•´æ€§èƒ½æŠ¥å‘Š

### ç¤ºä¾‹ 4: ä»…æµ‹è¯•å®Œæ•´æ¡†æ¶

```bash
python evaluate_framework.py \
    --dataset mydata \
    --limit 20 \
    --methods baselines \
    --verbose
```

### ç¤ºä¾‹ 5: å¯¹æ¯”åŸºçº¿æ–¹æ³•

```bash
# è¿è¡Œæ‰€æœ‰åŸºçº¿æ–¹æ³•
python evaluate_framework.py \
    --dataset gsm8k \
    --limit 50 \
    --methods baselines \
    --output baseline_comparison
```

### ç¤ºä¾‹ 6: æ¶ˆèå®éªŒ

```bash
# è¿è¡Œæ‰€æœ‰æ¶ˆèå®éªŒ
python evaluate_framework.py \
    --dataset gsm8k \
    --limit 30 \
    --methods ablations \
    --output ablation_study
```

---

## ğŸ“ˆ é«˜çº§ä½¿ç”¨

### 1. æ‰¹é‡è¯„ä¼°å¤šä¸ªæ•°æ®é›†

åˆ›å»ºè„šæœ¬ `batch_eval.sh`:

```bash
#!/bin/bash

# è¯„ä¼° GSM8K
python evaluate_framework.py --dataset gsm8k --limit 50 --methods baselines

# è¯„ä¼° MATH
python evaluate_framework.py --dataset math --limit 50 --methods baselines

# è¯„ä¼° MyData
python evaluate_framework.py --dataset mydata --limit 20 --methods baselines

echo "All evaluations completed!"
```

è¿è¡Œ:
```bash
bash batch_eval.sh
```

### 2. è¯„ä¼° OlympiadBench æ•°æ®é›†

é¦–å…ˆéœ€è¦æ·»åŠ  OlympiadBench æ•°æ®åŠ è½½å™¨ï¼ˆè§ä¸‹æ–‡ï¼‰ï¼Œç„¶åï¼š

```bash
python evaluate_olympiad.py \
    --dataset OE_TO_maths_zh_CEE \
    --limit 30 \
    --methods baselines
```

### 3. è‡ªå®šä¹‰è¯„ä¼°æ–¹æ³•

ç¼–è¾‘ `evaluate_framework.py`ï¼Œæ·»åŠ è‡ªå®šä¹‰æ–¹æ³•ï¼š

```python
class EvaluationMethod(Enum):
    # æ·»åŠ è‡ªå®šä¹‰æ–¹æ³•
    MY_CUSTOM_METHOD = "my_custom_method"

# åœ¨ evaluate_single ä¸­æ·»åŠ å¤„ç†é€»è¾‘
def evaluate_single(self, problem, method):
    if method == EvaluationMethod.MY_CUSTOM_METHOD:
        predicted_answer = self._run_my_custom_method(problem)
```

---

## ğŸ“Š ç»“æœåˆ†æ

### 1. æŸ¥çœ‹è¯„ä¼°ç»“æœ

è¯„ä¼°å®Œæˆåï¼Œç»“æœä¿å­˜åœ¨ JSON æ–‡ä»¶ä¸­ï¼š

```bash
cat evaluation_results/GSM8K_comparison.json
```

**ç»“æœç»“æ„**:
```json
{
  "dataset_name": "GSM8K",
  "total_problems": 50,
  "evaluation_time": "2025-10-07T...",
  "methods": {
    "direct_llm": {
      "statistics": {
        "total": 50,
        "correct": 30,
        "accuracy": 0.60,
        "avg_time": 1.2
      },
      "results": [...]
    },
    "full_framework": {
      "statistics": {
        "total": 50,
        "correct": 45,
        "accuracy": 0.90,
        "avg_time": 3.5
      },
      "results": [...]
    }
  }
}
```

### 2. ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼

```bash
python visualize_results.py evaluation_results/GSM8K_comparison.json
```

**è¾“å‡º**:
```
============================================================
COMPARISON TABLE / å¯¹æ¯”è¡¨æ ¼
============================================================
Dataset: GSM8K
æ•°æ®é›†: GSM8K

Method                         Accuracy        Avg Time
æ–¹æ³•                           å‡†ç¡®ç‡          å¹³å‡æ—¶é—´
------------------------------------------------------------
direct_llm                     60.00%          1.20s
zero_shot_cot                  75.00%          2.10s
few_shot_cot                   80.00%          2.50s
full_framework                 90.00%          3.50s
============================================================
```

### 3. ç”Ÿæˆ LaTeX è¡¨æ ¼ï¼ˆè®ºæ–‡ç”¨ï¼‰

```bash
python visualize_results.py \
    evaluation_results/GSM8K_comparison.json \
    --latex \
    --output paper_table.tex
```

**è¾“å‡ºæ–‡ä»¶** `paper_table.tex`:
```latex
\begin{table}[h]
\centering
\begin{tabular}{lcc}
\hline
Method & Accuracy & Avg Time (s) \\
\hline
Direct LLM & 60.00\% & 1.20 \\
Zero-Shot CoT & 75.00\% & 2.10 \\
Few-Shot CoT & 80.00\% & 2.50 \\
Full Framework & 90.00\% & 3.50 \\
\hline
\end{tabular}
\caption{Performance comparison on GSM8K dataset}
\end{table}
```

### 4. å¯¼å‡º CSV

```bash
python visualize_results.py \
    evaluation_results/GSM8K_comparison.json \
    --csv \
    --output results.csv
```

### 5. å¯¹æ¯”ä¸¤ç§æ–¹æ³•

```bash
python visualize_results.py \
    evaluation_results/GSM8K_comparison.json \
    --compare direct_llm full_framework
```

**è¾“å‡º**:
```
Comparing: direct_llm vs full_framework
-----------------------------------------
Accuracy improvement: +30.00%
Time overhead: +2.30s (+191.67%)
Correct answers gained: +15 questions
```

---

## ğŸ› ï¸ å¸¸è§é—®é¢˜

### Q1: è¯„ä¼°å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ

**A**: å‡å°‘è¯„ä¼°é—®é¢˜æ•°é‡
```bash
--limit 10    # å¿«é€Ÿæµ‹è¯•
--limit 20    # æ ‡å‡†æµ‹è¯•
```

### Q2: å¦‚ä½•åªè¯„ä¼°å®Œæ•´æ¡†æ¶ï¼Ÿ

**A**: æš‚æ—¶æ— æ³•å•ç‹¬é€‰æ‹©ï¼Œä½†å¯ä»¥ä¿®æ”¹ä»£ç ï¼š
```python
# åœ¨ main() å‡½æ•°ä¸­
methods_to_run = [EvaluationMethod.FULL_FRAMEWORK]
```

### Q3: å¦‚ä½•æ·»åŠ æ–°æ•°æ®é›†ï¼Ÿ

**A**: åœ¨ `evaluate_framework.py` ä¸­æ·»åŠ æ•°æ®åŠ è½½å™¨ï¼š
```python
@staticmethod
def load_my_dataset(file_path, limit=None):
    # è¯»å–æ•°æ®
    # æ ¼å¼åŒ–ä¸ºæ ‡å‡†æ ¼å¼
    # è¿”å›é—®é¢˜åˆ—è¡¨
    pass
```

### Q4: è¯„ä¼°ä¸­æ–­æ€ä¹ˆåŠï¼Ÿ

**A**: ç›®å‰ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œéœ€è¦é‡æ–°è¿è¡Œã€‚å»ºè®®ï¼š
- å‡å°‘ `--limit` å€¼
- ä½¿ç”¨å¤šä¸ªå°æ‰¹æ¬¡è¯„ä¼°

### Q5: å¦‚ä½•è°ƒè¯•å•ä¸ªé—®é¢˜ï¼Ÿ

**A**: ä½¿ç”¨ Python APIï¼š
```python
from evaluate_framework import FrameworkEvaluator, EvaluationMethod

evaluator = FrameworkEvaluator(verbose=True)
problem = {
    'id': 'test_1',
    'question': 'What is 2+2?',
    'answer': '4'
}

result = evaluator.evaluate_single(
    problem,
    EvaluationMethod.FULL_FRAMEWORK
)
print(f"Correct: {result.is_correct}")
print(f"Predicted: {result.predicted_answer}")
```

### Q6: å‡†ç¡®ç‡å¾ˆä½æ€ä¹ˆåŠï¼Ÿ

**A**: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. API å¯†é’¥æ˜¯å¦æ­£ç¡®é…ç½®
2. æ•°æ®æ ¼å¼æ˜¯å¦åŒ¹é…
3. ç­”æ¡ˆæ¯”è¾ƒé€»è¾‘æ˜¯å¦åˆé€‚
4. ä½¿ç”¨ `--verbose` æŸ¥çœ‹è¯¦ç»†é”™è¯¯

---

## ğŸ“ å®Œæ•´ç¤ºä¾‹æµç¨‹

### åœºæ™¯ï¼šè¯„ä¼°æ¡†æ¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„æ€§èƒ½

#### Step 1: é…ç½®ç¯å¢ƒ
```bash
# ç¡®ä¿ .env æ–‡ä»¶é…ç½®æ­£ç¡®
cat .env
```

#### Step 2: å¿«é€Ÿæµ‹è¯•
```bash
# å…ˆç”¨å°‘é‡æ•°æ®æµ‹è¯•
python evaluate_framework.py \
    --dataset gsm8k \
    --limit 5 \
    --methods baselines \
    --verbose
```

#### Step 3: GSM8K å®Œæ•´è¯„ä¼°
```bash
python evaluate_framework.py \
    --dataset gsm8k \
    --limit 100 \
    --methods baselines ablations \
    --output gsm8k_results
```

#### Step 4: MATH æ•°æ®é›†è¯„ä¼°
```bash
python evaluate_framework.py \
    --dataset math \
    --limit 50 \
    --methods baselines \
    --output math_results
```

#### Step 5: MyData è¯„ä¼°
```bash
python evaluate_framework.py \
    --dataset mydata \
    --limit 20 \
    --methods baselines \
    --output mydata_results
```

#### Step 6: ç»“æœå¯è§†åŒ–
```bash
# ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
python visualize_results.py gsm8k_results/GSM8K_comparison.json

# ç”Ÿæˆ LaTeX è¡¨æ ¼
python visualize_results.py \
    gsm8k_results/GSM8K_comparison.json \
    --latex --output gsm8k_table.tex

# å¯¼å‡º CSV
python visualize_results.py \
    gsm8k_results/GSM8K_comparison.json \
    --csv --output gsm8k_results.csv
```

#### Step 7: åˆ†æç»“æœ
```python
import json

# è¯»å–ç»“æœ
with open('gsm8k_results/GSM8K_comparison.json', 'r') as f:
    results = json.load(f)

# æ‰“å°ç»Ÿè®¡ä¿¡æ¯
for method, data in results['methods'].items():
    stats = data['statistics']
    print(f"{method}: {stats['accuracy']*100:.1f}% "
          f"({stats['correct']}/{stats['total']})")
```

---

## ğŸ“ è¯„ä¼°æœ€ä½³å®è·µ

1. **ä»å°å¼€å§‹**: å…ˆç”¨ `--limit 10` å¿«é€Ÿæµ‹è¯•
2. **é€æ­¥å¢åŠ **: ç¡®è®¤æ— è¯¯åå¢åŠ åˆ° 50ã€100
3. **è®°å½•ç»“æœ**: ä¿å­˜æ‰€æœ‰è¯„ä¼°ç»“æœä»¥ä¾¿å¯¹æ¯”
4. **å¤šæ¬¡è¿è¡Œ**: å¯¹äºéšæœºæ€§è¾ƒå¤§çš„æ–¹æ³•ï¼Œå¤šæ¬¡è¿è¡Œå–å¹³å‡
5. **æ£€æŸ¥é”™è¯¯**: ä½¿ç”¨ `--verbose` æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯
6. **åˆç†è®¾ç½®è¶…æ—¶**: å¤æ‚é—®é¢˜å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´

---

## ğŸ“ è·å–å¸®åŠ©

- **æŸ¥çœ‹æºç **: `evaluate_framework.py`
- **è¿è¡Œæµ‹è¯•**: `python test_baselines.py`
- **æŸ¥çœ‹æ–‡æ¡£**:
  - `BASELINES_GUIDE.md` - åŸºçº¿æ–¹æ³•æŒ‡å—
  - `HYBRID_RETRIEVAL_GUIDE.md` - æ··åˆæ£€ç´¢æŒ‡å—
  - `README.md` - é¡¹ç›®ä¸»æ–‡æ¡£

---

**ç¥è¯„ä¼°é¡ºåˆ©ï¼ğŸ“Š**
