# New Datasets Integration Summary
# æ–°æ•°æ®é›†é›†æˆæ€»ç»“

## ğŸ“‹ Overview / æ¦‚è¿°

æˆåŠŸåœ¨ `DatasetLoader` ç±»ä¸­æ·»åŠ äº†ä¸¤ä¸ªæ–°çš„æ•°æ®é›†ï¼š
- **Omni-MATH**: ç»¼åˆæ•°å­¦æ¨ç†æ•°æ®é›†
- **OlympiadBench**: å¥¥æ—åŒ¹å…‹çº§åˆ«æ•°å­¦ç‰©ç†æ•°æ®é›†ï¼ˆâ­ **æ”¯æŒå¤šæ¨¡æ€**ï¼‰

---

## âœ¨ New Features / æ–°åŠŸèƒ½

### 1. Omni-MATH Dataset / Omni-MATH æ•°æ®é›†

**æ–‡ä»¶ä½ç½®**: `dataset/Omni-MATH/archive/main_test.jsonl`

**ç‰¹ç‚¹**:
- JSONL æ ¼å¼ï¼ˆä¸ GSM8K ç±»ä¼¼ï¼‰
- åŒ…å« `question` å’Œ `answer` å­—æ®µ
- ç­”æ¡ˆæ ¼å¼ï¼š`è§£æè¿‡ç¨‹ #### æœ€ç»ˆç­”æ¡ˆ`

**ä½¿ç”¨æ–¹æ³•**:
```python
from evaluate_framework import DatasetLoader

loader = DatasetLoader()
problems = loader.load_omnimath(
    "dataset/Omni-MATH/archive/main_test.jsonl",
    limit=10
)
```

**å‘½ä»¤è¡Œ**:
```bash
python evaluate_framework.py --dataset omnimath --limit 10
python batch_evaluator.py --dataset omnimath --limit 10 --batch-size 3
```

---

### 2. OlympiadBench Dataset â­ / OlympiadBench æ•°æ®é›† â­

**æ–‡ä»¶ä½ç½®**: `dataset/OlympiadBench_Dataset/OlympiadBench_Dataset/data/*.json`

**ç‰¹ç‚¹**:
- â­ **å¤šæ¨¡æ€æ”¯æŒ**: éƒ¨åˆ†é—®é¢˜åŒ…å«å›¾ç‰‡ï¼ˆæ ‡è®°ä¸º `<img_XXXX>`ï¼‰
- ğŸ“š é«˜éš¾åº¦ï¼šå¥¥æ—åŒ¹å…‹ç«èµ›çº§åˆ«
- ğŸŒ å¤šè¯­è¨€ï¼šè‹±è¯­å’Œä¸­æ–‡
- ğŸ“ å¤šå­¦ç§‘ï¼šæ•°å­¦ã€ç‰©ç†
- ğŸ¯ å¤šé¢˜å‹ï¼šå®šç†è¯æ˜ã€å¼€æ”¾å¼é—®é¢˜

**æ–‡ä»¶å‘½åè§„åˆ™**:
```
{ProblemType}_{Modality}_{Subject}_{Language}_{Exam}.json

Examples:
- TP_TO_maths_en_COMP.json  (çº¯æ–‡æœ¬)
- TP_MM_maths_en_COMP.json  (å¤šæ¨¡æ€ â­)
- TP_MM_physics_zh_CEE.json (å¤šæ¨¡æ€ â­)
```

**ä½¿ç”¨æ–¹æ³•**:
```python
from evaluate_framework import DatasetLoader

loader = DatasetLoader()

# åŠ è½½æ‰€æœ‰é—®é¢˜
problems = loader.load_olympiadbench(
    "dataset/OlympiadBench_Dataset/OlympiadBench_Dataset/data/TP_MM_maths_en_COMP.json",
    limit=10
)

# åªåŠ è½½å¤šæ¨¡æ€é—®é¢˜
problems_mm = loader.load_olympiadbench(
    "dataset/OlympiadBench_Dataset/OlympiadBench_Dataset/data/TP_MM_maths_en_COMP.json",
    limit=10,
    filter_multimodal=True  # åªè¦æœ‰å›¾ç‰‡çš„
)

# åªåŠ è½½çº¯æ–‡æœ¬é—®é¢˜
problems_to = loader.load_olympiadbench(
    "dataset/OlympiadBench_Dataset/OlympiadBench_Dataset/data/TP_MM_maths_en_COMP.json",
    limit=10,
    filter_multimodal=False  # åªè¦æ²¡å›¾ç‰‡çš„
)
```

**å‘½ä»¤è¡Œ**:
```bash
python evaluate_framework.py --dataset olympiad --limit 10
python batch_evaluator.py --dataset olympiad --limit 10 --batch-size 3
```

**å¤šæ¨¡æ€å…ƒæ•°æ®** / Multi-Modal Metadata:
æ¯ä¸ªé—®é¢˜éƒ½åŒ…å«ä»¥ä¸‹å¤šæ¨¡æ€ç›¸å…³å­—æ®µï¼š
```python
{
    'has_images': True/False,        # æ˜¯å¦åŒ…å«å›¾ç‰‡
    'image_ids': ['3408', '3692'],   # å›¾ç‰‡ ID åˆ—è¡¨
    'image_count': 2,                # å›¾ç‰‡æ•°é‡
    'problem_type': 'TP',            # é—®é¢˜ç±»å‹
    'modality': 'MM',                # æ¨¡æ€ç±»å‹
    'subject': 'maths',              # å­¦ç§‘
    'language': 'en',                # è¯­è¨€
    'exam_type': 'COMP',             # è€ƒè¯•ç±»å‹
}
```

---

## ğŸ“ Modified Files / ä¿®æ”¹çš„æ–‡ä»¶

### 1. `evaluate_framework.py`
- âœ… æ·»åŠ  `DatasetLoader.load_omnimath()` æ–¹æ³• (è¡Œ 172-212)
- âœ… æ·»åŠ  `DatasetLoader.load_olympiadbench()` æ–¹æ³• (è¡Œ 214-345)
  - æ”¯æŒå¤šæ¨¡æ€å›¾ç‰‡æ£€æµ‹
  - æ”¯æŒè¿‡æ»¤é€‰é¡¹ `filter_multimodal`
  - è‡ªåŠ¨è§£ææ–‡ä»¶åå…ƒæ•°æ®
- âœ… æ›´æ–°å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ `omnimath` å’Œ `olympiad` (è¡Œ 852)
- âœ… æ›´æ–°æ•°æ®é›†åŠ è½½é€»è¾‘ (è¡Œ 932-944)

### 2. `batch_evaluator.py`
- âœ… æ›´æ–°å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ `omnimath` å’Œ `olympiad` (è¡Œ 366)
- âœ… æ›´æ–°æ•°æ®é›†åŠ è½½é€»è¾‘ (è¡Œ 460-471)

### 3. New Files / æ–°æ–‡ä»¶

| File | Description |
|------|-------------|
| `DATASET_STRUCTURES.md` | æ‰€æœ‰æ•°æ®é›†çš„è¯¦ç»†ç»“æ„åˆ†æ |
| `NEW_DATASETS_SUMMARY.md` | æœ¬æ–‡æ¡£ - æ–°æ•°æ®é›†é›†æˆæ€»ç»“ |
| `test_new_datasets.py` | æµ‹è¯•è„šæœ¬ï¼ŒéªŒè¯æ–°æ•°æ®é›†åŠ è½½åŠŸèƒ½ |

---

## ğŸ§ª Testing / æµ‹è¯•

### Quick Test / å¿«é€Ÿæµ‹è¯•
```bash
# æµ‹è¯•æ–°æ•°æ®é›†åŠ è½½
python test_new_datasets.py
```

### Real Evaluation / å®é™…è¯„ä¼°
```bash
# Omni-MATH è¯„ä¼°
python evaluate_framework.py --dataset omnimath --limit 10 --methods baselines

# OlympiadBench è¯„ä¼°ï¼ˆçº¯æ–‡æœ¬ï¼‰
python evaluate_framework.py --dataset olympiad --limit 5 --methods baselines

# æ‰¹é‡å¹¶å‘è¯„ä¼°
python batch_evaluator.py --dataset omnimath --limit 10 --batch-size 3
python batch_evaluator.py --dataset olympiad --limit 5 --batch-size 2
```

---

## ğŸ“Š Dataset Comparison / æ•°æ®é›†å¯¹æ¯”

| Dataset | Format | Modality | Difficulty | Language | Image Support |
|---------|--------|----------|-----------|----------|---------------|
| GSM8K | JSONL | Text | Elementary | EN | âŒ |
| MATH | JSON | Text | High School | EN | âŒ |
| Omni-MATH | JSONL | Text | Mixed | EN | âŒ |
| **OlympiadBench** | **JSON** | **Multi-Modal** | **Olympiad** | **EN/ZH** | **â­ YES** |
| MyData | JSON | Text | Custom | ZH | âŒ |

---

## ğŸ”§ Implementation Details / å®ç°ç»†èŠ‚

### Image Detection / å›¾ç‰‡æ£€æµ‹
```python
# åœ¨ load_olympiadbench æ–¹æ³•ä¸­
question_text = item.get('question', '')
image_pattern = r'<img_(\d+)>'
image_matches = re.findall(image_pattern, question_text)
has_images = len(image_matches) > 0
```

### File Name Parsing / æ–‡ä»¶åè§£æ
```python
# è‡ªåŠ¨è§£ææ–‡ä»¶åæå–å…ƒæ•°æ®
file_name = Path(file_path).stem  # "TP_MM_maths_en_COMP"
parts = file_name.split('_')
problem_type = parts[0]  # TP or OE
modality = parts[1]      # TO or MM
subject = parts[2]       # maths or physics
language = parts[3]      # en or zh
exam_type = parts[4]     # COMP or CEE
```

### Data Summary / æ•°æ®æ‘˜è¦
```python
# åŠ è½½åè‡ªåŠ¨æ‰“å°æ‘˜è¦
ğŸ“Š OlympiadBench Dataset Loaded / OlympiadBench æ•°æ®é›†å·²åŠ è½½:
  Total problems: 10 / æ€»é—®é¢˜æ•°: 10
  Multi-modal (with images): 8 / å¤šæ¨¡æ€ï¼ˆå«å›¾ç‰‡ï¼‰: 8
  Text-only: 2 / çº¯æ–‡æœ¬: 2
  Subject: maths | Language: en | Type: TP
```

---

## ğŸ’¡ Usage Tips / ä½¿ç”¨æç¤º

### 1. OlympiadBench æ–‡ä»¶é€‰æ‹© / OlympiadBench File Selection

æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ–‡ä»¶ï¼š

**çº¯æ–‡æœ¬** (Text-Only):
```bash
# æ•°å­¦ç«èµ› - è‹±è¯­
TP_TO_maths_en_COMP.json
# ç‰©ç†ç«èµ› - è‹±è¯­
TP_TO_physics_en_COMP.json
# æ•°å­¦é«˜è€ƒ - ä¸­æ–‡
TP_TO_maths_zh_CEE.json
```

**å¤šæ¨¡æ€** (Multi-Modal):
```bash
# æ•°å­¦ç«èµ› - è‹±è¯­ï¼ˆå«å›¾ç‰‡ï¼‰â­
TP_MM_maths_en_COMP.json
# ç‰©ç†ç«èµ› - è‹±è¯­ï¼ˆå«å›¾ç‰‡ï¼‰â­
TP_MM_physics_en_COMP.json
# æ•°å­¦é«˜è€ƒ - ä¸­æ–‡ï¼ˆå«å›¾ç‰‡ï¼‰â­
TP_MM_maths_zh_CEE.json
```

### 2. å¤šæ¨¡æ€é—®é¢˜å¤„ç† / Multi-Modal Problem Handling

å½“å‰å®ç°ï¼š
- âœ… æ£€æµ‹å›¾ç‰‡æ ‡è®° `<img_XXXX>`
- âœ… æå–å›¾ç‰‡ ID åˆ—è¡¨
- âœ… è®°å½•å¤šæ¨¡æ€å…ƒæ•°æ®
- âš ï¸ å›¾ç‰‡ä½œä¸ºæ–‡æœ¬æ ‡è®°ä¿ç•™åœ¨é—®é¢˜ä¸­

æœªæ¥å¢å¼ºï¼š
- å®é™…å›¾ç‰‡æ–‡ä»¶åŠ è½½
- æ”¯æŒè§†è§‰è¯­è¨€æ¨¡å‹ (VLM)
- å›¾ç‰‡ç‰¹å¾æå–

### 3. æ‰¹é‡å¤„ç†å»ºè®® / Batch Processing Recommendations

```bash
# Omni-MATH: ä¸­ç­‰éš¾åº¦ï¼Œå¯ä»¥ç”¨è¾ƒå¤§ batch_size
python batch_evaluator.py --dataset omnimath --limit 20 --batch-size 5

# OlympiadBench: æé«˜éš¾åº¦ï¼Œå»ºè®®å° batch_size
python batch_evaluator.py --dataset olympiad --limit 10 --batch-size 2
```

---

## ğŸ› Known Limitations / å·²çŸ¥é™åˆ¶

1. **å¤šæ¨¡æ€å›¾ç‰‡**: å½“å‰åªå­˜å‚¨å›¾ç‰‡æ ‡è®°ï¼Œä¸åŠ è½½å®é™…å›¾ç‰‡
2. **è¯æ˜é¢˜ç­”æ¡ˆ**: OlympiadBench çš„è¯æ˜é¢˜æ²¡æœ‰æ•°å€¼ç­”æ¡ˆï¼Œä½¿ç”¨å ä½ç¬¦ `[PROOF_REQUIRED]`
3. **ç­”æ¡ˆæ ¼å¼**: éƒ¨åˆ† OlympiadBench é—®é¢˜çš„ `final_answer` ä¸º `null`

---

## ğŸ“š Documentation / æ–‡æ¡£

è¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒï¼š
- **æ•°æ®é›†ç»“æ„åˆ†æ**: `DATASET_STRUCTURES.md`
- **æ‰¹é‡è¯„ä¼°æŒ‡å—**: `BATCH_EVALUATION_GUIDE.md`
- **ä¸»è¦ README**: `README.md`

---

## âœ… Checklist / æ£€æŸ¥æ¸…å•

- [x] æ·»åŠ  `load_omnimath()` æ–¹æ³•
- [x] æ·»åŠ  `load_olympiadbench()` æ–¹æ³•
- [x] æ”¯æŒå¤šæ¨¡æ€å›¾ç‰‡æ£€æµ‹
- [x] æ·»åŠ è¿‡æ»¤é€‰é¡¹ `filter_multimodal`
- [x] æ›´æ–°å‘½ä»¤è¡Œå‚æ•°
- [x] æ›´æ–° `evaluate_framework.py`
- [x] æ›´æ–° `batch_evaluator.py`
- [x] åˆ›å»ºæµ‹è¯•è„šæœ¬
- [x] åˆ›å»ºæ–‡æ¡£

---

## ğŸš€ Quick Start / å¿«é€Ÿå¼€å§‹

```bash
# 1. æµ‹è¯•æ–°æ•°æ®é›†åŠ è½½
python test_new_datasets.py

# 2. è¯„ä¼° Omni-MATH
python evaluate_framework.py --dataset omnimath --limit 10 --methods baselines

# 3. è¯„ä¼° OlympiadBenchï¼ˆå¤šæ¨¡æ€ï¼‰
python evaluate_framework.py --dataset olympiad --limit 5 --methods baselines

# 4. æ‰¹é‡å¹¶å‘è¯„ä¼°
python batch_evaluator.py --dataset omnimath --limit 20 --batch-size 5
python batch_evaluator.py --dataset olympiad --limit 10 --batch-size 2
```

---

**é›†æˆå®Œæˆæ—¶é—´**: 2025-01-15
**æ”¯æŒçš„æ•°æ®é›†æ€»æ•°**: 5 (GSM8K, MATH, MyData, Omni-MATH, OlympiadBench)
**å¤šæ¨¡æ€æ”¯æŒ**: â­ YES (OlympiadBench)

äº«å—æ–°æ•°æ®é›†çš„å¼ºå¤§åŠŸèƒ½ï¼ğŸ‰
