"""
Vector-based Knowledge Retriever Module
åŸºäºå‘é‡çš„çŸ¥è¯†æ£€ç´¢æ¨¡å—

This module implements true RAG (Retrieval-Augmented Generation) using
semantic similarity search with sentence embeddings instead of keyword matching.

æœ¬æ¨¡å—ä½¿ç”¨å¥å­åµŒå…¥çš„è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢å®ç°çœŸæ­£çš„RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ï¼Œ
è€Œä¸æ˜¯å…³é”®è¯åŒ¹é…ã€‚
"""

import json
import numpy as np
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
import pickle


@dataclass
class VectorKnowledgeEntry:
    """
    Data structure for a vector-based knowledge entry.
    åŸºäºå‘é‡çš„çŸ¥è¯†æ¡ç›®æ•°æ®ç»“æ„
    
    Attributes:
        rule: The formula or principle description
              å…¬å¼æˆ–åŸç†çš„æè¿°
        category: Optional category for organization
                  å¯é€‰çš„åˆ†ç±»æ ‡ç­¾
        embedding: The vector embedding of the rule
                   è§„åˆ™çš„å‘é‡åµŒå…¥
    """
    rule: str
    category: Optional[str] = None
    embedding: Optional[np.ndarray] = None


class VectorKnowledgeRetriever:
    """
    Vector-based Knowledge Retrieval System using semantic similarity.
    åŸºäºå‘é‡çš„çŸ¥è¯†æ£€ç´¢ç³»ç»Ÿï¼Œä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦
    
    This class uses sentence embeddings to find semantically similar
    knowledge entries rather than relying on keyword matching.
    
    æ­¤ç±»ä½¿ç”¨å¥å­åµŒå…¥æ¥æ‰¾åˆ°è¯­ä¹‰ç›¸ä¼¼çš„çŸ¥è¯†æ¡ç›®ï¼Œè€Œä¸æ˜¯ä¾èµ–å…³é”®è¯åŒ¹é…ã€‚
    """

    def __init__(
        self,
        knowledge_base_path: str = "data/knowledge_base.json",
        model_name: str = "all-MiniLM-L6-v2",
        cache_path: Optional[str] = "data/knowledge_embeddings.pkl",
        use_cache: bool = True
    ):
        """
        Initialize the vector-based knowledge retriever.
        åˆå§‹åŒ–åŸºäºå‘é‡çš„çŸ¥è¯†æ£€ç´¢å™¨
        
        Args:
            knowledge_base_path: Path to the JSON knowledge base file
                                 JSONçŸ¥è¯†åº“æ–‡ä»¶çš„è·¯å¾„
            model_name: Name or path of the sentence transformer model
                        å¥å­è½¬æ¢å™¨æ¨¡å‹çš„åç§°æˆ–è·¯å¾„
            cache_path: Path to cache embeddings (None to disable caching)
                       ç¼“å­˜åµŒå…¥çš„è·¯å¾„ï¼ˆNoneè¡¨ç¤ºç¦ç”¨ç¼“å­˜ï¼‰
            use_cache: Whether to use cached embeddings
                      æ˜¯å¦ä½¿ç”¨ç¼“å­˜çš„åµŒå…¥
        """
        self.knowledge_base_path = Path(knowledge_base_path)
        self.cache_path = Path(cache_path) if cache_path else None
        self.use_cache = use_cache
        
        # Initialize sentence transformer model
        print(f"Loading sentence transformer model: {model_name}")
        print(f"æ­£åœ¨åŠ è½½å¥å­è½¬æ¢å™¨æ¨¡å‹: {model_name}")
        
        try:
            from sentence_transformers import SentenceTransformer
            
            # Check if local model exists
            model_path = Path(model_name)
            if model_path.exists():
                self.model = SentenceTransformer(str(model_path))
                print(f"âœ“ Loaded local model from: {model_path}")
            else:
                self.model = SentenceTransformer(model_name)
                print(f"âœ“ Loaded model from HuggingFace: {model_name}")
                
        except Exception as e:
            print(f"âŒ Error loading model: {e}")
            print("Please install: pip install sentence-transformers")
            raise
        
        self.knowledge_entries: List[VectorKnowledgeEntry] = []
        self.embeddings_matrix: Optional[np.ndarray] = None
        
        # Load knowledge base and compute embeddings
        self._load_knowledge_base()

    def _load_knowledge_base(self) -> None:
        """
        Load the knowledge base and compute/load embeddings.
        åŠ è½½çŸ¥è¯†åº“å¹¶è®¡ç®—/åŠ è½½åµŒå…¥
        """
        if not self.knowledge_base_path.exists():
            raise FileNotFoundError(
                f"Knowledge base file not found: {self.knowledge_base_path}\n"
                f"çŸ¥è¯†åº“æ–‡ä»¶æœªæ‰¾åˆ°: {self.knowledge_base_path}"
            )

        # Load JSON data
        with open(self.knowledge_base_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        print(f"Loaded {len(data)} knowledge entries from JSON")
        print(f"ä»JSONåŠ è½½äº† {len(data)} ä¸ªçŸ¥è¯†æ¡ç›®")
        
        # Handle empty knowledge base
        # å¤„ç†ç©ºçŸ¥è¯†åº“
        if len(data) == 0:
            print("âš ï¸ Warning: Knowledge base is empty!")
            print("âš ï¸ è­¦å‘Šï¼šçŸ¥è¯†åº“ä¸ºç©ºï¼")
            print("   Please add some rules to the knowledge base or use AI retriever.")
            print("   è¯·å‘çŸ¥è¯†åº“æ·»åŠ è§„åˆ™æˆ–ä½¿ç”¨AIæ£€ç´¢å™¨ã€‚")
            self.knowledge_entries = []
            self.embeddings_matrix = None
            return

        # Check if we can use cached embeddings
        if self.use_cache and self.cache_path and self.cache_path.exists():
            print(f"Loading cached embeddings from: {self.cache_path}")
            print(f"ä»ç¼“å­˜åŠ è½½åµŒå…¥: {self.cache_path}")
            
            try:
                with open(self.cache_path, 'rb') as f:
                    cache_data = pickle.load(f)
                
                # Verify cache validity
                if len(cache_data['entries']) == len(data):
                    self.knowledge_entries = cache_data['entries']
                    self.embeddings_matrix = cache_data['embeddings']
                    print("âœ“ Successfully loaded cached embeddings")
                    print("âœ“ æˆåŠŸåŠ è½½ç¼“å­˜çš„åµŒå…¥")
                    return
                else:
                    print("âš  Cache size mismatch, recomputing embeddings")
                    print("âš  ç¼“å­˜å¤§å°ä¸åŒ¹é…ï¼Œé‡æ–°è®¡ç®—åµŒå…¥")
            except Exception as e:
                print(f"âš  Failed to load cache: {e}")
                print(f"âš  åŠ è½½ç¼“å­˜å¤±è´¥: {e}")

        # Compute embeddings from scratch
        print("Computing embeddings for all knowledge entries...")
        print("æ­£åœ¨ä¸ºæ‰€æœ‰çŸ¥è¯†æ¡ç›®è®¡ç®—åµŒå…¥...")
        
        rules = []
        for entry in data:
            rule_text = entry.get("rule", "")
            category = entry.get("category")
            
            self.knowledge_entries.append(VectorKnowledgeEntry(
                rule=rule_text,
                category=category,
                embedding=None  # Will be filled after batch encoding
            ))
            rules.append(rule_text)
        
        # Batch encode all rules
        embeddings = self.model.encode(
            rules,
            convert_to_numpy=True,
            show_progress_bar=True,
            batch_size=32
        )
        
        # Ensure embeddings is 2D (n_samples, n_features)
        # ç¡®ä¿embeddingsæ˜¯2ç»´çš„ (æ ·æœ¬æ•°, ç‰¹å¾æ•°)
        if embeddings.ndim == 1:
            embeddings = embeddings.reshape(1, -1)
        
        # Store embeddings
        self.embeddings_matrix = embeddings
        for i, entry in enumerate(self.knowledge_entries):
            entry.embedding = embeddings[i]
        
        print(f"âœ“ Computed embeddings with shape: {embeddings.shape}")
        print(f"âœ“ è®¡ç®—å®Œæˆï¼ŒåµŒå…¥å½¢çŠ¶: {embeddings.shape}")
        
        # Cache embeddings
        if self.cache_path:
            self._cache_embeddings()

    def _cache_embeddings(self) -> None:
        """
        Cache embeddings to disk for faster loading.
        å°†åµŒå…¥ç¼“å­˜åˆ°ç£ç›˜ä»¥åŠ å¿«åŠ è½½é€Ÿåº¦
        """
        try:
            self.cache_path.parent.mkdir(parents=True, exist_ok=True)
            
            cache_data = {
                'entries': self.knowledge_entries,
                'embeddings': self.embeddings_matrix
            }
            
            with open(self.cache_path, 'wb') as f:
                pickle.dump(cache_data, f)
            
            print(f"âœ“ Cached embeddings to: {self.cache_path}")
            print(f"âœ“ åµŒå…¥å·²ç¼“å­˜åˆ°: {self.cache_path}")
        except Exception as e:
            print(f"âš  Failed to cache embeddings: {e}")
            print(f"âš  ç¼“å­˜åµŒå…¥å¤±è´¥: {e}")

    def _compute_similarity(
        self,
        query_embedding: np.ndarray,
        top_k: int = 10
    ) -> List[Tuple[int, float]]:
        """
        Compute cosine similarity between query and all knowledge entries.
        è®¡ç®—æŸ¥è¯¢ä¸æ‰€æœ‰çŸ¥è¯†æ¡ç›®ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦
        
        Args:
            query_embedding: The query vector
                            æŸ¥è¯¢å‘é‡
            top_k: Number of top results to return
                   è¿”å›çš„é¡¶éƒ¨ç»“æœæ•°é‡
        
        Returns:
            List of (index, similarity_score) tuples
            (ç´¢å¼•, ç›¸ä¼¼åº¦åˆ†æ•°)å…ƒç»„åˆ—è¡¨
        """
        # Check if knowledge base is empty
        # æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦ä¸ºç©º
        if self.embeddings_matrix is None or len(self.knowledge_entries) == 0:
            print("âš ï¸ Warning: Knowledge base is empty, no results to return")
            print("âš ï¸ è­¦å‘Šï¼šçŸ¥è¯†åº“ä¸ºç©ºï¼Œæ— ç»“æœè¿”å›")
            return []
        
        # Ensure embeddings_matrix is 2D
        # ç¡®ä¿embeddings_matrixæ˜¯2ç»´çš„
        if self.embeddings_matrix.ndim == 1:
            # Single entry, reshape to (1, n)
            # å•æ¡æ•°æ®ï¼Œé‡å¡‘ä¸º(1, n)
            embeddings_2d = self.embeddings_matrix.reshape(1, -1)
        else:
            embeddings_2d = self.embeddings_matrix
        
        # Normalize embeddings for cosine similarity
        query_norm = query_embedding / np.linalg.norm(query_embedding)
        kb_norms = embeddings_2d / np.linalg.norm(
            embeddings_2d, axis=1, keepdims=True
        )
        
        # Compute cosine similarity
        similarities = np.dot(kb_norms, query_norm)
        
        # Limit top_k to actual number of entries
        # é™åˆ¶top_kä¸ºå®é™…æ¡ç›®æ•°
        actual_k = min(top_k, len(self.knowledge_entries))
        
        # Get top-k indices
        top_indices = np.argsort(similarities)[-actual_k:][::-1]
        
        return [(int(idx), float(similarities[idx])) for idx in top_indices]

    def retrieve_knowledge(
        self,
        problem_text: str,
        top_k: int = 5,
        similarity_threshold: float = 0.3
    ) -> List[str]:
        """
        Retrieve relevant knowledge entries using semantic similarity.
        ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢ç›¸å…³çš„çŸ¥è¯†æ¡ç›®
        
        Args:
            problem_text: The problem statement
                          é—®é¢˜é™ˆè¿°
            top_k: Maximum number of results to return
                   è¿”å›çš„æœ€å¤§ç»“æœæ•°é‡
            similarity_threshold: Minimum similarity score (0-1)
                                 æœ€å°ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0-1ï¼‰
        
        Returns:
            List of relevant rule descriptions
            ç›¸å…³è§„åˆ™æè¿°çš„åˆ—è¡¨
        """
        if not problem_text.strip():
            print("Warning: Empty problem text provided")
            print("è­¦å‘Šï¼šæä¾›äº†ç©ºçš„é—®é¢˜æ–‡æœ¬")
            return []
        
        # Encode the query
        print(f"\nğŸ” Encoding query: {problem_text[:100]}...")
        query_embedding = self.model.encode(
            problem_text,
            convert_to_numpy=True
        )
        
        # Find similar entries
        similar_entries = self._compute_similarity(query_embedding, top_k=top_k)
        
        # Filter by threshold and extract rules
        retrieved_rules = []
        print(f"\nğŸ“Š Top {top_k} similar knowledge entries:")
        print(f"ğŸ“Š æœ€ç›¸ä¼¼çš„ {top_k} ä¸ªçŸ¥è¯†æ¡ç›®:")
        
        for idx, similarity in similar_entries:
            if similarity >= similarity_threshold:
                entry = self.knowledge_entries[idx]
                retrieved_rules.append(entry.rule)
                
                # Print similarity info
                category_str = f"[{entry.category}]" if entry.category else ""
                print(f"  {len(retrieved_rules)}. {category_str} Similarity: {similarity:.3f}")
                print(f"     {entry.rule[:80]}...")
            else:
                print(f"  âœ— Similarity {similarity:.3f} below threshold {similarity_threshold}")
                break
        
        print(f"\nâœ“ Retrieved {len(retrieved_rules)} relevant rules (threshold: {similarity_threshold})")
        print(f"âœ“ æ£€ç´¢åˆ° {len(retrieved_rules)} æ¡ç›¸å…³è§„åˆ™ï¼ˆé˜ˆå€¼: {similarity_threshold})")
        
        return retrieved_rules

    def retrieve_with_scores(
        self,
        problem_text: str,
        top_k: int = 5,
        similarity_threshold: float = 0.3
    ) -> List[Tuple[str, float, Optional[str]]]:
        """
        Retrieve knowledge with similarity scores.
        æ£€ç´¢çŸ¥è¯†å¹¶è¿”å›ç›¸ä¼¼åº¦åˆ†æ•°
        
        Args:
            problem_text: The problem statement
            top_k: Maximum number of results
            similarity_threshold: Minimum similarity score
        
        Returns:
            List of (rule, score, category) tuples
            (è§„åˆ™, åˆ†æ•°, ç±»åˆ«)å…ƒç»„åˆ—è¡¨
        """
        if not problem_text.strip():
            return []
        
        query_embedding = self.model.encode(problem_text, convert_to_numpy=True)
        similar_entries = self._compute_similarity(query_embedding, top_k=top_k)
        
        results = []
        for idx, similarity in similar_entries:
            if similarity >= similarity_threshold:
                entry = self.knowledge_entries[idx]
                results.append((entry.rule, similarity, entry.category))
        
        return results

    def get_knowledge(self, problem_text: str) -> List[str]:
        """
        Main interface for knowledge retrieval (compatible with old API).
        çŸ¥è¯†æ£€ç´¢çš„ä¸»æ¥å£ï¼ˆä¸æ—§APIå…¼å®¹ï¼‰
        
        Args:
            problem_text: The problem statement
                          é—®é¢˜é™ˆè¿°
        
        Returns:
            List of relevant rule descriptions
            ç›¸å…³è§„åˆ™æè¿°çš„åˆ—è¡¨
        """
        return self.retrieve_knowledge(
            problem_text,
            top_k=5,
            similarity_threshold=0.3
        )

    def add_knowledge(
        self,
        rule: str,
        category: Optional[str] = None,
        save_to_disk: bool = True
    ) -> None:
        """
        Add a new knowledge entry and compute its embedding.
        æ·»åŠ æ–°çš„çŸ¥è¯†æ¡ç›®å¹¶è®¡ç®—å…¶åµŒå…¥
        
        Args:
            rule: The rule or formula description
                  è§„åˆ™æˆ–å…¬å¼æè¿°
            category: Optional category label
                      å¯é€‰çš„åˆ†ç±»æ ‡ç­¾
            save_to_disk: Whether to save to JSON file
                         æ˜¯å¦ä¿å­˜åˆ°JSONæ–‡ä»¶
        """
        # Compute embedding for new rule
        embedding = self.model.encode(rule, convert_to_numpy=True)
        
        # Create new entry
        new_entry = VectorKnowledgeEntry(
            rule=rule,
            category=category,
            embedding=embedding
        )
        
        self.knowledge_entries.append(new_entry)
        
        # Update embeddings matrix
        if self.embeddings_matrix is not None:
            self.embeddings_matrix = np.vstack([self.embeddings_matrix, embedding])
        else:
            self.embeddings_matrix = embedding.reshape(1, -1)
        
        print(f"âœ“ Added new knowledge entry with embedding")
        print(f"âœ“ å·²æ·»åŠ æ–°çŸ¥è¯†æ¡ç›®å¹¶è®¡ç®—åµŒå…¥")
        
        # Optionally save to disk
        if save_to_disk:
            self.save_knowledge_base()
            if self.cache_path:
                self._cache_embeddings()

    def save_knowledge_base(self) -> None:
        """
        Save the current knowledge base back to JSON file.
        å°†å½“å‰çŸ¥è¯†åº“ä¿å­˜å›JSONæ–‡ä»¶
        """
        data = [
            {
                "rule": entry.rule,
                "category": entry.category
            }
            for entry in self.knowledge_entries
        ]
        
        self.knowledge_base_path.parent.mkdir(parents=True, exist_ok=True)
        with open(self.knowledge_base_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ“ Knowledge base saved to {self.knowledge_base_path}")
        print(f"âœ“ çŸ¥è¯†åº“å·²ä¿å­˜åˆ° {self.knowledge_base_path}")

    def search_by_category(self, category: str, top_k: int = 5) -> List[str]:
        """
        Get knowledge entries by category.
        æŒ‰ç±»åˆ«è·å–çŸ¥è¯†æ¡ç›®
        
        Args:
            category: Category name
            top_k: Maximum number of results
        
        Returns:
            List of rules in the category
        """
        results = [
            entry.rule for entry in self.knowledge_entries
            if entry.category == category
        ][:top_k]
        
        return results


# Example usage / ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("="*80)
    print("Vector-based Knowledge Retriever Test")
    print("="*80 + "\n")
    
    # Initialize retriever with local model
    retriever = VectorKnowledgeRetriever(
        knowledge_base_path="data/knowledge_base.json",
        model_name="all-MiniLM-L6-v2",  # Will use local model if exists
        cache_path="data/knowledge_embeddings.pkl",
        use_cache=True
    )
    
    # Test problems
    test_problems = [
        """
        An object with a mass of 10 kg is initially at rest.
        A constant force of 50 Newtons is applied to it for 5 seconds.
        What is its final velocity?
        """,
        """
        A projectile is launched at an angle of 45 degrees with initial velocity 20 m/s.
        What is the maximum height reached?
        """,
        """
        Calculate the area of a circle with radius 5 meters.
        """
    ]
    
    for i, problem in enumerate(test_problems, 1):
        print(f"\n{'='*80}")
        print(f"Test Problem {i}:")
        print(f"{'='*80}")
        print(problem.strip())
        
        # Retrieve knowledge with scores
        results = retriever.retrieve_with_scores(
            problem,
            top_k=3,
            similarity_threshold=0.2
        )
        
        print(f"\nğŸ“š Retrieved Knowledge:")
        for j, (rule, score, category) in enumerate(results, 1):
            cat_str = f"[{category}]" if category else ""
            print(f"\n{j}. {cat_str} (Score: {score:.3f})")
            print(f"   {rule}")

