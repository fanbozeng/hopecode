"""
Causal Scaffolding Module
å› æœè„šæ‰‹æ¶æ¨¡å—

This module translates unstructured problem text into a structured JSON plan
representing a Structural Causal Model (SCM). It uses LLM prompts to guide
the planning process.

æœ¬æ¨¡å—å°†éç»“æ„åŒ–çš„é—®é¢˜æ–‡æœ¬è½¬æ¢ä¸ºè¡¨ç¤ºç»“æ„å› æœæ¨¡å‹ï¼ˆSCMï¼‰çš„ç»“æ„åŒ–JSONè®¡åˆ’ã€‚
å®ƒä½¿ç”¨LLMæç¤ºè¯æ¥æŒ‡å¯¼è§„åˆ’è¿‡ç¨‹ã€‚
"""

import json
import os
import re
import time  # æ–°å¢ï¼šç”¨äºé‡è¯•å»¶è¿Ÿ / Added: for retry delay
from typing import Dict, List, Optional, Any
from pathlib import Path
from dotenv import load_dotenv


class LLMClient:
    """
    Unified LLM client supporting multiple API providers.
    æ”¯æŒå¤šä¸ªAPIæä¾›å•†çš„ç»Ÿä¸€LLMå®¢æˆ·ç«¯
    """

    def __init__(self, provider: Optional[str] = None):
        """
        Initialize LLM client.
        åˆå§‹åŒ–LLMå®¢æˆ·ç«¯

        Args:
            provider: API provider name ('siliconflow', 'openai', 'anthropic')
                      APIæä¾›å•†åç§°ï¼ˆ'siliconflow'ã€'openai'ã€'anthropic'ï¼‰
        """
        load_dotenv()

        self.provider = provider or os.getenv("DEFAULT_PROVIDER", "siliconflow")

        if self.provider == "siliconflow":
            self._init_siliconflow()
        elif self.provider == "openai":
            self._init_openai()
        elif self.provider == "anthropic":
            self._init_anthropic()
        else:
            raise ValueError(f"Unsupported provider: {self.provider}")

    def _init_siliconflow(self):
        """Initialize SiliconFlow client / åˆå§‹åŒ–SiliconFlowå®¢æˆ·ç«¯"""
        from openai import OpenAI

        api_key = os.getenv("SILICONFLOW_API_KEY")
        api_base = os.getenv("SILICONFLOW_API_BASE", "https://api.siliconflow.cn/v1")
        self.model = os.getenv("SILICONFLOW_MODEL", "Qwen/Qwen2.5-72B-Instruct")

        self.client = OpenAI(api_key=api_key, base_url=api_base)
        print(f"Initialized SiliconFlow client with model: {self.model}")
        print(f"å·²åˆå§‹åŒ–SiliconFlowå®¢æˆ·ç«¯ï¼Œæ¨¡å‹: {self.model}")

    def _init_openai(self):
        """Initialize OpenAI client / åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        from openai import OpenAI

        api_key = os.getenv("OPENAI_API_KEY")
        self.model = os.getenv("OPENAI_MODEL", "gpt-4")

        self.client = OpenAI(api_key=api_key)
        print(f"Initialized OpenAI client with model: {self.model}")
        print(f"å·²åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼Œæ¨¡å‹: {self.model}")

    def _init_anthropic(self):
        """Initialize Anthropic client / åˆå§‹åŒ–Anthropicå®¢æˆ·ç«¯"""
        from anthropic import Anthropic

        api_key = os.getenv("ANTHROPIC_API_KEY")
        self.model = os.getenv("ANTHROPIC_MODEL", "claude-3-opus-20240229")

        self.client = Anthropic(api_key=api_key)
        print(f"Initialized Anthropic client with model: {self.model}")
        print(f"å·²åˆå§‹åŒ–Anthropicå®¢æˆ·ç«¯ï¼Œæ¨¡å‹: {self.model}")

    def complete(self, prompt: str, temperature: float = 0.0) -> str:
        """
        Generate completion using the configured LLM.
        ä½¿ç”¨é…ç½®çš„LLMç”Ÿæˆè¡¥å…¨

        Args:
            prompt: The input prompt
                    è¾“å…¥æç¤ºè¯
            temperature: Sampling temperature (0.0 for deterministic)
                         é‡‡æ ·æ¸©åº¦ï¼ˆ0.0è¡¨ç¤ºç¡®å®šæ€§è¾“å‡ºï¼‰

        Returns:
            Generated text completion
            ç”Ÿæˆçš„æ–‡æœ¬è¡¥å…¨
        """
        if self.provider in ["siliconflow", "openai"]:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=temperature
            )
            return response.choices[0].message.content

        elif self.provider == "anthropic":
            response = self.client.messages.create(
                model=self.model,
                max_tokens=4096,
                temperature=temperature,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text

        else:
            raise ValueError(f"Unsupported provider: {self.provider}")


class CausalScaffolder:
    """
    Causal Scaffolding Engine that generates structured problem-solving plans.
    ç”Ÿæˆç»“æ„åŒ–é—®é¢˜è§£å†³è®¡åˆ’çš„å› æœè„šæ‰‹æ¶å¼•æ“

    This class uses LLM prompts to convert natural language problems into
    JSON representations of Structural Causal Models.

    æ­¤ç±»ä½¿ç”¨LLMæç¤ºè¯å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸ºç»“æ„å› æœæ¨¡å‹çš„JSONè¡¨ç¤ºã€‚
    """

    def __init__(
        self,
        llm_client: Optional[LLMClient] = None,
        prompt_template_path: str = "prompts/scaffolding_prompt_v3.txt",
        max_retries: int = 3,  # æ–°å¢ï¼šæœ€å¤§é‡è¯•æ¬¡æ•° / Added: max retry attempts
        retry_delay: float = 2.0  # æ–°å¢ï¼šé‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰/ Added: retry delay in seconds
    ):
        """
        Initialize the causal scaffolder.
        åˆå§‹åŒ–å› æœè„šæ‰‹æ¶å™¨

        Args:
            llm_client: LLM client instance (creates default if None)
                        LLMå®¢æˆ·ç«¯å®ä¾‹ï¼ˆå¦‚æœä¸ºNoneåˆ™åˆ›å»ºé»˜è®¤å®ä¾‹ï¼‰
            prompt_template_path: Path to the scaffolding prompt template
                                  è„šæ‰‹æ¶æç¤ºè¯æ¨¡æ¿çš„è·¯å¾„
            max_retries: Maximum number of retry attempts for timeout/errors
                        è¶…æ—¶/é”™è¯¯æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°
            retry_delay: Delay in seconds between retries
                        é‡è¯•ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰
        """
        self.llm_client = llm_client or LLMClient()
        self.prompt_template_path = Path(prompt_template_path)
        self.prompt_template = self._load_prompt_template()
        self.max_retries = max_retries  # æ–°å¢ / Added
        self.retry_delay = retry_delay  # æ–°å¢ / Added
        self.timeout_log = []  # æ–°å¢ï¼šè®°å½•è¶…æ—¶çš„é—®é¢˜ / Added: log timeout problems

    def _load_prompt_template(self) -> str:
        """
        Load the scaffolding prompt template from file.
        

        Returns:
            The prompt template string
            
        """
        # Try relative path first
        if self.prompt_template_path.exists():
            with open(self.prompt_template_path, 'r', encoding='utf-8') as f:
                return f.read()
        
        # Try absolute path from project root
        project_root = Path(__file__).parent.parent
        absolute_path = project_root / self.prompt_template_path
        
        if absolute_path.exists():
            with open(absolute_path, 'r', encoding='utf-8') as f:
                return f.read()
        
        # If file not found, raise error (no fallback)
        raise FileNotFoundError(
            f"Prompt template not found at:\n"
            f"  - Relative path: {self.prompt_template_path}\n"
            f"  - Absolute path: {absolute_path}\n"
            f"Please ensure 'prompts/scaffolding_prompt_v3.txt' exists in project root."
        )

    def generate_scaffold(
        self,
        problem_text: str,
        retrieved_knowledge: List[str],
        experiences: Optional[List[str]] = None
    ) -> Optional[Dict[str, Any]]:
        """
        Generate a structured causal scaffold from problem text with retry mechanism.
        ä½¿ç”¨é‡è¯•æœºåˆ¶ä»é—®é¢˜æ–‡æœ¬ç”Ÿæˆç»“æ„åŒ–å› æœè„šæ‰‹æ¶

        This method constructs a prompt with the problem and retrieved knowledge,
        sends it to the LLM, and parses the JSON response. If timeout or errors occur,
        it will retry up to max_retries times.

        æ­¤æ–¹æ³•æ„é€ åŒ…å«é—®é¢˜å’Œæ£€ç´¢çŸ¥è¯†çš„æç¤ºè¯ï¼Œå‘é€ç»™ LLM å¹¶è§£æ JSON å“åº”ã€‚
        å¦‚æœå‘ç”Ÿè¶…æ—¶æˆ–é”™è¯¯ï¼Œå°†é‡è¯•æœ€å¤š max_retries æ¬¡ã€‚

        Args:
            problem_text: The problem statement
                          é—®é¢˜é™ˆè¿°
            retrieved_knowledge: List of relevant formulas and rules (from RAG)
                                 ç›¸å…³å…¬å¼å’Œè§„åˆ™åˆ—è¡¨ï¼ˆæ¥è‡ªRAGï¼‰
            experiences: List of prior experiences (from GRPO training)
                        å…ˆå‰çš„ç»éªŒåˆ—è¡¨ï¼ˆæ¥è‡ªGRPOè®­ç»ƒï¼‰

        Returns:
            Parsed JSON scaffold as a dictionary, or None if all retries fail
            è§£æçš„ JSON è„šæ‰‹æ¶å­—å…¸ï¼Œå¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥åˆ™è¿”å› None
        """
        # Format knowledge as a numbered list
        # æ ¼å¼åŒ–çŸ¥è¯†ä¸ºç¼–å·åˆ—è¡¨
        knowledge_str = "\n".join(
            f"{i}. {rule}" for i, rule in enumerate(retrieved_knowledge, 1)
        ) if retrieved_knowledge else "No additional knowledge provided."
        
        # Format experiences as a numbered list
        # æ ¼å¼åŒ–ç»éªŒä¸ºç¼–å·åˆ—è¡¨
        if experiences is None:
            experiences = []
        experiences_str = "\n".join(
            f"{i}. {exp}" for i, exp in enumerate(experiences, 1)
        ) if experiences else "No prior experiences available."

        # Construct the full prompt
        # æ„é€ å®Œæ•´çš„æç¤ºè¯
        prompt = self.prompt_template.format(
            retrieved_knowledge=knowledge_str,
            prior_experiences=experiences_str,
            problem_text=problem_text
        )

        print("Generating causal scaffold...")
        print("ç”Ÿæˆå› æœè„šæ‰‹æ¶...")

        # Retry loop / é‡è¯•å¾ªç¯
        for attempt in range(1, self.max_retries + 1):
            try:
                # Print attempt info / æ‰“å°å°è¯•ä¿¡æ¯
                if attempt > 1:
                    print(f"\nğŸ”„ Retry attempt {attempt}/{self.max_retries}")
                    print(f"ğŸ”„ é‡è¯•ç¬¬ {attempt}/{self.max_retries} æ¬¡")
                    time.sleep(self.retry_delay)  # Wait before retry / é‡è¯•å‰ç­‰å¾…

                print(f"Calling LLM (attempt {attempt})...")
                print(f"è°ƒç”¨ LLMï¼ˆç¬¬ {attempt} æ¬¡å°è¯•ï¼‰...")

                # Call LLM with timeout handling / è°ƒç”¨ LLM å¹¶å¤„ç†è¶…æ—¶
                response = self.llm_client.complete(prompt, temperature=0.0)

                print(f"âœ“ LLM response received ({len(response)} characters)")
                print(f"âœ“ å·²æ”¶åˆ° LLM å“åº”ï¼ˆ{len(response)} å­—ç¬¦ï¼‰")
                print("\n" + "="*80)
                print("LLM Response Preview (first 500 chars):")
                print("LLM å“åº”é¢„è§ˆï¼ˆå‰ 500 å­—ç¬¦ï¼‰:")
                print("="*80)
                print(response)
                print("="*80 + "\n")

                # Extract JSON from response / ä»å“åº”ä¸­æå– JSON
                scaffold = self._extract_json(response)

                if scaffold:
                    print("[OK] Successfully generated causal scaffold.")
                    print("[OK] æˆåŠŸç”Ÿæˆå› æœè„šæ‰‹æ¶")
                    print(f"  Target variable: {scaffold.get('target_variable')}")
                    print(f"  ç›®æ ‡å˜é‡: {scaffold.get('target_variable')}")
                    print(f"  Knowns: {list(scaffold.get('knowns', {}).keys())}")
                    print(f"  å·²çŸ¥é‡: {list(scaffold.get('knowns', {}).keys())}")
                    return scaffold
                else:
                    # Failed to parse JSON, but might retry / è§£æ JSON å¤±è´¥ï¼Œä½†å¯èƒ½é‡è¯•
                    print(f"\nâš  Failed to parse JSON (attempt {attempt}/{self.max_retries})")
                    print(f"âš  è§£æ JSON å¤±è´¥ï¼ˆç¬¬ {attempt}/{self.max_retries} æ¬¡å°è¯•ï¼‰")

                    if attempt < self.max_retries:
                        print(f"Will retry in {self.retry_delay} seconds...")
                        print(f"å°†åœ¨ {self.retry_delay} ç§’åé‡è¯•...")
                        continue
                    else:
                        print("\nâŒ All retry attempts exhausted for JSON parsing.")
                        print("âŒ JSON è§£æçš„æ‰€æœ‰é‡è¯•æ¬¡æ•°å·²ç”¨å°½")
                        print("\nFull LLM response:")
                        print("å®Œæ•´ LLM å“åº”:")
                        print("="*80)
                        print(response)
                        print("="*80)

            except TimeoutError as e:
                # Timeout error - retry / è¶…æ—¶é”™è¯¯ - é‡è¯•
                print(f"\nâ± Timeout error on attempt {attempt}/{self.max_retries}: {e}")
                print(f"â± ç¬¬ {attempt}/{self.max_retries} æ¬¡å°è¯•è¶…æ—¶: {e}")

                if attempt < self.max_retries:
                    print(f"Retrying in {self.retry_delay} seconds...")
                    print(f"å°†åœ¨ {self.retry_delay} ç§’åé‡è¯•...")
                else:
                    # Log timeout problem / è®°å½•è¶…æ—¶é—®é¢˜
                    timeout_entry = {
                        'problem_text': problem_text[:200] + '...' if len(problem_text) > 200 else problem_text,
                        'attempts': self.max_retries,
                        'error': 'Timeout',
                        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
                    }
                    self.timeout_log.append(timeout_entry)

                    print(f"\nâŒ TIMEOUT: Failed after {self.max_retries} attempts.")
                    print(f"âŒ è¶…æ—¶: {self.max_retries} æ¬¡å°è¯•åå¤±è´¥")
                    print(f"Problem logged to timeout_log (total: {len(self.timeout_log)} timeouts)")
                    print(f"é—®é¢˜å·²è®°å½•åˆ° timeout_logï¼ˆæ€»è®¡: {len(self.timeout_log)} ä¸ªè¶…æ—¶ï¼‰")

            except Exception as e:
                # Other errors - retry / å…¶ä»–é”™è¯¯ - é‡è¯•
                error_type = type(e).__name__
                print(f"\nâ— Error on attempt {attempt}/{self.max_retries} ({error_type}): {e}")
                print(f"â— ç¬¬ {attempt}/{self.max_retries} æ¬¡å°è¯•å‡ºé”™ï¼ˆ{error_type}ï¼‰: {e}")

                if attempt < self.max_retries:
                    print(f"Retrying in {self.retry_delay} seconds...")
                    print(f"å°†åœ¨ {self.retry_delay} ç§’åé‡è¯•...")
                else:
                    # Log error problem / è®°å½•é”™è¯¯é—®é¢˜
                    error_entry = {
                        'problem_text': problem_text[:200] + '...' if len(problem_text) > 200 else problem_text,
                        'attempts': self.max_retries,
                        'error': f'{error_type}: {str(e)}',
                        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
                    }
                    self.timeout_log.append(error_entry)

                    print(f"\nâŒ ERROR: Failed after {self.max_retries} attempts.")
                    print(f"âŒ é”™è¯¯: {self.max_retries} æ¬¡å°è¯•åå¤±è´¥")
                    print(f"Problem logged to timeout_log (total: {len(self.timeout_log)} errors)")
                    print(f"é—®é¢˜å·²è®°å½•åˆ° timeout_logï¼ˆæ€»è®¡: {len(self.timeout_log)} ä¸ªé”™è¯¯ï¼‰")

                    import traceback
                    print("\nFull traceback:")
                    print("å®Œæ•´é”™è¯¯è¿½è¸ª:")
                    traceback.print_exc()

        # All retries failed / æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
        return None

    def _extract_json(self, text: str) -> Optional[Dict[str, Any]]:
        """
        Extract and parse JSON from LLM response text.
         LLM  JSON

        Args:
            text: LLM response text that may contain JSON
                   JSON  LLM

        Returns:
            Parsed JSON as dictionary, or None if extraction fails
             JSON  None
        """
        print("Extracting JSON from response...")

        # Try to find JSON code block
        #  JSON
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)

        if json_match:
            json_str = json_match.group(1)
            print("  Found JSON in code block (```json...```)")
        else:
            # Try to find raw JSON object
            #  JSON
            json_match = re.search(r'\{.*\}', text, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                print("  Found raw JSON object")
            else:
                print("  âŒ No JSON found in response!")
                print("  âŒ JSONï¼")
                return None

        # Preprocess: Fix Python-style fractions to string format (preserve precision)
        # é¢„å¤„ç†ï¼šå°†Pythoné£æ ¼çš„åˆ†æ•°è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼ˆä¿ç•™ç²¾åº¦ï¼‰
        print("  Preprocessing: Converting fractions to string format (e.g., 1/3 â†’ \"1/3\")...")
        
        # Convert patterns like `: 1/3,` to `: "1/3",` to keep precision
        # å°† `: 1/3,` è½¬æ¢ä¸º `: "1/3",` ä»¥ä¿ç•™ç²¾åº¦
        original_json = json_str
        json_str = re.sub(r':\s*(\d+)/(\d+)(\s*[,\}])', r': "\1/\2"\3', json_str)
        json_str = re.sub(r'\[\s*(\d+)/(\d+)(\s*[,\]])', r'["\1/\2"\3', json_str)
        json_str = re.sub(r',\s*(\d+)/(\d+)(\s*[,\]\}])', r', "\1/\2"\3', json_str)
        
        if json_str != original_json:
            print("  âœ“ Converted Python-style fractions to JSON strings")

        # Parse JSON
        #  JSON
        try:
            print(f"  Parsing JSON ({len(json_str)} characters)...")
            result = json.loads(json_str)
            print("  âœ“ JSON parsed successfully")

            # Check if the result has a "problem_analysis" wrapper and unwrap it
            # æ£€æŸ¥ç»“æœæ˜¯å¦æœ‰ "problem_analysis" åŒ…è£…ï¼Œå¦‚æœæœ‰åˆ™è§£åŒ…
            if isinstance(result, dict) and "problem_analysis" in result:
                print("  ğŸ“¦ Detected 'problem_analysis' wrapper, unwrapping...")
                print("  ğŸ“¦ æ£€æµ‹åˆ° 'problem_analysis' åŒ…è£…ï¼Œæ­£åœ¨è§£åŒ…...")
                result = result["problem_analysis"]

            return result
        except json.JSONDecodeError as e:
            print(f"\nâŒ JSON parsing error: {e}")
            print(f"âŒ JSON : {e}")
            print(f"  Error at line {e.lineno}, column {e.colno}")
            print(f"  : {e.lineno}ï¼Œ{e.colno}")
            print("\nProblematic JSON (first 1000 chars):")
            print("="*80)
            print(json_str[:1000])
            print("="*80)
            return None

    def validate_scaffold(self, scaffold: Dict[str, Any]) -> bool:
        """
        Validate the structure of a generated scaffold.
        éªŒè¯ç”Ÿæˆçš„è„šæ‰‹æ¶ç»“æ„

        Args:
            scaffold: The scaffold dictionary to validate
                      è¦éªŒè¯çš„è„šæ‰‹æ¶å­—å…¸

        Returns:
            True if valid, False otherwise
            æœ‰æ•ˆåˆ™è¿”å› Trueï¼Œå¦åˆ™è¿”å› False
        """
        required_keys = ["target_variable", "knowns", "causal_graph", "computation_plan"]

        # Check required keys
        # æ£€æŸ¥å¿…éœ€çš„é”®
        if not all(key in scaffold for key in required_keys):
            print("Missing required keys in scaffold.")
            print("è„šæ‰‹æ¶ä¸­ç¼ºå°‘å¿…éœ€çš„é”®")
            return False

        # Validate causal_graph structure
        # éªŒè¯ causal_graph ç»“æ„
        for link in scaffold.get("causal_graph", []):
            if not all(key in link for key in ["cause", "effect", "rule"]):
                print("Invalid causal_graph structure.")
                print("causal_graph ç»“æ„æ— æ•ˆ")
                return False

        # Validate computation_plan structure
        # éªŒè¯ computation_plan ç»“æ„
        for step in scaffold.get("computation_plan", []):
            # New schema: only requires id, target, inputs, description
            # æ–°schemaï¼šåªéœ€è¦ id, target, inputs, description
            required_step_keys = ["id", "target", "inputs", "description"]
            if not all(key in step for key in required_step_keys):
                print(f"Invalid computation_plan structure. Missing keys in step: {step}")
                print(f"computation_plan ç»“æ„æ— æ•ˆã€‚æ­¥éª¤ä¸­ç¼ºå°‘é”®: {step}")
                print(f"Required keys: {required_step_keys}")
                print(f"å¿…éœ€çš„é”®: {required_step_keys}")
                return False

        print("Scaffold validation passed.")
        print("è„šæ‰‹æ¶éªŒè¯é€šè¿‡")
        return True

    def get_timeout_log(self) -> List[Dict[str, Any]]:
        """
        Get the timeout/error log.
        è·å–è¶…æ—¶/é”™è¯¯æ—¥å¿—

        Returns:
            List of timeout/error entries
            è¶…æ—¶/é”™è¯¯æ¡ç›®åˆ—è¡¨
        """
        return self.timeout_log

    def save_timeout_log(self, output_path: str = "timeout_log.json") -> None:
        """
        Save timeout/error log to a JSON file.
        å°†è¶…æ—¶/é”™è¯¯æ—¥å¿—ä¿å­˜åˆ° JSON æ–‡ä»¶

        Args:
            output_path: Path to save the log file
                        ä¿å­˜æ—¥å¿—æ–‡ä»¶çš„è·¯å¾„
        """
        if not self.timeout_log:
            print("No timeout/error logs to save.")
            print("æ²¡æœ‰è¶…æ—¶/é”™è¯¯æ—¥å¿—éœ€è¦ä¿å­˜")
            return

        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        log_data = {
            'total_timeouts': len(self.timeout_log),
            'generated_at': time.strftime('%Y-%m-%d %H:%M:%S'),
            'entries': self.timeout_log
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(log_data, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ“ Timeout log saved to: {output_file}")
        print(f"ğŸ“ è¶…æ—¶æ—¥å¿—å·²ä¿å­˜åˆ°: {output_file}")
        print(f"   Total entries: {len(self.timeout_log)}")
        print(f"   æ€»æ¡ç›®æ•°: {len(self.timeout_log)}")

    def print_timeout_summary(self) -> None:
        """
        Print a summary of timeout/error statistics.
        æ‰“å°è¶…æ—¶/é”™è¯¯ç»Ÿè®¡æ‘˜è¦
        """
        if not self.timeout_log:
            print("\nâœ“ No timeouts or errors occurred.")
            print("âœ“ æœªå‘ç”Ÿè¶…æ—¶æˆ–é”™è¯¯")
            return

        print(f"\n{'='*80}")
        print(f"Timeout/Error Summary / è¶…æ—¶/é”™è¯¯æ‘˜è¦")
        print(f"{'='*80}")
        print(f"Total problems failed: {len(self.timeout_log)}")
        print(f"å¤±è´¥é—®é¢˜æ€»æ•°: {len(self.timeout_log)}")

        # Count error types
        # ç»Ÿè®¡é”™è¯¯ç±»å‹
        error_types = {}
        for entry in self.timeout_log:
            error = entry['error']
            error_types[error] = error_types.get(error, 0) + 1

        print(f"\nError types / é”™è¯¯ç±»å‹:")
        for error_type, count in error_types.items():
            print(f"  {error_type}: {count}")

        print(f"\nRecent failures / æœ€è¿‘çš„å¤±è´¥:")
        for i, entry in enumerate(self.timeout_log[-5:], 1):
            print(f"  {i}. [{entry['timestamp']}] {entry['error']}")
            print(f"     Problem: {entry['problem_text'][:100]}...")

        print(f"{'='*80}\n")



# Example usage / 
if __name__ == "__main__":
    # Initialize scaffolder / 
    scaffolder = CausalScaffolder()

    # Test problem / 
    problem = """
    An object with a mass of 10 kg is initially at rest.
    A constant force of 50 Newtons is applied to it for 5 seconds.
    What is its final velocity?
    """

    # Mock retrieved knowledge / 
    knowledge = [
        "Newton's Second Law: Force equals mass times acceleration (F=ma).",
        "Kinematic Equation: Final velocity equals initial velocity plus acceleration multiplied by time (v_f = v_i + a*t)."
    ]

    # Generate scaffold / 
    scaffold = scaffolder.generate_scaffold(
        problem_text=problem,
        retrieved_knowledge=knowledge,
        experiences=[]  # No experiences in test
    )

    if scaffold:
        print("\n--- Generated Scaffold ---")
        print(json.dumps(scaffold, indent=2, ensure_ascii=False))

        # Validate / 
        is_valid = scaffolder.validate_scaffold(scaffold)
        print(f"\nValidation result: {is_valid}")
        print(f": {is_valid}")
