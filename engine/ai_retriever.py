"""
AI-based Knowledge Retriever Module
åŸºäºŽAIçš„çŸ¥è¯†æ£€ç´¢æ¨¡å—

This module uses Large Language Models to dynamically generate relevant
formulas, principles, and domain knowledge based on problem context,
replacing traditional database retrieval.

æœ¬æ¨¡å—ä½¿ç”¨å¤§è¯­è¨€æ¨¡åž‹æ ¹æ®é—®é¢˜ä¸Šä¸‹æ–‡åŠ¨æ€ç”Ÿæˆç›¸å…³çš„å…¬å¼ã€åŽŸç†å’Œé¢†åŸŸçŸ¥è¯†ï¼Œ
å–ä»£ä¼ ç»Ÿçš„æ•°æ®åº“æ£€ç´¢æ–¹å¼ã€‚
"""

import json
import re
from pathlib import Path
from typing import List, Optional, Dict, Any
from dataclasses import dataclass
from enum import Enum


class RuleFormat(Enum):
    """
    Output format for generated rules.
    ç”Ÿæˆè§„åˆ™çš„è¾“å‡ºæ ¼å¼
    """
    SIMPLE_LIST = "simple_list"  # Plain text list / çº¯æ–‡æœ¬åˆ—è¡¨
    STRUCTURED_JSON = "structured_json"  # JSON with metadata / å¸¦å…ƒæ•°æ®çš„JSON


@dataclass
class KnowledgeRule:
    """
    Structured representation of a knowledge rule.
    çŸ¥è¯†è§„åˆ™çš„ç»“æž„åŒ–è¡¨ç¤º

    Attributes:
        rule: The formula or principle description
              å…¬å¼æˆ–åŽŸç†çš„æè¿°
        category: Domain category (e.g., 'mechanics', 'mathematics')
                  é¢†åŸŸåˆ†ç±»ï¼ˆä¾‹å¦‚ï¼š'mechanics'åŠ›å­¦, 'mathematics'æ•°å­¦ï¼‰
        confidence: Confidence score (0.0-1.0) if available
                    ç½®ä¿¡åº¦åˆ†æ•°ï¼ˆ0.0-1.0ï¼‰ï¼Œå¦‚æžœå¯ç”¨
        explanation: Additional context or usage notes
                     é¢å¤–çš„ä¸Šä¸‹æ–‡æˆ–ä½¿ç”¨è¯´æ˜Ž
    """
    rule: str
    category: Optional[str] = None
    confidence: Optional[float] = None
    explanation: Optional[str] = None


class AIKnowledgeRetriever:
    """
    AI-powered Knowledge Retriever for dynamic rule generation.
    åŸºäºŽAIçš„åŠ¨æ€è§„åˆ™ç”ŸæˆçŸ¥è¯†æ£€ç´¢å™¨

    This class uses an LLM to analyze problem statements and generate
    contextually relevant formulas, laws, and principles on-the-fly,
    providing more flexibility than static knowledge bases.

    æ­¤ç±»ä½¿ç”¨LLMåˆ†æžé—®é¢˜é™ˆè¿°ï¼Œå¹¶å³æ—¶ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³çš„å…¬å¼ã€å®šå¾‹å’ŒåŽŸç†ï¼Œ
    æä¾›æ¯”é™æ€çŸ¥è¯†åº“æ›´å¤§çš„çµæ´»æ€§ã€‚

    Key Features / å…³é”®ç‰¹æ€§:
    - Dynamic rule generation / åŠ¨æ€è§„åˆ™ç”Ÿæˆ
    - Context-aware knowledge extraction / ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„çŸ¥è¯†æå–
    - Customizable prompts / å¯è‡ªå®šä¹‰æç¤ºè¯
    - Multiple output formats / å¤šç§è¾“å‡ºæ ¼å¼
    - Fallback strategies / é™çº§ç­–ç•¥
    """

    def __init__(
        self,
        llm_client: Optional['LLMClient'] = None,
        prompt_template_path: Optional[str] = "prompts/knowledge_extraction_prompt.txt",
        fallback_retriever: Optional['KnowledgeRetriever'] = None,
        knowledge_base_path: Optional[str] = "data/knowledge_base.json",
        auto_enrich_kb: bool = False,
        max_rules: int = 5,
        temperature: float = 0.3,
        output_format: RuleFormat = RuleFormat.SIMPLE_LIST,
        enable_cache: bool = False,
        verbose: bool = True
    ):
        """
        Initialize the AI knowledge retriever.
        åˆå§‹åŒ–AIçŸ¥è¯†æ£€ç´¢å™¨

        Args:
            llm_client: LLM client instance (creates default if None)
                        LLMå®¢æˆ·ç«¯å®žä¾‹ï¼ˆå¦‚æžœä¸ºNoneåˆ™åˆ›å»ºé»˜è®¤å®žä¾‹ï¼‰
            prompt_template_path: Path to prompt template file or None for default
                                  æç¤ºè¯æ¨¡æ¿æ–‡ä»¶è·¯å¾„ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨é»˜è®¤æ¨¡æ¿
            fallback_retriever: Traditional retriever to use if AI fails
                                AIå¤±è´¥æ—¶ä½¿ç”¨çš„ä¼ ç»Ÿæ£€ç´¢å™¨
            knowledge_base_path: Path to knowledge base JSON file for saving rules
                                 ç”¨äºŽä¿å­˜è§„åˆ™çš„çŸ¥è¯†åº“JSONæ–‡ä»¶è·¯å¾„
            auto_enrich_kb: Whether to automatically add generated rules to knowledge base
                            æ˜¯å¦è‡ªåŠ¨å°†ç”Ÿæˆçš„è§„åˆ™æ·»åŠ åˆ°çŸ¥è¯†åº“
            max_rules: Maximum number of rules to generate
                       ç”Ÿæˆè§„åˆ™çš„æœ€å¤§æ•°é‡
            temperature: LLM sampling temperature (0.0-1.0)
                         LLMé‡‡æ ·æ¸©åº¦ï¼ˆ0.0-1.0ï¼‰
            output_format: Format for rule output
                           è§„åˆ™è¾“å‡ºæ ¼å¼
            enable_cache: Whether to cache generated rules
                          æ˜¯å¦ç¼“å­˜ç”Ÿæˆçš„è§„åˆ™
            verbose: Whether to print detailed progress
                     æ˜¯å¦æ‰“å°è¯¦ç»†è¿›åº¦
        """
        # Lazy import to avoid circular dependency
        # å»¶è¿Ÿå¯¼å…¥ä»¥é¿å…å¾ªçŽ¯ä¾èµ–
        from engine.scaffolder import LLMClient

        self.llm_client = llm_client or LLMClient()
        self.fallback_retriever = fallback_retriever
        self.knowledge_base_path = Path(knowledge_base_path) if knowledge_base_path else None
        self.auto_enrich_kb = auto_enrich_kb
        self.max_rules = max_rules
        self.temperature = temperature
        self.output_format = output_format
        self.enable_cache = enable_cache
        self.verbose = verbose

        # Load prompt template / åŠ è½½æç¤ºè¯æ¨¡æ¿
        self.prompt_template = self._load_prompt_template(prompt_template_path)

        # Initialize cache / åˆå§‹åŒ–ç¼“å­˜
        self.cache: Dict[str, List[str]] = {} if enable_cache else None

        # Track problem-rule mappings for KB enrichment
        # è·Ÿè¸ªé—®é¢˜-è§„åˆ™æ˜ å°„ä»¥ä¾¿ä¸°å¯ŒçŸ¥è¯†åº“
        self.problem_rule_history: List[Dict[str, Any]] = []
        
        # Store structured rules from last extraction (for KB enrichment)
        # å­˜å‚¨ä¸Šæ¬¡æå–çš„ç»“æž„åŒ–è§„åˆ™ï¼ˆç”¨äºŽçŸ¥è¯†åº“ä¸°å¯Œï¼‰
        self.last_structured_rules: List[Dict[str, Any]] = []
        
        # Semantic embedding for duplicate detection (lazy loading)
        # ç”¨äºŽé‡å¤æ£€æµ‹çš„è¯­ä¹‰åµŒå…¥ï¼ˆæ‡’åŠ è½½ï¼‰
        self._embedding_model = None
        self._embeddings_cache: Dict[str, Any] = {}  # Cache embeddings
        self.use_semantic_dedup = True  # Enable semantic deduplication by default

        self._print("Initialized AI Knowledge Retriever.")
        self._print("å·²åˆå§‹åŒ–AIçŸ¥è¯†æ£€ç´¢å™¨")

        if auto_enrich_kb:
            self._print("   Auto-enrichment of knowledge base is ENABLED.")
            self._print("   çŸ¥è¯†åº“è‡ªåŠ¨ä¸°å¯ŒåŠŸèƒ½å·²å¯ç”¨")

    def _print(self, message: str) -> None:
        """
        Print message if verbose mode is enabled.
        å¦‚æžœå¯ç”¨è¯¦ç»†æ¨¡å¼ï¼Œåˆ™æ‰“å°æ¶ˆæ¯

        Args:
            message: Message to print
                     è¦æ‰“å°çš„æ¶ˆæ¯
        """
        if self.verbose:
            print(message)

    def _load_prompt_template(self, template_path: Optional[str]) -> str:
        """
        Load prompt template from file or use default.
        ä»Žæ–‡ä»¶åŠ è½½æç¤ºè¯æ¨¡æ¿æˆ–ä½¿ç”¨é»˜è®¤æ¨¡æ¿

        Args:
            template_path: Path to template file or None
                           æ¨¡æ¿æ–‡ä»¶è·¯å¾„ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨é»˜è®¤

        Returns:
            Prompt template string
            æç¤ºè¯æ¨¡æ¿å­—ç¬¦ä¸²
        """
        if template_path:
            path = Path(template_path)
            if path.exists():
                with open(path, 'r', encoding='utf-8') as f:
                    self._print(f"Loaded custom prompt template from: {path}")
                    self._print(f"å·²ä»Žä»¥ä¸‹ä½ç½®åŠ è½½è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿: {path}")
                    return f.read()
            else:
                self._print(f"Warning: Template file not found: {path}, using default.")
                self._print(f"è­¦å‘Š: æœªæ‰¾åˆ°æ¨¡æ¿æ–‡ä»¶: {path}ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿")

        return self._get_default_prompt_template()

    def _get_default_prompt_template(self) -> str:
        """
        Get the default prompt template for knowledge extraction.
        èŽ·å–çŸ¥è¯†æå–çš„é»˜è®¤æç¤ºè¯æ¨¡æ¿

        Returns:
            Default prompt template
            é»˜è®¤æç¤ºè¯æ¨¡æ¿
        """
        return """**ROLE:**
You are an expert in mathematics, physics, and scientific reasoning. Your task is to identify and articulate all relevant formulas, laws, principles, and rules needed to solve a given problem.

**OBJECTIVE:**
Analyze the problem statement and generate a comprehensive list of domain knowledge required for solving it. Focus on being precise, relevant, and complete.

**INSTRUCTIONS:**
1. Carefully read and understand the problem domain (e.g., mechanics, thermodynamics, geometry, algebra).
2. Identify all physical laws, mathematical formulas, and principles applicable to this problem.
3. For each rule, provide:
   - A clear name or description
   - The mathematical formula or expression
   - Brief context on when and how to apply it
4. List up to {max_rules} most relevant rules.
5. Order rules by relevance (most important first).

**OUTPUT FORMAT:**
Provide a numbered list where each entry follows this structure:
```
N. [Name/Description]: [Formula/Expression] - [Brief explanation of application]
```

**EXAMPLE:**
Problem: "An object with mass 10 kg starts from rest. A force of 50 N acts on it for 5 seconds. Find the final velocity."

Output:
1. Newton's Second Law: F = m Ã— a - Relates force, mass, and acceleration. Use to find acceleration when force and mass are known.
2. Kinematic Equation (Constant Acceleration): v_f = v_i + a Ã— t - Calculates final velocity given initial velocity, acceleration, and time.
3. Rest Condition: v_i = 0 - When an object is at rest, its initial velocity is zero.

**YOUR TASK:**
Analyze the following problem and generate the required knowledge rules:

**PROBLEM:**
{problem_text}

**OUTPUT:**
"""

    def get_knowledge(self, problem_text: str) -> List[str]:
        """
        Main interface for knowledge extraction (compatible with KnowledgeRetriever).
        çŸ¥è¯†æå–çš„ä¸»æŽ¥å£ï¼ˆä¸ŽKnowledgeRetrieverå…¼å®¹ï¼‰

        This method provides the same interface as the traditional KnowledgeRetriever,
        making it a drop-in replacement.

        æ­¤æ–¹æ³•æä¾›ä¸Žä¼ ç»ŸKnowledgeRetrieverç›¸åŒçš„æŽ¥å£ï¼Œä½¿å…¶å¯ä»¥ç›´æŽ¥æ›¿æ¢ä½¿ç”¨ã€‚

        Args:
            problem_text: The problem statement in natural language
                          è‡ªç„¶è¯­è¨€çš„é—®é¢˜é™ˆè¿°

        Returns:
            List of relevant rule descriptions
            ç›¸å…³è§„åˆ™æè¿°çš„åˆ—è¡¨
        """
        return self.extract_knowledge(problem_text)

    def extract_knowledge(
        self,
        problem_text: str,
        use_fallback_on_error: bool = True
    ) -> List[str]:
        """
        Extract relevant knowledge rules using AI generation.
        ä½¿ç”¨AIç”Ÿæˆæ–¹å¼æå–ç›¸å…³çš„çŸ¥è¯†è§„åˆ™

        This method sends the problem to the LLM and parses the generated
        formulas, laws, and principles.

        æ­¤æ–¹æ³•å°†é—®é¢˜å‘é€ç»™LLMï¼Œå¹¶è§£æžç”Ÿæˆçš„å…¬å¼ã€å®šå¾‹å’ŒåŽŸç†ã€‚

        Args:
            problem_text: The problem statement
                          é—®é¢˜é™ˆè¿°
            use_fallback_on_error: Whether to use fallback retriever on error
                                   é”™è¯¯æ—¶æ˜¯å¦ä½¿ç”¨é™çº§æ£€ç´¢å™¨

        Returns:
            List of relevant rule descriptions
            ç›¸å…³è§„åˆ™æè¿°çš„åˆ—è¡¨
        """
        # Check cache first / é¦–å…ˆæ£€æŸ¥ç¼“å­˜
        if self.enable_cache and problem_text in self.cache:
            self._print("Retrieved rules from cache.")
            self._print("ä»Žç¼“å­˜ä¸­æ£€ç´¢åˆ°è§„åˆ™")
            return self.cache[problem_text]

        self._print("\n" + "="*60)
        self._print("Extracting knowledge using AI...")
        self._print("ä½¿ç”¨AIæå–çŸ¥è¯†...")
        self._print("="*60)

        try:
            # Generate prompt / ç”Ÿæˆæç¤ºè¯
            prompt = self.prompt_template.format(
                problem_text=problem_text,
                max_rules=self.max_rules
            )

            # Call LLM / è°ƒç”¨LLM
            self._print("Calling LLM for knowledge generation...")
            self._print("æ­£åœ¨è°ƒç”¨LLMç”ŸæˆçŸ¥è¯†...")

            response = self.llm_client.complete(prompt, temperature=self.temperature)

            # Parse response / è§£æžå“åº”
            rules = self._parse_rules(response)

            # Validate rules / éªŒè¯è§„åˆ™
            if not rules:
                self._print("Warning: No rules were extracted from LLM response.")
                self._print("è­¦å‘Š: æœªä»ŽLLMå“åº”ä¸­æå–åˆ°è§„åˆ™")
                if use_fallback_on_error and self.fallback_retriever:
                    return self._use_fallback(problem_text)
                return []

            # Cache results / ç¼“å­˜ç»“æžœ
            if self.enable_cache:
                self.cache[problem_text] = rules

            # Auto-enrich knowledge base if enabled
            # å¦‚æžœå¯ç”¨ï¼Œè‡ªåŠ¨ä¸°å¯ŒçŸ¥è¯†åº“
            if self.auto_enrich_kb and rules:
                self._save_rules_to_kb(problem_text, rules)

            self._print(f"\n Successfully extracted {len(rules)} relevant rules.")
            self._print(f" æˆåŠŸæå–äº† {len(rules)} æ¡ç›¸å…³è§„åˆ™")
            self._print("="*60 + "\n")

            return rules

        except Exception as e:
            self._print(f"\n Error during AI knowledge extraction: {e}")
            self._print(f" AIçŸ¥è¯†æå–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")

            if use_fallback_on_error and self.fallback_retriever:
                return self._use_fallback(problem_text)

            self._print("No fallback retriever available, returning empty list.")
            self._print("æ²¡æœ‰å¯ç”¨çš„é™çº§æ£€ç´¢å™¨ï¼Œè¿”å›žç©ºåˆ—è¡¨")
            return []

    def _parse_rules(self, response: str) -> List[str]:
        """
        Parse the LLM response to extract individual rules.
        è§£æžLLMå“åº”ä»¥æå–å•ä¸ªè§„åˆ™

        This method handles various output formats and extracts clean,
        usable rule descriptions. Now supports JSON format output.

        æ­¤æ–¹æ³•å¤„ç†å„ç§è¾“å‡ºæ ¼å¼å¹¶æå–æ¸…æ™°ã€å¯ç”¨çš„è§„åˆ™æè¿°ã€‚çŽ°åœ¨æ”¯æŒJSONæ ¼å¼è¾“å‡ºã€‚

        Args:
            response: The raw LLM response text
                      LLMåŽŸå§‹å“åº”æ–‡æœ¬

        Returns:
            List of extracted rules
            æå–çš„è§„åˆ™åˆ—è¡¨
        """
        rules = []
        
        # Clear previous structured rules
        # æ¸…é™¤ä¹‹å‰çš„ç»“æž„åŒ–è§„åˆ™
        self.last_structured_rules = []

        # Strategy 1: Parse JSON format (NEW - for updated prompt template)
        # ç­–ç•¥1: è§£æžJSONæ ¼å¼ï¼ˆæ–°å¢ž - é€‚é…æ›´æ–°çš„promptæ¨¡æ¿ï¼‰
        try:
            # Extract JSON content from response
            # ä»Žå“åº”ä¸­æå–JSONå†…å®¹
            json_match = re.search(r'```json\s*(\[.*?\])\s*```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Try to find JSON array without code blocks
                # å°è¯•æŸ¥æ‰¾æ²¡æœ‰ä»£ç å—çš„JSONæ•°ç»„
                json_match = re.search(r'\[\s*\{.*?\}\s*\]', response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                else:
                    json_str = None

            if json_str:
                # Parse JSON
                # è§£æžJSON
                json_data = json.loads(json_str)
                
                if isinstance(json_data, list):
                    for item in json_data[:self.max_rules]:
                        if isinstance(item, dict):
                            # Extract rule from JSON object
                            # ä»ŽJSONå¯¹è±¡ä¸­æå–è§„åˆ™
                            rule_text = item.get('rule', '')
                            
                            # Extract keywords and category from LLM response
                            # ä»ŽLLMå“åº”ä¸­æå–å…³é”®è¯å’Œåˆ†ç±»
                            keywords = item.get('keywords', [])
                            category = item.get('category', '')
                            
                            if rule_text and len(rule_text) > 15:
                                # Store structured data for KB enrichment
                                # å­˜å‚¨ç»“æž„åŒ–æ•°æ®ç”¨äºŽçŸ¥è¯†åº“ä¸°å¯Œ
                                self.last_structured_rules.append({
                                    'keywords': keywords,
                                    'rule': rule_text,
                                    'category': category
                                })
                                
                                # Format: rule text (with optional metadata)
                                # æ ¼å¼ï¼šè§„åˆ™æ–‡æœ¬ï¼ˆå¸¦å¯é€‰å…ƒæ•°æ®ï¼‰
                                formatted_rule = rule_text
                                
                                # Add category if available
                                # å¦‚æžœæœ‰åˆ†ç±»åˆ™æ·»åŠ 
                                if category:
                                    formatted_rule = f"[{category}] {formatted_rule}"
                                
                                rules.append(formatted_rule)
                
                # If we successfully parsed JSON rules, return them
                # å¦‚æžœæˆåŠŸè§£æžäº†JSONè§„åˆ™ï¼Œè¿”å›žå®ƒä»¬
                if rules:
                    self._print(f"  âœ“ Successfully parsed {len(rules)} rules from JSON format")
                    self._print(f"  âœ“ æˆåŠŸä»ŽJSONæ ¼å¼è§£æžäº† {len(rules)} æ¡è§„åˆ™")
                    self._print(f"  âœ“ Stored {len(self.last_structured_rules)} structured rules for KB enrichment")
                    self._print(f"  âœ“ å·²å­˜å‚¨ {len(self.last_structured_rules)} æ¡ç»“æž„åŒ–è§„åˆ™ç”¨äºŽçŸ¥è¯†åº“ä¸°å¯Œ")
                    return rules
        
        except json.JSONDecodeError as e:
            self._print(f"  âš  JSON parsing failed: {e}, trying fallback methods")
            self._print(f"  âš  JSONè§£æžå¤±è´¥: {e}ï¼Œå°è¯•fallbackæ–¹æ³•")
        except Exception as e:
            self._print(f"  âš  Error parsing JSON: {e}, trying fallback methods")
            self._print(f"  âš  è§£æžJSONæ—¶å‡ºé”™: {e}ï¼Œå°è¯•fallbackæ–¹æ³•")

        # Strategy 2: Parse numbered list (e.g., "1.", "2.", etc.) - FALLBACK
        # ç­–ç•¥2: è§£æžç¼–å·åˆ—è¡¨ï¼ˆä¾‹å¦‚"1.","2."ç­‰ï¼‰- å¤‡ç”¨æ–¹æ¡ˆ
        # Match patterns like: "1. Name: Formula - Explanation"
        pattern = r'\d+\.\s+(.+?)(?=\n\d+\.|\n*$)'
        matches = re.findall(pattern, response, re.DOTALL)

        if matches:
            for match in matches:
                rule = match.strip()
                if rule and len(rule) > 15:  # Filter out very short matches
                    rules.append(rule)

            # Limit to max_rules
            if rules:
                self._print(f"  âœ“ Parsed {len(rules)} rules from numbered list format")
                self._print(f"  âœ“ ä»Žç¼–å·åˆ—è¡¨æ ¼å¼è§£æžäº† {len(rules)} æ¡è§„åˆ™")
                return rules[:self.max_rules]

        # Strategy 3: Split by newlines and clean up - LAST RESORT
        # ç­–ç•¥3: æŒ‰æ¢è¡Œç¬¦åˆ†å‰²å¹¶æ¸…ç† - æœ€åŽçš„æ‰‹æ®µ
        lines = response.strip().split('\n')
        for line in lines:
            line = line.strip()

            # Remove leading numbers and common list markers
            # åˆ é™¤å‰å¯¼æ•°å­—å’Œå¸¸è§åˆ—è¡¨æ ‡è®°
            cleaned = re.sub(r'^[\d\-\*\]+[\.\)]\s*', '', line)

            # Filter: must be substantial and likely a rule description
            # è¿‡æ»¤ï¼šå¿…é¡»æ˜¯å®žè´¨æ€§çš„å¹¶ä¸”å¯èƒ½æ˜¯è§„åˆ™æè¿°
            if cleaned and len(cleaned) > 15 and ':' in cleaned:
                rules.append(cleaned)

                if len(rules) >= self.max_rules:
                    break

        if rules:
            self._print(f"  âœ“ Parsed {len(rules)} rules from line-by-line format")
            self._print(f"  âœ“ ä»Žé€è¡Œæ ¼å¼è§£æžäº† {len(rules)} æ¡è§„åˆ™")
        
        return rules

    def _use_fallback(self, problem_text: str) -> List[str]:
        """
        Use fallback retriever when AI extraction fails.
         AI 

        Args:
            problem_text: The problem statement
                          

        Returns:
            Rules from fallback retriever
            
        """
        self._print("\n Using fallback retriever (traditional knowledge base)...")
        self._print(" ...")

        try:
            rules = self.fallback_retriever.get_knowledge(problem_text)
            self._print(f"  Fallback retriever returned {len(rules)} rules.")
            self._print(f"   {len(rules)} ")
            return rules
        except Exception as e:
            self._print(f"  Fallback retriever also failed: {e}")
            self._print(f"  : {e}")
            return []

    def extract_structured_knowledge(
        self,
        problem_text: str
    ) -> List[KnowledgeRule]:
        """
        Extract knowledge in structured format with metadata.
        

        This method returns KnowledgeRule objects instead of plain strings,
        providing additional metadata for advanced use cases.

         KnowledgeRule 
        

        Args:
            problem_text: The problem statement
                          

        Returns:
            List of structured KnowledgeRule objects
             KnowledgeRule 
        """
        # Get raw rules / 
        raw_rules = self.extract_knowledge(problem_text)

        # Convert to structured format / 
        structured_rules = []
        for rule_text in raw_rules:
            # Try to parse structured information from rule text
            # 
            structured_rule = self._parse_structured_rule(rule_text)
            structured_rules.append(structured_rule)

        return structured_rules

    def _parse_structured_rule(self, rule_text: str) -> KnowledgeRule:
        """
        Parse a rule string into a structured KnowledgeRule object.
         KnowledgeRule 

        Args:
            rule_text: Raw rule text
                       

        Returns:
            KnowledgeRule object
            KnowledgeRule 
        """
        # Basic implementation: just wrap the text
        # 
        # TODO: Enhanced parsing to extract category, formula, etc.
        # TODO
        return KnowledgeRule(
            rule=rule_text,
            category=None,
            confidence=None,
            explanation=None
        )

    def clear_cache(self) -> None:
        """
        Clear the cached rules.
        
        """
        if self.cache is not None:
            self.cache.clear()
            self._print("Cache cleared.")
            self._print("")

    def get_cache_stats(self) -> Dict[str, Any]:
        """
        Get statistics about the cache.
        

        Returns:
            Dictionary with cache statistics
            
        """
        if not self.enable_cache:
            return {"enabled": False}

        return {
            "enabled": True,
            "size": len(self.cache),
            "problems_cached": list(self.cache.keys())
        }

    def _save_rules_to_kb(self, problem_text: str, rules: List[str]) -> None:
        """
        Save generated rules to the knowledge base.
        å°†ç”Ÿæˆçš„è§„åˆ™ä¿å­˜åˆ°çŸ¥è¯†åº“
        
        This method uses the structured data from LLM (keywords, rule, category)
        stored in self.last_structured_rules to save to knowledge base.
        If structured data is not available, falls back to extracting keywords
        from the problem text.
        
        æ­¤æ–¹æ³•ä½¿ç”¨å­˜å‚¨åœ¨ self.last_structured_rules ä¸­çš„LLMç»“æž„åŒ–æ•°æ®
        ï¼ˆå…³é”®è¯ã€è§„åˆ™ã€åˆ†ç±»ï¼‰ä¿å­˜åˆ°çŸ¥è¯†åº“ã€‚å¦‚æžœæ²¡æœ‰ç»“æž„åŒ–æ•°æ®ï¼Œ
        åˆ™é™çº§ä¸ºä»Žé—®é¢˜æ–‡æœ¬ä¸­æå–å…³é”®è¯ã€‚

        Args:
            problem_text: The problem statement
                          é—®é¢˜é™ˆè¿°
            rules: List of generated rules (for compatibility)
                   ç”Ÿæˆçš„è§„åˆ™åˆ—è¡¨ï¼ˆç”¨äºŽå…¼å®¹æ€§ï¼‰
        """
        if not self.knowledge_base_path:
            self._print("   Knowledge base path not set, skipping save.")
            self._print("   ")
            return

        try:
            # Load existing knowledge base
            # åŠ è½½çŽ°æœ‰çŸ¥è¯†åº“
            kb_data = self._load_knowledge_base()

            # Use structured rules if available (from JSON parsing)
            # å¦‚æžœæœ‰ç»“æž„åŒ–è§„åˆ™ï¼ˆæ¥è‡ªJSONè§£æžï¼‰ï¼Œåˆ™ä½¿ç”¨å®ƒä»¬
            if self.last_structured_rules:
                new_entries_count = 0
                
                for structured_rule in self.last_structured_rules:
                    rule_text = structured_rule.get('rule', '')
                    keywords = structured_rule.get('keywords', [])
                    category = structured_rule.get('category', 'ai_generated')
                    
                    # Check if rule already exists (avoid duplicates)
                    # æ£€æŸ¥è§„åˆ™æ˜¯å¦å·²å­˜åœ¨ï¼ˆé¿å…é‡å¤ï¼‰
                    if not self._rule_exists_in_kb(rule_text, kb_data):
                        kb_entry = {
                            "keywords": keywords if keywords else ["general"],
                            "rule": rule_text,
                            "category": category,
                            "source": "ai_retriever"
                        }
                        kb_data.append(kb_entry)
                        new_entries_count += 1
                        
                        # Print the rule being added to KB
                        # æ‰“å°æ­£åœ¨æ·»åŠ åˆ°çŸ¥è¯†åº“çš„è§„åˆ™
                        self._print(f"   ðŸ“ Adding to KB â†’ [{category}] {rule_text}")
                        self._print(f"   ðŸ“ æ·»åŠ åˆ°çŸ¥è¯†åº“ â†’ [å…³é”®è¯: {', '.join(keywords[:3])}{'...' if len(keywords) > 3 else ''}]")

                        # Track in history
                        # è®°å½•åˆ°åŽ†å²
                        self.problem_rule_history.append({
                            "problem": problem_text[:100] + "..." if len(problem_text) > 100 else problem_text,
                            "rule": rule_text,
                            "keywords": keywords,
                            "category": category
                        })
                
                # Save updated knowledge base
                # ä¿å­˜æ›´æ–°çš„çŸ¥è¯†åº“
                if new_entries_count > 0:
                    self._write_knowledge_base(kb_data)
                    self._print(f"   âœ“ Added {new_entries_count} new structured rules to knowledge base.")
                    self._print(f"   âœ“ å‘çŸ¥è¯†åº“æ·»åŠ äº† {new_entries_count} æ¡æ–°çš„ç»“æž„åŒ–è§„åˆ™")
                else:
                    self._print("   â„¹ All rules already exist in knowledge base.")
                    self._print("   â„¹ æ‰€æœ‰è§„åˆ™å·²å­˜åœ¨äºŽçŸ¥è¯†åº“ä¸­")
            
            else:
                # Fallback: Extract keywords from problem (for non-JSON formats)
                # åŽå¤‡æ–¹æ¡ˆï¼šä»Žé—®é¢˜ä¸­æå–å…³é”®è¯ï¼ˆç”¨äºŽéžJSONæ ¼å¼ï¼‰
                self._print("   âš  No structured rules available, using fallback method")
                self._print("   âš  æ²¡æœ‰å¯ç”¨çš„ç»“æž„åŒ–è§„åˆ™ï¼Œä½¿ç”¨åŽå¤‡æ–¹æ³•")
                
                keywords = self._extract_keywords_from_problem(problem_text)
                new_entries_count = 0
                
                for rule in rules:
                    if not self._rule_exists_in_kb(rule, kb_data):
                        # Remove category prefix if exists (e.g., "[algebra] ...")
                        # å¦‚æžœå­˜åœ¨åˆ†ç±»å‰ç¼€åˆ™åˆ é™¤ï¼ˆä¾‹å¦‚ï¼š"[algebra] ..."ï¼‰
                        clean_rule = re.sub(r'^\[[\w\s]+\]\s*', '', rule)
                        
                        kb_entry = {
                            "keywords": keywords,
                            "rule": clean_rule,
                            "category": "ai_generated",
                            "source": "ai_retriever"
                        }
                        kb_data.append(kb_entry)
                        new_entries_count += 1
                        
                        # Print the rule being added to KB
                        # æ‰“å°æ­£åœ¨æ·»åŠ åˆ°çŸ¥è¯†åº“çš„è§„åˆ™
                        self._print(f"   ðŸ“ Adding to KB â†’ [ai_generated] {clean_rule}")
                        self._print(f"   ðŸ“ æ·»åŠ åˆ°çŸ¥è¯†åº“ â†’ [å…³é”®è¯: {', '.join(keywords[:3])}{'...' if len(keywords) > 3 else ''}]")

                        self.problem_rule_history.append({
                            "problem": problem_text[:100] + "..." if len(problem_text) > 100 else problem_text,
                            "rule": clean_rule,
                            "keywords": keywords
                        })

                if new_entries_count > 0:
                    self._write_knowledge_base(kb_data)
                    self._print(f"   Added {new_entries_count} new rules to knowledge base.")
                    self._print(f"   å‘çŸ¥è¯†åº“æ·»åŠ äº† {new_entries_count} æ¡æ–°è§„åˆ™")
                else:
                    self._print("   All rules already exist in knowledge base.")
                    self._print("   æ‰€æœ‰è§„åˆ™å·²å­˜åœ¨äºŽçŸ¥è¯†åº“ä¸­")

        except Exception as e:
            self._print(f"   âŒ Error saving rules to KB: {e}")
            self._print(f"   âŒ ä¿å­˜è§„åˆ™åˆ°çŸ¥è¯†åº“æ—¶å‡ºé”™: {e}")
            import traceback
            if self.verbose:
                traceback.print_exc()

    def _extract_keywords_from_problem(self, problem_text: str) -> List[str]:
        """
        Extract keywords from problem text for knowledge base indexing.
        

        This method uses a comprehensive domain-specific keyword database
        to identify relevant academic terms in the problem.

        

        Args:
            problem_text: The problem statement
                          

        Returns:
            List of extracted keywords
            
        """
        # Use the comprehensive domain keywords database
        # 
        from .domain_keywords import extract_keywords_from_text, identify_domains

        # Extract keywords using the domain keywords module
        # 
        extracted = extract_keywords_from_text(problem_text, max_keywords=15)

        # If still too few keywords, add domain names
        # 
        if len(extracted) < 3:
            domains = identify_domains(problem_text)
            if domains:
                # Add top 2 domain names
                top_domains = sorted(domains.items(), key=lambda x: x[1]["count"], reverse=True)[:2]
                extracted.extend([domain for domain, _ in top_domains])
            else:
                # Fallback to generic keywords
                extracted.extend(["problem", "solve"])

        return extracted[:15]  # Limit to 15 keywords

    def _load_knowledge_base(self) -> List[Dict[str, Any]]:
        """
        Load the knowledge base from JSON file.
         JSON 

        Returns:
            List of knowledge base entries
            
        """
        if not self.knowledge_base_path.exists():
            self._print(f"   Creating new knowledge base at: {self.knowledge_base_path}")
            self._print(f"   : {self.knowledge_base_path}")
            return []

        try:
            with open(self.knowledge_base_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except json.JSONDecodeError:
            self._print("   Knowledge base JSON is corrupted, creating new one.")
            self._print("    JSON ")
            return []
        except Exception as e:
            self._print(f"   Error loading KB: {e}")
            self._print(f"   : {e}")
            return []

    def _write_knowledge_base(self, kb_data: List[Dict[str, Any]]) -> None:
        """
        Write knowledge base data to JSON file.
         JSON 

        Args:
            kb_data: Knowledge base entries to write
                     
        """
        # Ensure parent directory exists
        # 
        self.knowledge_base_path.parent.mkdir(parents=True, exist_ok=True)

        with open(self.knowledge_base_path, 'w', encoding='utf-8') as f:
            json.dump(kb_data, f, indent=2, ensure_ascii=False)

    def _load_embedding_model(self):
        """
        Lazy load the sentence transformer model for semantic similarity.
        æ‡’åŠ è½½ç”¨äºŽè¯­ä¹‰ç›¸ä¼¼åº¦çš„å¥å­è½¬æ¢æ¨¡åž‹
        
        Returns:
            Loaded model or None if loading fails
            åŠ è½½çš„æ¨¡åž‹ï¼Œå¦‚æžœåŠ è½½å¤±è´¥åˆ™è¿”å›žNone
        """
        if self._embedding_model is not None:
            return self._embedding_model
        
        try:
            from sentence_transformers import SentenceTransformer
            from pathlib import Path
            
            # Use a lightweight but effective model
            # ä½¿ç”¨è½»é‡çº§ä½†æœ‰æ•ˆçš„æ¨¡åž‹
            # Try local path first, then download from hub
            # é¦–å…ˆå°è¯•æœ¬åœ°è·¯å¾„ï¼Œç„¶åŽä»Žhubä¸‹è½½
            local_model_path = Path('all-MiniLM-L6-v2')
            
            if local_model_path.exists():
                model_name = str(local_model_path)
                self._print(f"   Loading local semantic embedding model: {local_model_path}...")
                self._print(f"   æ­£åœ¨åŠ è½½æœ¬åœ°è¯­ä¹‰åµŒå…¥æ¨¡åž‹: {local_model_path}...")
            else:
                model_name = 'all-MiniLM-L6-v2'  # 80MB, fast, good for short texts
                self._print(f"   Loading semantic embedding model: {model_name}...")
                self._print(f"   æ­£åœ¨åŠ è½½è¯­ä¹‰åµŒå…¥æ¨¡åž‹: {model_name}...")
            
            self._embedding_model = SentenceTransformer(model_name)
            
            self._print("   âœ“ Semantic embedding model loaded successfully.")
            self._print("   âœ“ è¯­ä¹‰åµŒå…¥æ¨¡åž‹åŠ è½½æˆåŠŸ")
            
            return self._embedding_model
            
        except ImportError:
            self._print("   âš  sentence-transformers not installed. Falling back to simple similarity.")
            self._print("   âš  æœªå®‰è£… sentence-transformersã€‚é™çº§ä½¿ç”¨ç®€å•ç›¸ä¼¼åº¦ã€‚")
            self._print("   Install with: pip install sentence-transformers")
            self.use_semantic_dedup = False  # Disable semantic dedup
            return None
        except Exception as e:
            self._print(f"   âš  Failed to load embedding model: {e}")
            self._print(f"   âš  åŠ è½½åµŒå…¥æ¨¡åž‹å¤±è´¥: {e}")
            self.use_semantic_dedup = False
            return None
    
    def _get_embedding(self, text: str):
        """
        Get embedding vector for a text.
        èŽ·å–æ–‡æœ¬çš„åµŒå…¥å‘é‡
        
        Args:
            text: Text to embed
                  è¦åµŒå…¥çš„æ–‡æœ¬
        
        Returns:
            Embedding vector or None
            åµŒå…¥å‘é‡æˆ–None
        """
        # Check cache first
        # é¦–å…ˆæ£€æŸ¥ç¼“å­˜
        if text in self._embeddings_cache:
            return self._embeddings_cache[text]
        
        # Load model if not loaded
        # å¦‚æžœæ¨¡åž‹æœªåŠ è½½ï¼Œåˆ™åŠ è½½
        model = self._load_embedding_model()
        if model is None:
            return None
        
        try:
            # Generate embedding
            # ç”ŸæˆåµŒå…¥
            embedding = model.encode(text, convert_to_tensor=False)
            
            # Cache it
            # ç¼“å­˜å®ƒ
            self._embeddings_cache[text] = embedding
            
            return embedding
        except Exception as e:
            self._print(f"   âš  Error generating embedding: {e}")
            return None
    
    def _semantic_similarity(self, text1: str, text2: str) -> float:
        """
        Calculate semantic similarity between two texts using embeddings.
        ä½¿ç”¨åµŒå…¥è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬ä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼åº¦
        
        Args:
            text1: First text
                   ç¬¬ä¸€ä¸ªæ–‡æœ¬
            text2: Second text
                   ç¬¬äºŒä¸ªæ–‡æœ¬
        
        Returns:
            Similarity score (0.0-1.0), or -1.0 if calculation fails
            ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0.0-1.0ï¼‰ï¼Œå¦‚æžœè®¡ç®—å¤±è´¥åˆ™è¿”å›ž-1.0
        """
        if not self.use_semantic_dedup:
            return -1.0
        
        # Get embeddings
        # èŽ·å–åµŒå…¥
        emb1 = self._get_embedding(text1)
        emb2 = self._get_embedding(text2)
        
        if emb1 is None or emb2 is None:
            return -1.0
        
        try:
            # Calculate cosine similarity
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            from sklearn.metrics.pairwise import cosine_similarity
            import numpy as np
            
            # Reshape for sklearn
            # ä¸ºsklearné‡å¡‘
            emb1 = np.array(emb1).reshape(1, -1)
            emb2 = np.array(emb2).reshape(1, -1)
            
            similarity = cosine_similarity(emb1, emb2)[0][0]
            
            return float(similarity)
            
        except Exception as e:
            self._print(f"   âš  Error calculating similarity: {e}")
            return -1.0
    
    def _rule_exists_in_kb(self, rule: str, kb_data: List[Dict[str, Any]]) -> bool:
        """
        Check if a rule already exists in the knowledge base.
        æ£€æŸ¥è§„åˆ™æ˜¯å¦å·²å­˜åœ¨äºŽçŸ¥è¯†åº“ä¸­
        
        Enhanced with semantic similarity detection:
        å¢žå¼ºäº†è¯­ä¹‰ç›¸ä¼¼åº¦æ£€æµ‹ï¼š
        1. Exact match (case-insensitive)
           å®Œå…¨åŒ¹é…ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        2. Semantic similarity > 0.85 (if enabled)
           è¯­ä¹‰ç›¸ä¼¼åº¦ > 0.85ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
        3. Simple word similarity > 0.9 (fallback)
           ç®€å•è¯ç›¸ä¼¼åº¦ > 0.9ï¼ˆé™çº§ï¼‰

        Args:
            rule: Rule text to check
                  è¦æ£€æŸ¥çš„è§„åˆ™æ–‡æœ¬
            kb_data: Knowledge base data
                     çŸ¥è¯†åº“æ•°æ®

        Returns:
            True if rule exists, False otherwise
            å¦‚æžœè§„åˆ™å­˜åœ¨åˆ™è¿”å›žTrueï¼Œå¦åˆ™è¿”å›žFalse
        """
        rule_lower = rule.lower()
        
        for entry in kb_data:
            existing_rule = entry.get("rule", "")
            existing_lower = existing_rule.lower()
            
            # Check 1: Exact match
            # æ£€æŸ¥1ï¼šå®Œå…¨åŒ¹é…
            if rule_lower == existing_lower:
                return True
            
            # Check 2: Semantic similarity (if enabled)
            # æ£€æŸ¥2ï¼šè¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
            if self.use_semantic_dedup:
                semantic_sim = self._semantic_similarity(rule, existing_rule)
                # Use lower threshold (0.60) for formulas vs natural language
                # å¯¹äºŽå…¬å¼ä¸Žè‡ªç„¶è¯­è¨€ä½¿ç”¨è¾ƒä½Žé˜ˆå€¼ï¼ˆ0.60ï¼‰
                if semantic_sim > 0.60:  # Adjusted threshold for better detection
                    if self.verbose:
                        self._print(f"   ðŸ” Semantic duplicate detected (similarity: {semantic_sim:.2f})")
                        self._print(f"   ðŸ” æ£€æµ‹åˆ°è¯­ä¹‰é‡å¤ï¼ˆç›¸ä¼¼åº¦: {semantic_sim:.2f}ï¼‰")
                    return True
            
            # Check 3: Simple word-based similarity (fallback)
            # æ£€æŸ¥3ï¼šç®€å•çš„åŸºäºŽè¯çš„ç›¸ä¼¼åº¦ï¼ˆé™çº§ï¼‰
            if self._similarity(rule_lower, existing_lower) > 0.9:
                return True
        
        return False

    def _similarity(self, s1: str, s2: str) -> float:
        """
        Calculate simple similarity between two strings.
        

        Args:
            s1: First string
                
            s2: Second string
                

        Returns:
            Similarity score (0.0-1.0)
            0.0-1.0
        """
        # Simple word-based similarity
        # 
        words1 = set(s1.split())
        words2 = set(s2.split())

        if not words1 or not words2:
            return 0.0

        intersection = words1 & words2
        union = words1 | words2

        return len(intersection) / len(union) if union else 0.0

    def export_enrichment_history(self, output_path: str = "kb_enrichment_history.json") -> None:
        """
        Export the history of knowledge base enrichment to a file.
        

        Args:
            output_path: Path to save the history
                         
        """
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.problem_rule_history, f, indent=2, ensure_ascii=False)

        self._print(f"Enrichment history exported to: {output_file}")
        self._print(f": {output_file}")

    def get_enrichment_stats(self) -> Dict[str, Any]:
        """
        Get statistics about knowledge base enrichment.
        

        Returns:
            Dictionary with enrichment statistics
            
        """
        return {
            "auto_enrich_enabled": self.auto_enrich_kb,
            "total_rules_generated": len(self.problem_rule_history),
            "knowledge_base_path": str(self.knowledge_base_path) if self.knowledge_base_path else None
        }


# Example usage / 
if __name__ == "__main__":
    from engine.retriever import KnowledgeRetriever

    # Test problem / 
    test_problem = """
    An object with a mass of 10 kg is initially at rest.
    A constant force of 50 Newtons is applied to it for 5 seconds.
    What is its final velocity?
    """

    print("="*70)
    print("Testing AI Knowledge Retriever")
    print(" AI ")
    print("="*70)

    # Initialize with fallback / 
    try:
        fallback = KnowledgeRetriever("data/knowledge_base.json")
    except:
        fallback = None
        print("Note: Traditional retriever not available for fallback.")
        print("")

    retriever = AIKnowledgeRetriever(
        fallback_retriever=fallback,
        max_rules=5,
        enable_cache=True,
        verbose=True
    )

    # Extract knowledge / 
    rules = retriever.get_knowledge(test_problem)

    print("\n" + "="*70)
    print("EXTRACTED RULES")
    print("")
    print("="*70)

    for i, rule in enumerate(rules, 1):
        print(f"\n{i}. {rule}")

    # Test cache / 
    print("\n" + "="*70)
    print("Testing cache...")
    print("...")
    print("="*70)

    rules_cached = retriever.get_knowledge(test_problem)
    print(f"\nCache stats: {retriever.get_cache_stats()}")
    print(f": {retriever.get_cache_stats()}")
