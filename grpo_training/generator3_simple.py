"""
Generator 1 ç®€åŒ–ç‰ˆè®­ç»ƒè„šæœ¬
åŠŸèƒ½ï¼šåŠ è½½æ•°æ®é›†ï¼Œç”Ÿæˆrolloutsï¼Œè®¡ç®—å¥–åŠ±ï¼Œæå–ç»éªŒ
"""

import json
import argparse
from pathlib import Path
from datetime import datetime
from tqdm import tqdm

# å¯¼å…¥éœ€è¦çš„ç»„ä»¶
from engine.api_manager import APIKeyManager
from grpo_training.experience_extractor import ExperienceExtractor
from engine.scaffolder import LLMClient, CausalScaffolder
from engine.llm_computer import LLMComputer
from engine.reward_evaluator import RewardEvaluator
from grpo_training.training_stats import TrainingStats

GENERATOR_ID = "generator_1"


def load_problems(dataset="full", max_problems=None):
    """
    åŠ è½½è®­ç»ƒé¢˜ç›®
    - full: å®Œæ•´90é¢˜ï¼ˆAIME2024 30é¢˜ + AIME2025 30é¢˜ + ç‰©ç† 30é¢˜ï¼‰
    - aime2024: å•ç‹¬AIME2024
    - aime2025: å•ç‹¬AIME2025
    - physics: å•ç‹¬ç‰©ç†é¢˜
    """
    problems = []
    project_root = Path(__file__).parent.parent

    if dataset == "full":
        # ä»é…ç½®æ–‡ä»¶è¯»å–
        config_path = project_root / "grpo_training" / "dataset_config.json"
        with open(config_path, 'r') as f:
            config = json.load(f)

        for source in config['full_dataset']['datasets']:
            dataset_path = project_root / source['path']

            if source['format'] == 'jsonl':
                # JSONLæ ¼å¼æ–‡ä»¶
                with open(dataset_path, 'r', encoding='utf-8') as f:
                    for i, line in enumerate(f):
                        if max_problems and len(problems) >= max_problems:
                            break
                        data = json.loads(line.strip())
                        problems.append({
                            'id': f"{source['id_prefix']}_{i+1:03d}",
                            'text': data.get(source['problem_field'], ''),
                            'answer': str(data.get(source['answer_field'], ''))
                        })

            elif source['format'] == 'json':
                # JSONæ ¼å¼æ–‡ä»¶
                with open(dataset_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for i, item in enumerate(data):
                        if max_problems and len(problems) >= max_problems:
                            break
                        problems.append({
                            'id': f"{source['id_prefix']}_{i+1:03d}",
                            'text': item.get(source['problem_field'], ''),
                            'answer': str(item.get(source['answer_field'], ''))
                        })

        print(f"âœ“ åŠ è½½å®Œæˆ: {len(problems)} é“é¢˜ç›®")

    else:
        # å•ç‹¬æ•°æ®é›†åŠ è½½é€»è¾‘
        print(f"âœ“ æš‚æ—¶åªæ”¯æŒ full æ•°æ®é›†")

    return problems


def generate_rollouts(problem, scaffolder, computer, evaluator, extractor, num_rollouts=3):
    """
    ä¸ºä¸€é“é¢˜ç”Ÿæˆå¤šä¸ªrolloutså¹¶è®¡ç®—å¥–åŠ±
    """
    rollouts = []

    # åŠ è½½å½“å‰ç»éªŒåº“
    experiences_list = extractor._load_experiences(GENERATOR_ID)
    experiences = [exp['content'] for exp in experiences_list]

    for i in range(1, num_rollouts + 1):
        try:
            print(f"  ç”ŸæˆRollout {i}...")

            # ç”Ÿæˆå› æœå›¾
            scaffold = scaffolder.generate_scaffold(
                problem_text=problem['text'],
                retrieved_knowledge=[],
                experiences=experiences
            )

            # è®¡ç®—ç­”æ¡ˆ
            result = computer.compute_from_scaffold(
                causal_scaffold=scaffold,
                problem_text=problem['text']
            )

            if result['success']:
                answer = result['result']
                is_correct = evaluator.evaluate_answer(answer, problem['answer'], problem['text']) >= 0.99
            else:
                answer = None
                is_correct = False

            # è®¡ç®—å¥–åŠ±
            r_ans = evaluator.evaluate_answer(answer, problem['answer'], problem['text']) if answer else 0.0
            r_logic = evaluator.evaluate_logic(str(scaffold), problem['text'])
            r_graph = evaluator.evaluate_graph(scaffold)
            r_total = 0.5 * r_ans + 0.25 * r_logic + 0.25 * r_graph

            rollouts.append({
                'rollout_id': i,
                'scaffold': scaffold,
                'answer': answer,
                'is_correct': is_correct,
                'r_total': r_total
            })

            print(f"  âœ“ Rollout {i}: {'æ­£ç¡®' if is_correct else 'é”™è¯¯'} (å¥–åŠ±: {r_total:.2f})")

        except Exception as e:
            print(f"  âœ— Rollout {i} å¤±è´¥: {e}")
            rollouts.append({
                'rollout_id': i,
                'error': str(e),
                'r_total': 0.0
            })

    return rollouts


def save_results(problem, rollouts, output_file):
    """
    ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    """
    record = {
        'problem_id': problem['id'],
        'problem_text': problem['text'],
        'ground_truth': problem['answer'],
        'rollouts': rollouts,
        'timestamp': datetime.now().isoformat()
    }

    with open(output_file, 'a', encoding='utf-8') as f:
        f.write(json.dumps(record, ensure_ascii=False) + '\n')


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Generator 1 è®­ç»ƒè„šæœ¬')
    parser.add_argument('--dataset', type=str, default='full', help='æ•°æ®é›†é€‰æ‹©')
    parser.add_argument('--max-problems', type=int, help='æœ€å¤§é¢˜ç›®æ•°é‡')
    parser.add_argument('--rollouts', type=int, default=3, help='æ¯é¢˜ç”Ÿæˆrolloutsæ•°é‡')
    parser.add_argument('--temperature', type=float, default=0.3, help='ç”Ÿæˆæ¸©åº¦')

    args = parser.parse_args()

    print("=" * 60)
    print("ğŸ¤– Generator 1 å¼€å§‹è®­ç»ƒ")
    print("=" * 60)

    # 1. åˆå§‹åŒ–ç»„ä»¶
    print("1. åˆå§‹åŒ–ç»„ä»¶...")
    project_root = Path(__file__).parent.parent

    # åŠ è½½APIå¯†é’¥
    api_manager = APIKeyManager(str(project_root / "data" / "api_keys" / "api_config.json"))
    api_key = api_manager.get_api_key(GENERATOR_ID)

    # è®¾ç½®ç¯å¢ƒå˜é‡
    import os
    os.environ["SILICONFLOW_API_KEY"] = api_key

    # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
    llm_client = LLMClient(provider="siliconflow")
    scaffolder = CausalScaffolder(llm_client=llm_client)
    computer = LLMComputer(verbose=False)
    evaluator = RewardEvaluator(llm_client=llm_client, verbose=False)
    extractor = ExperienceExtractor(llm_client=llm_client, tau=0.05, verbose=False)

    # åˆå§‹åŒ–æ­£ç¡®ç‡ç»Ÿè®¡
    stats = TrainingStats(GENERATOR_ID)

    print("âœ“ ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

    # 2. åŠ è½½æ•°æ®
    print("\n2. åŠ è½½è®­ç»ƒæ•°æ®...")
    problems = load_problems(args.dataset, args.max_problems)
    print(f"âœ“ åŠ è½½äº† {len(problems)} é“é¢˜ç›®")

    # 3. å¼€å§‹è®­ç»ƒ
    print("\n3. å¼€å§‹è®­ç»ƒ...")
    output_file = str(project_root / "grpo_training" / "cache" / f"{GENERATOR_ID}_results.json")

    # ç»Ÿè®¡æ•°æ®
    total_correct_problems = 0
    total_correct_rollouts = 0
    total_rollouts = 0
    total_reward = 0.0

    for idx, problem in enumerate(tqdm(problems, desc="è®­ç»ƒè¿›åº¦"), 1):
        print(f"\n--- é¢˜ç›® {idx}/{len(problems)}: {problem['id']} ---")

        # æ˜¾ç¤ºå½“å‰ç»éªŒåº“å¤§å°
        current_experiences = extractor._load_experiences(GENERATOR_ID)
        print(f"å½“å‰ç»éªŒåº“: {len(current_experiences)} æ¡")

        # ç”Ÿæˆrollouts
        rollouts = generate_rollouts(problem, scaffolder, computer, evaluator, extractor, args.rollouts)

        # ä¿å­˜ç»“æœ
        save_results(problem, rollouts, output_file)

        # æå–ç»éªŒ
        extractor.extract_generator_experience(
            generator_id=GENERATOR_ID,
            problem=problem,
            rollouts=rollouts,
            ground_truth=problem['answer']
        )

        # æ˜¾ç¤ºæ›´æ–°åçš„ç»éªŒåº“
        updated_experiences = extractor._load_experiences(GENERATOR_ID)
        print(f"æ›´æ–°åç»éªŒåº“: {len(updated_experiences)} æ¡")

        # ç»Ÿè®¡æ­£ç¡®ç‡
        correct_count = sum(1 for r in rollouts if r.get('is_correct', False))
        print(f"æœ¬é¢˜ç›®æ­£ç¡®ç‡: {correct_count}/{len(rollouts)} = {correct_count/len(rollouts)*100:.1f}%")

        # ç´¯è®¡ç»Ÿè®¡æ•°æ®
        total_rollouts += len(rollouts)
        total_correct_rollouts += correct_count
        if correct_count > 0:  # è‡³å°‘æœ‰ä¸€ä¸ªrolloutæ­£ç¡®
            total_correct_problems += 1
        total_reward += sum(r.get('r_total', 0) for r in rollouts)

    # è®¡ç®—æ­£ç¡®ç‡
    problem_accuracy = total_correct_problems / len(problems) if problems else 0.0
    rollout_accuracy = total_correct_rollouts / total_rollouts if total_rollouts > 0 else 0.0
    avg_reward = total_reward / total_rollouts if total_rollouts > 0 else 0.0

    # è®°å½•ç»Ÿè®¡
    additional_metrics = {
        "rollout_accuracy": rollout_accuracy,
        "total_experiences": len(extractor._load_experiences(GENERATOR_ID)),
        "total_rollouts": total_rollouts
    }

    stats.record_epoch(
        epoch_num=len(stats.stats_data["epochs"]) + 1,
        total_problems=len(problems),
        correct_answers=total_correct_problems,
        total_reward=total_reward,
        avg_reward=avg_reward,
        additional_metrics=additional_metrics
    )

    print("\n" + "=" * 60)
    print("âœ… Generator 1 è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“ ç»“æœä¿å­˜è‡³: {output_file}")
    print(f"ğŸ§  ç»éªŒä¿å­˜è‡³: data/grpo_experiences/{GENERATOR_ID}_experiences.json")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿å­˜è‡³: training_stats/{GENERATOR_ID}_stats.json")

    # æ‰“å°æ­£ç¡®ç‡ç»Ÿè®¡
    print(f"\nğŸ“Š æœ¬æ¬¡è®­ç»ƒç»Ÿè®¡:")
    print(f"æ€»é¢˜ç›®æ•°: {len(problems)}")
    print(f"é¢˜ç›®æ­£ç¡®ç‡: {total_correct_problems}/{len(problems)} = {problem_accuracy:.3f} ({problem_accuracy*100:.1f}%)")
    print(f"Rolloutæ­£ç¡®ç‡: {total_correct_rollouts}/{total_rollouts} = {rollout_accuracy:.3f} ({rollout_accuracy*100:.1f}%)")
    print(f"å¹³å‡å¥–åŠ±: {avg_reward:.3f}")

    # ç”Ÿæˆç»Ÿè®¡å›¾è¡¨å’ŒæŠ¥å‘Š
    try:
        chart_path = f"training_stats/{GENERATOR_ID}_progress.png"
        stats.plot_progress(save_path=chart_path)
        report_path = stats.export_detailed_report()
    except Exception as e:
        print(f"ç”Ÿæˆç»Ÿè®¡å›¾è¡¨å¤±è´¥: {e}")

    print("=" * 60)


if __name__ == "__main__":
    main()