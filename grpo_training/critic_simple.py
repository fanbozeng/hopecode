"""
Critic ç®€åŒ–ç‰ˆè®­ç»ƒè„šæœ¬
åŠŸèƒ½ï¼šèåˆ3ä¸ªGeneratorçš„rolloutsï¼Œè®¡ç®—å¥–åŠ±ï¼Œæå–ç»éªŒ
"""

import json
import argparse
from pathlib import Path
from datetime import datetime
from tqdm import tqdm

# å¯¼å…¥éœ€è¦çš„ç»„ä»¶
from engine.api_manager import APIKeyManager
from grpo_training.experience_extractor import ExperienceExtractor
from engine.scaffolder import LLMClient
from engine.llm_computer import LLMComputer
from engine.reward_evaluator import RewardEvaluator
from engine.multi_agent_scaffolder import MultiAgentScaffolder
from grpo_training.training_stats import TrainingStats

CRITIC_ID = "critic"


def load_generator_rollouts(generator_id):
    """
    åŠ è½½Generatorçš„rolloutsæ–‡ä»¶
    """
    project_root = Path(__file__).parent.parent
    rollouts_file = project_root / "grpo_training" / "cache" / f"{generator_id}_rollouts.jsonl"

    if not rollouts_file.exists():
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {rollouts_file}")
        print(f"è¯·å…ˆè¿è¡Œ {generator_id}.py!")
        return {}

    rollouts_dict = {}

    with open(rollouts_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                data = json.loads(line)
                problem_id = data['problem_id']
                rollouts_dict[problem_id] = data

    return rollouts_dict


def fuse_rollouts(rollouts, llm_client, problem_text):
    """
    èåˆå¤šä¸ªrolloutsï¼Œç”Ÿæˆä¸€ä¸ªæ›´å¥½çš„scaffold
    """
    print(f"  èåˆ {len(rollouts)} ä¸ªrollouts...")

    # æå–scaffolds
    proposals = []
    for r in rollouts:
        scaffold = r.get('scaffold')
        if scaffold:
            proposals.append(scaffold)

    # å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„proposalsï¼Œè¿”å›æœ€å¥½çš„ä¸€ä¸ª
    if len(proposals) == 0:
        return None
    elif len(proposals) < 3:
        # è¿”å›å¥–åŠ±æœ€é«˜çš„é‚£ä¸ª
        best_idx = max(range(len(rollouts)), key=lambda i: rollouts[i].get('r_total', 0))
        return rollouts[best_idx].get('scaffold')

    # åŠ è½½èåˆprompt
    project_root = Path(__file__).parent.parent
    fusion_prompt_path = project_root / "prompts" / "critic_fusion_prompt.txt"

    if not fusion_prompt_path.exists():
        print("  âš ï¸ æ‰¾ä¸åˆ°èåˆpromptï¼Œè¿”å›æœ€å¥½çš„proposal")
        best_idx = max(range(len(rollouts)), key=lambda i: rollouts[i].get('r_total', 0))
        return rollouts[best_idx].get('scaffold')

    # æ ¼å¼åŒ–proposalsä¸ºJSONå­—ç¬¦ä¸²
    proposal_strs = []
    for i, prop in enumerate(proposals[:3]):
        if isinstance(prop, dict):
            proposal_strs.append(json.dumps(prop, indent=2, ensure_ascii=False))
        else:
            proposal_strs.append(str(prop))

    # è¡¥é½åˆ°3ä¸ª
    while len(proposal_strs) < 3:
        proposal_strs.append(json.dumps({"error": "No proposal"}, indent=2))

    try:
        # è¯»å–promptæ¨¡æ¿
        with open(fusion_prompt_path, 'r', encoding='utf-8') as f:
            fusion_prompt_template = f.read()

        # å¡«å……prompt
        fusion_prompt = fusion_prompt_template.format(
            problem_text=problem_text,
            retrieved_knowledge="",
            proposal_1=proposal_strs[0],
            proposal_2=proposal_strs[1],
            proposal_3=proposal_strs[2]
        )

        # è°ƒç”¨LLMè¿›è¡Œèåˆ
        response = llm_client.complete(fusion_prompt, temperature=0.0)

        # è§£æèåˆç»“æœ
        fused_scaffold = parse_fused_scaffold(response)

        if fused_scaffold:
            print(f"  âœ“ èåˆæˆåŠŸ")
            return fused_scaffold
        else:
            print("  âš ï¸ èåˆå¤±è´¥ï¼Œè¿”å›æœ€å¥½çš„proposal")
            best_idx = max(range(len(rollouts)), key=lambda i: rollouts[i].get('r_total', 0))
            return rollouts[best_idx].get('scaffold')

    except Exception as e:
        print(f"  âš ï¸ èåˆå¤±è´¥: {e}ï¼Œè¿”å›æœ€å¥½çš„proposal")
        best_idx = max(range(len(rollouts)), key=lambda i: rollouts[i].get('r_total', 0))
        return rollouts[best_idx].get('scaffold')


def parse_fused_scaffold(response):
    """
    ä»LLMå“åº”ä¸­è§£æèåˆåçš„scaffold
    """
    try:
        # æ‰¾JSONéƒ¨åˆ†
        start = response.find('{')
        end = response.rfind('}') + 1

        if start >= 0 and end > start:
            json_str = response[start:end]
            data = json.loads(json_str)

            # æå–problem_analysiså­—æ®µ
            if 'problem_analysis' in data:
                return data['problem_analysis']
            else:
                return data

        return None
    except Exception as e:
        print(f"  âš ï¸ JSONè§£æé”™è¯¯: {e}")
        return None


def compute_rewards(fused_scaffold, rollouts, problem, computer, evaluator):
    """
    è®¡ç®—èåˆåçš„å¥–åŠ±
    """
    print(f"  è®¡ç®—å¥–åŠ±...")

    # è®¡ç®—ç­”æ¡ˆ
    try:
        result = computer.compute_from_scaffold(
            causal_scaffold=fused_scaffold,
            problem_text=problem['text']
        )

        if result['success']:
            answer = result['result']
        else:
            answer = None
    except:
        answer = None

    # è®¡ç®—å„é¡¹å¥–åŠ±
    if answer is not None:
        r_ans = evaluator.evaluate_answer(answer, problem['answer'], problem['text'])
        is_correct = (r_ans >= 0.99)
    else:
        is_correct = False
        r_ans = 0.0

    # é€»è¾‘è´¨é‡
    r_logic = evaluator.evaluate_logic(str(fused_scaffold), problem['text'])

    # å›¾è´¨é‡
    r_graph = evaluator.evaluate_graph(fused_scaffold)

    # èåˆè´¨é‡
    proposals = [r.get('scaffold') for r in rollouts if r.get('scaffold')]
    r_fusion = evaluator.evaluate_fusion(
        proposals=proposals,
        fused_result=fused_scaffold,
        ground_truth=problem['answer']
    )

    # æ€»å¥–åŠ±ï¼ˆCriticæƒé‡ä¸åŒï¼Œæ›´é‡è§†èåˆè´¨é‡ï¼‰
    r_total = 0.3 * r_ans + 0.2 * r_logic + 0.2 * r_graph + 0.3 * r_fusion

    print(f"  âœ“ ç­”æ¡ˆ: {'æ­£ç¡®' if is_correct else 'é”™è¯¯'} (å¥–åŠ±: {r_total:.3f})")

    return {
        'answer': answer,
        'is_correct': is_correct,
        'r_ans': r_ans,
        'r_logic': r_logic,
        'r_graph': r_graph,
        'r_fusion': r_fusion,
        'r_total': r_total
    }


def save_result(problem, generator_id, fused_scaffold, rewards, output_file):
    """
    ä¿å­˜èåˆç»“æœåˆ°æ–‡ä»¶
    """
    record = {
        'problem_id': problem['id'],
        'problem_text': problem['text'],
        'ground_truth': problem['answer'],
        'generator_id': generator_id,
        'fused_scaffold': str(fused_scaffold),
        'final_answer': rewards['answer'],
        'is_correct': rewards['is_correct'],
        'rewards': {
            'r_ans': rewards['r_ans'],
            'r_logic': rewards['r_logic'],
            'r_graph': rewards['r_graph'],
            'r_fusion': rewards['r_fusion'],
            'r_total': rewards['r_total']
        },
        'timestamp': datetime.now().isoformat()
    }

    with open(output_file, 'a', encoding='utf-8') as f:
        f.write(json.dumps(record, ensure_ascii=False) + '\n')


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Critic è®­ç»ƒè„šæœ¬')
    parser.add_argument('--temperature', type=float, default=0.0, help='Criticæ¸©åº¦è®¾ç½®')

    args = parser.parse_args()

    print("=" * 60)
    print("ğŸ§  Critic å¼€å§‹è®­ç»ƒ")
    print("=" * 60)

    # 1. åˆå§‹åŒ–ç»„ä»¶
    print("1. åˆå§‹åŒ–ç»„ä»¶...")
    project_root = Path(__file__).parent.parent

    # åŠ è½½APIå¯†é’¥
    api_manager = APIKeyManager(str(project_root / "data" / "api_keys" / "api_config.json"))
    api_key = api_manager.get_api_key(CRITIC_ID)

    # è®¾ç½®ç¯å¢ƒå˜é‡
    import os
    os.environ["SILICONFLOW_API_KEY"] = api_key

    # åˆå§‹åŒ–ç»„ä»¶
    llm_client = LLMClient(provider="siliconflow")
    critic_scaffolder = MultiAgentScaffolder(
        llm_client=llm_client,
        num_generators=1,
        critic_temperature=args.temperature
    )
    computer = LLMComputer(verbose=False)
    evaluator = RewardEvaluator(llm_client=llm_client, verbose=False)
    extractor = ExperienceExtractor(llm_client=llm_client, tau=0.05, verbose=False)

    # åˆå§‹åŒ–æ­£ç¡®ç‡ç»Ÿè®¡
    stats = TrainingStats(CRITIC_ID)

    print("âœ“ ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

    # 2. åŠ è½½æ‰€æœ‰Generatorçš„rollouts
    print("\n2. åŠ è½½Generatorçš„rollouts...")
    gen1_rollouts = load_generator_rollouts('generator_1')
    gen2_rollouts = load_generator_rollouts('generator_2')
    gen3_rollouts = load_generator_rollouts('generator_3')

    print(f"âœ“ Generator 1: {len(gen1_rollouts)} ä¸ªé—®é¢˜")
    print(f"âœ“ Generator 2: {len(gen2_rollouts)} ä¸ªé—®é¢˜")
    print(f"âœ“ Generator 3: {len(gen3_rollouts)} ä¸ªé—®é¢˜")

    # æ‰¾åˆ°æ‰€æœ‰Generatoréƒ½æœ‰çš„å…±åŒé—®é¢˜
    problem_ids = set(gen1_rollouts.keys()) & set(gen2_rollouts.keys()) & set(gen3_rollouts.keys())
    problem_ids = sorted(problem_ids)
    print(f"âœ“ å…±åŒé—®é¢˜: {len(problem_ids)} ä¸ª")

    # 3. å¼€å§‹èåˆ
    print("\n3. å¼€å§‹èåˆ...")
    output_file = str(project_root / "grpo_training" / "cache" / "critic_results.json")

    # ç»Ÿè®¡æ•°æ®
    total_problems = len(problem_ids)
    total_correct_fusions = 0
    total_fusion_attempts = 0
    total_reward = 0.0

    for idx, problem_id in enumerate(tqdm(problem_ids, desc="èåˆè¿›åº¦"), 1):
        print(f"\n--- é—®é¢˜ {idx}/{len(problem_ids)}: {problem_id} ---")

        # è·å–é—®é¢˜ä¿¡æ¯
        problem = {
            'id': problem_id,
            'text': gen1_rollouts[problem_id]['problem_text'],
            'answer': gen1_rollouts[problem_id]['ground_truth']
        }

        # æ˜¾ç¤ºå½“å‰ç»éªŒåº“
        current_experiences = extractor._load_experiences(CRITIC_ID)
        print(f"å½“å‰ç»éªŒåº“: {len(current_experiences)} æ¡")

        # åˆ†åˆ«èåˆæ¯ä¸ªGeneratorçš„rollouts
        fusion_results = []
        problem_correct = 0
        problem_attempts = 0

        for gen_id, gen_rollouts_dict in [
            ('generator_1', gen1_rollouts),
            ('generator_2', gen2_rollouts),
            ('generator_3', gen3_rollouts)
        ]:
            print(f"  èåˆ {gen_id}...")
            rollouts = gen_rollouts_dict[problem_id]['rollouts']

            # èåˆrollouts
            fused_scaffold = fuse_rollouts(rollouts, llm_client, problem['text'])

            if fused_scaffold:
                # è®¡ç®—å¥–åŠ±
                rewards = compute_rewards(fused_scaffold, rollouts, problem, computer, evaluator)

                # ä¿å­˜ç»“æœ
                save_result(problem, gen_id, fused_scaffold, rewards, output_file)

                # è®°å½•ç”¨äºç»éªŒæå–
                fusion_results.append({
                    **rewards,
                    'fused_dag': fused_scaffold
                })

                problem_attempts += 1
                total_fusion_attempts += 1
                total_reward += rewards['r_total']

                if rewards['is_correct']:
                    problem_correct += 1
                    total_correct_fusions += 1
            else:
                print(f"  âŒ {gen_id} èåˆå¤±è´¥")

        problem_accuracy = problem_correct / problem_attempts if problem_attempts > 0 else 0.0
        print(f"æœ¬é—®é¢˜èåˆæˆåŠŸç‡: {problem_correct}/{problem_attempts} = {problem_accuracy*100:.1f}%")

        # æå–Criticç»éªŒ
        experience_result = extractor.extract_critic_experience(
            problem=problem,
            fusion_results=fusion_results,
            ground_truth=problem['answer']
        )

        # æ˜¾ç¤ºæ›´æ–°åçš„ç»éªŒåº“
        updated_experiences = extractor._load_experiences(CRITIC_ID)
        print(f"æ›´æ–°åç»éªŒåº“: {len(updated_experiences)} æ¡")

    # è®¡ç®—æ­£ç¡®ç‡
    fusion_accuracy = total_correct_fusions / total_fusion_attempts if total_fusion_attempts > 0 else 0.0
    avg_reward = total_reward / total_fusion_attempts if total_fusion_attempts > 0 else 0.0

    # è®°å½•ç»Ÿè®¡
    additional_metrics = {
        "fusion_accuracy": fusion_accuracy,
        "total_fusion_attempts": total_fusion_attempts,
        "total_experiences": len(extractor._load_experiences(CRITIC_ID)),
        "extraction_triggered": experience_result is not None
    }

    stats.record_epoch(
        epoch_num=len(stats.stats_data["epochs"]) + 1,
        total_problems=total_problems,
        correct_answers=total_correct_fusions,
        total_reward=total_reward,
        avg_reward=avg_reward,
        additional_metrics=additional_metrics
    )

    print("\n" + "=" * 60)
    print("âœ… Critic è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“ ç»“æœä¿å­˜è‡³: {output_file}")
    print(f"ğŸ§  ç»éªŒä¿å­˜è‡³: data/grpo_experiences/{CRITIC_ID}_experiences.json")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿å­˜è‡³: training_stats/{CRITIC_ID}_stats.json")

    # æ‰“å°æ­£ç¡®ç‡ç»Ÿè®¡
    print(f"\nğŸ“Š æœ¬æ¬¡è®­ç»ƒç»Ÿè®¡:")
    print(f"æ€»é—®é¢˜æ•°: {total_problems}")
    print(f"æ€»èåˆå°è¯•: {total_fusion_attempts}")
    print(f"èåˆæ­£ç¡®ç‡: {total_correct_fusions}/{total_fusion_attempts} = {fusion_accuracy:.3f} ({fusion_accuracy*100:.1f}%)")
    print(f"å¹³å‡å¥–åŠ±: {avg_reward:.3f}")

    # ç”Ÿæˆç»Ÿè®¡å›¾è¡¨å’ŒæŠ¥å‘Š
    try:
        chart_path = f"training_stats/{CRITIC_ID}_progress.png"
        stats.plot_progress(save_path=chart_path)
        report_path = stats.export_detailed_report()
    except Exception as e:
        print(f"ç”Ÿæˆç»Ÿè®¡å›¾è¡¨å¤±è´¥: {e}")

    print("=" * 60)


if __name__ == "__main__":
    main()