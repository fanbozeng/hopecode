#!/usr/bin/env python3
"""
Ablation Study Runner for CFGO Framework
CFGOæ¡†æ¶æ¶ˆèå®éªŒè¿è¡Œå™¨

This script runs Level-1 ablation studies to validate core components.
è¯¥è„šæœ¬è¿è¡Œä¸€çº§æ¶ˆèå®éªŒä»¥éªŒè¯æ ¸å¿ƒç»„ä»¶ã€‚

Level-1 Ablations (Core Components):
ä¸€çº§æ¶ˆèï¼ˆæ ¸å¿ƒç»„ä»¶ï¼‰ï¼š
1. CFGO (Full) - å®Œæ•´æ–¹æ³•
2. CFGO-woGRPO - æ— GRPOç»éªŒåº“
3. CFGO-woMultiAgent - å•Generatorï¼ˆæ— Criticï¼‰
4. CFGO-woEnhancement - æ— å¢å¼ºæµæ°´çº¿

Usage:
    # è¿è¡Œå®Œæ•´æ–¹æ³•
    python run_ablation.py --ablation full --dataset gsm8k --limit 30
    
    # è¿è¡Œæ¶ˆèå®éªŒ
    python run_ablation.py --ablation woGRPO --dataset gsm8k --limit 30
    python run_ablation.py --ablation woMultiAgent --dataset gsm8k --limit 30
    python run_ablation.py --ablation woEnhancement --dataset gsm8k --limit 30
    
    # é™é»˜æ¨¡å¼
    python run_ablation.py --ablation full --dataset gsm8k --limit 30 --quiet

Evaluation with CF & AC Metrics:
ä½¿ç”¨CFå’ŒACæŒ‡æ ‡è¿›è¡Œè¯„ä¼°ï¼š
    After running ablation studies, evaluate with causal metrics:
    è¿è¡Œæ¶ˆèå®éªŒåï¼Œä½¿ç”¨å› æœæŒ‡æ ‡è¯„ä¼°ï¼š
    
    python -m comparasion.causal_evaluation \\
        --baseline-results comparasion/results/ablation/full/*.json \\
        --other-results comparasion/results/ablation/woGRPO/*.json
"""

import json
import argparse
import time
import re
import traceback
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List

# Import necessary modules
import sys
sys.path.append(str(Path(__file__).parent.parent))

from main import CausalReasoningEngine


class AblationRunner:
    """æ¶ˆèå®éªŒè¿è¡Œå™¨"""
    
    VALID_ABLATIONS = ['full', 'woGRPO', 'woMultiAgent', 'woEnhancement']
    
    def __init__(self, ablation_type: str, output_dir: str = "results/ablation", verbose: bool = True):
        """
        åˆå§‹åŒ–æ¶ˆèå®éªŒè¿è¡Œå™¨
        
        Args:
            ablation_type: æ¶ˆèç±»å‹ ('full', 'woGRPO', 'woMultiAgent', 'woEnhancement')
            output_dir: è¾“å‡ºç›®å½•
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
        """
        if ablation_type not in self.VALID_ABLATIONS:
            raise ValueError(f"Invalid ablation type: {ablation_type}. Must be one of {self.VALID_ABLATIONS}")
        
        self.ablation_type = ablation_type
        self.output_dir = Path(output_dir) / ablation_type
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.verbose = verbose
        
        # æ ¹æ®æ¶ˆèç±»å‹é…ç½®å¼•æ“
        self.engine = self._create_engine()
        
        if self.verbose:
            print(f"\n{'='*80}")
            print(f"ğŸ”¬ Ablation Study: {self._get_ablation_description()}")
            print(f"ğŸ“ Output Directory: {self.output_dir}")
            print(f"{'='*80}\n")
    
    def _get_ablation_description(self) -> str:
        """è·å–æ¶ˆèå®éªŒçš„æè¿°"""
        descriptions = {
            'full': 'CFGO (Full) - å®Œæ•´æ–¹æ³•',
            'woGRPO': 'CFGO-woGRPO - æ— GRPOç»éªŒåº“',
            'woMultiAgent': 'CFGO-woMultiAgent - å•Generatorï¼ˆæ— Criticï¼‰',
            'woEnhancement': 'CFGO-woEnhancement - æ— å¢å¼ºæµæ°´çº¿'
        }
        return descriptions.get(self.ablation_type, 'Unknown')
    
    def _create_engine(self) -> CausalReasoningEngine:
        """æ ¹æ®æ¶ˆèç±»å‹åˆ›å»ºé…ç½®å¥½çš„å¼•æ“"""
        
        if self.ablation_type == 'full':
            # å®Œæ•´æ–¹æ³•ï¼šæ‰€æœ‰åŠŸèƒ½å¼€å¯
            print("âœ… Configuration: Full CFGO Framework")
            print("  - GRPO Experience: âœ“")
            print("  - Multi-Agent: âœ“ (3 Generators + Critic)")
            print("  - Enhancement Pipeline: âœ“ (Stage 1+2+3)")
            
            return CausalReasoningEngine(
                knowledge_base_path="data/knowledge_base.json",
                verbose=True,
                use_multi_agent=True,              # ä½¿ç”¨å¤šæ™ºèƒ½ä½“
                enable_step2_enhancement=True,      # å¯ç”¨å¢å¼º
                use_expert_review=True,             # Stage 1
                use_rag_enhancement=True,           # Stage 2
                use_structure_optimization=True,    # Stage 3
                use_grpo_experience=True            # åŠ è½½GRPOç»éªŒ
            )
        
        elif self.ablation_type == 'woGRPO':
            # æ¶ˆèGRPOï¼šä¸åŠ è½½ç»éªŒåº“
            print("âŒ Ablation: Remove GRPO Experience")
            print("  - GRPO Experience: âœ—")
            print("  - Multi-Agent: âœ“ (3 Generators + Critic)")
            print("  - Enhancement Pipeline: âœ“ (Stage 1+2+3)")
            
            return CausalReasoningEngine(
                knowledge_base_path="data/knowledge_base.json",
                verbose=True,
                use_multi_agent=True,
                enable_step2_enhancement=True,
                use_expert_review=True,
                use_rag_enhancement=True,
                use_structure_optimization=True,
                use_grpo_experience=False           # âŒ ä¸åŠ è½½ç»éªŒ
            )
        
        elif self.ablation_type == 'woMultiAgent':
            # æ¶ˆèå¤šæ™ºèƒ½ä½“ï¼šåªç”¨å•ä¸ªGenerator
            print("âŒ Ablation: Remove Multi-Agent")
            print("  - GRPO Experience: âœ“")
            print("  - Multi-Agent: âœ— (1 Generator, No Critic)")
            print("  - Enhancement Pipeline: âœ“ (Stage 1+2+3)")
            
            return CausalReasoningEngine(
                knowledge_base_path="data/knowledge_base.json",
                verbose=True,
                use_multi_agent=False,              # âŒ ä¸ä½¿ç”¨å¤šæ™ºèƒ½ä½“
                enable_step2_enhancement=True,
                use_expert_review=True,
                use_rag_enhancement=True,
                use_structure_optimization=True,
                use_grpo_experience=True
            )
        
        elif self.ablation_type == 'woEnhancement':
            # æ¶ˆèå¢å¼ºæµæ°´çº¿ï¼šè·³è¿‡æ‰€æœ‰Stage
            print("âŒ Ablation: Remove Enhancement Pipeline")
            print("  - GRPO Experience: âœ“")
            print("  - Multi-Agent: âœ“ (3 Generators + Critic)")
            print("  - Enhancement Pipeline: âœ— (Skip all stages)")
            
            return CausalReasoningEngine(
                knowledge_base_path="data/knowledge_base.json",
                verbose=True,
                use_multi_agent=True,
                enable_step2_enhancement=False,     # âŒ ç¦ç”¨å¢å¼ºæµæ°´çº¿
                use_expert_review=False,
                use_rag_enhancement=False,
                use_structure_optimization=False,
                use_grpo_experience=True
            )
        
        else:
            raise ValueError(f"Unknown ablation type: {self.ablation_type}")
    
    def solve_problem(self, problem: str, problem_id: str = None) -> Dict[str, Any]:
        """ä½¿ç”¨é…ç½®å¥½çš„å¼•æ“è§£å†³é—®é¢˜"""
        try:
            start_time = time.time()
            
            # è¿è¡Œå› æœæ¨ç†å¼•æ“
            result = self.engine.solve_problem(
                problem_text=problem,
                include_validation=True,
                problem_id=problem_id
            )
            
            execution_time = time.time() - start_time
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_result = {
                'method': f'cfgo_{self.ablation_type}',
                'ablation_type': self.ablation_type,
                'problem_id': problem_id,
                'problem': problem,
                'answer': result.get('final_answer'),
                'reasoning': self._extract_reasoning_from_result(result),
                'causal_dag': result.get('causal_scaffold', {}),
                'raw_response': json.dumps(result, default=str),
                'execution_time': execution_time,
                'metadata': {
                    'ablation': self.ablation_type,
                    'scaffold_generated': 'causal_scaffold' in result,
                    'knowledge_enhanced': result.get('knowledge_enhanced', False),
                    'verification_passed': result.get('verification_passed', False),
                    'dag_complexity': self._calculate_dag_complexity(result.get('causal_scaffold', {}))
                }
            }
            
            return formatted_result
        
        except Exception as e:
            execution_time = time.time() - start_time
            error_msg = str(e)
            
            # æ‰“å°é”™è¯¯ä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
            print(f"âŒ Error solving problem {problem_id}: {error_msg}")
            if self.verbose:
                traceback.print_exc()
            
            return {
                'method': f'cfgo_{self.ablation_type}',
                'ablation_type': self.ablation_type,
                'problem_id': problem_id,
                'problem': problem,
                'answer': None,
                'reasoning': '',
                'causal_dag': {},
                'raw_response': '',
                'error': error_msg,
                'execution_time': execution_time,
                'metadata': {
                    'error': True, 
                    'ablation': self.ablation_type,
                    'error_type': type(e).__name__
                }
            }
    
    def _extract_reasoning_from_result(self, result: Dict[str, Any]) -> str:
        """ä»CFGOç»“æœä¸­æå–æ¨ç†è¿‡ç¨‹"""
        reasoning_parts = []
        
        # æ·»åŠ è®¡ç®—æ­¥éª¤
        if 'computation_steps' in result:
            reasoning_parts.append("Computation Steps:")
            for step in result['computation_steps']:
                reasoning_parts.append(f"- {step}")
        
        # æ·»åŠ æ¨ç†é“¾
        if 'reasoning_chain' in result:
            reasoning_parts.append("\nReasoning Chain:")
            reasoning_parts.append(str(result['reasoning_chain']))
        
        return '\n'.join(reasoning_parts) if reasoning_parts else "No reasoning available"
    
    def _calculate_dag_complexity(self, dag: Dict[str, Any]) -> float:
        """è®¡ç®—DAGå¤æ‚åº¦"""
        if not dag:
            return 0.0
        
        complexity = 0
        complexity += len(dag.get('causal_graph', [])) * 2
        complexity += len(dag.get('computation_plan', [])) * 1
        complexity += len(dag.get('knowns', {})) * 0.5
        
        return complexity
    
    def run_on_dataset(self, dataset_name: str, limit: Optional[int] = None):
        """åœ¨æ•°æ®é›†ä¸Šè¿è¡Œæ¶ˆèå®éªŒ"""
        print(f"\n{'='*80}")
        print(f"ğŸ“Š Running {self.ablation_type} on {dataset_name} (limit: {limit})")
        print(f"{'='*80}\n")
        
        # åŠ è½½æ•°æ®é›†
        problems = self._load_dataset(dataset_name, limit)
        
        if not problems:
            print(f"âŒ Failed to load dataset: {dataset_name}")
            return
        
        print(f"âœ… Loaded {len(problems)} problems\n")
        
        # è¿è¡Œå®éªŒ
        results = []
        correct = 0
        
        for i, problem_data in enumerate(problems, 1):
            problem_id = problem_data['id']
            problem = problem_data['question']
            expected_answer = problem_data['answer']
            
            print(f"\n[{i}/{len(problems)}] Problem: {problem_id}")
            print(f"Question: {problem[:100]}..." if len(problem) > 100 else f"Question: {problem}")
            
            # è§£å†³é—®é¢˜
            result = self.solve_problem(problem, problem_id)
            
            # æ£€æŸ¥ç­”æ¡ˆ
            is_correct = self._check_answer(result['answer'], expected_answer)
            result['expected_answer'] = expected_answer
            result['is_correct'] = is_correct
            
            if is_correct:
                correct += 1
                print(f"âœ“ Correct! Answer: {result['answer']}")
            else:
                print(f"âœ— Wrong. Got: {result['answer']}, Expected: {expected_answer}")
            
            print(f"â±ï¸  Time: {result['execution_time']:.2f}s")
            
            results.append(result)
            
            # å®æ—¶å‡†ç¡®ç‡
            accuracy = correct / i
            print(f"ğŸ“Š Current Accuracy: {correct}/{i} ({accuracy*100:.1f}%)")
        
        # è®¡ç®—æœ€ç»ˆç»Ÿè®¡
        accuracy = correct / len(problems) if problems else 0
        total_time = sum(r['execution_time'] for r in results)
        avg_time = total_time / len(problems) if problems else 0
        error_count = sum(1 for r in results if r.get('error'))
        
        print(f"\n{'='*80}")
        print(f"ğŸ“Š Final Results for {self.ablation_type}")
        print(f"{'='*80}")
        print(f"Total Problems: {len(problems)}")
        print(f"Correct: {correct}")
        print(f"Wrong: {len(problems) - correct - error_count}")
        print(f"Errors: {error_count}")
        print(f"Accuracy: {accuracy*100:.2f}%")
        print(f"Average Time: {avg_time:.2f}s")
        print(f"Total Time: {total_time:.2f}s")
        print(f"{'='*80}\n")
        
        # ä¿å­˜ç»“æœ
        self._save_results(dataset_name, results, accuracy, total_time, avg_time)
    
    def _load_dataset(self, dataset_name: str, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """åŠ è½½æ•°æ®é›†"""
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        project_root = Path(__file__).resolve().parent.parent
        
        dataset_map = {
            'gsm8k': project_root / "dataset/GSM8K/grade_school_math/data/test.jsonl",
            'math': project_root / "dataset/Math/test-00000-of-00001.parquet.json",
            'mydata': project_root / "dataset/mydata/data/2024A.json",
        }
        
        dataset_path = dataset_map.get(dataset_name.lower())
        
        if not dataset_path:
            print(f"âŒ Unknown dataset: {dataset_name}")
            return []
        
        if not dataset_path.exists():
            print(f"âŒ Dataset file not found: {dataset_path}")
            return []
        
        problems = []
        
        try:
            if dataset_name.lower() == 'gsm8k':
                with open(dataset_path, 'r', encoding='utf-8') as f:
                    for i, line in enumerate(f):
                        if limit and i >= limit:
                            break
                        data = json.loads(line.strip())
                        answer_text = data['answer']
                        final_answer = answer_text.split('####')[-1].strip() if '####' in answer_text else answer_text
                        problems.append({
                            'id': f'gsm8k_{i}',
                            'question': data['question'],
                            'answer': final_answer
                        })
            
            elif dataset_name.lower() in ['math', 'mydata']:
                with open(dataset_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if limit:
                        data = data[:limit]
                    
                    for i, item in enumerate(data):
                        problems.append({
                            'id': item.get('unique_id', f"{dataset_name}_{i}"),
                            'question': item.get('problem', item.get('question', '')),
                            'answer': item.get('answer', item.get('final_answer', ''))
                        })
        
        except Exception as e:
            print(f"âŒ Error loading dataset: {e}")
            return []
        
        return problems
    
    def _check_answer(self, predicted: Any, expected: str) -> bool:
        """æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦æ­£ç¡®ï¼ˆå¢å¼ºçš„ç­”æ¡ˆæ¯”è¾ƒé€»è¾‘ï¼‰"""
        if predicted is None:
            return False
        
        pred_str = str(predicted).strip().lower()
        exp_str = str(expected).strip().lower()
        
        # 1. ç²¾ç¡®åŒ¹é…
        if pred_str == exp_str:
            return True
        
        # 2. ç§»é™¤ç©ºæ ¼ååŒ¹é…
        pred_clean = pred_str.replace(" ", "")
        exp_clean = exp_str.replace(" ", "")
        if pred_clean == exp_clean:
            return True
        
        # 3. å°è¯•æ•°å€¼æ¯”è¾ƒ
        try:
            # æå–æ•°å­—ï¼ˆæ”¯æŒå°æ•°å’Œç§‘å­¦è®¡æ•°æ³•ï¼‰
            pred_nums = re.findall(r'[-+]?\d*\.?\d+(?:[eE][-+]?\d+)?', pred_str)
            exp_nums = re.findall(r'[-+]?\d*\.?\d+(?:[eE][-+]?\d+)?', exp_str)
            
            if pred_nums and exp_nums:
                # æ¯”è¾ƒç¬¬ä¸€ä¸ªæ•°å­—ï¼ˆé€šå¸¸æ˜¯ç­”æ¡ˆï¼‰
                pred_val = float(pred_nums[0])
                exp_val = float(exp_nums[0])
                
                # ä½¿ç”¨ç›¸å¯¹è¯¯å·®å’Œç»å¯¹è¯¯å·®
                if abs(exp_val) > 1e-6:
                    relative_error = abs(pred_val - exp_val) / abs(exp_val)
                    if relative_error < 1e-4:  # 0.01% ç›¸å¯¹è¯¯å·®
                        return True
                
                # ç»å¯¹è¯¯å·®
                if abs(pred_val - exp_val) < 1e-6:
                    return True
        except (ValueError, IndexError):
            pass
        
        # 4. æ£€æŸ¥åŒ…å«å…³ç³»ï¼ˆä½†è¦å°å¿ƒ - åªåœ¨é•¿åº¦è¶³å¤Ÿæ—¶ä½¿ç”¨ï¼‰
        # é¿å…"3"åŒ¹é…"30"è¿™ç§æƒ…å†µ
        if len(pred_clean) >= 3 and len(exp_clean) >= 3:
            if pred_clean in exp_clean or exp_clean in pred_clean:
                return True
        
        return False
    
    def _save_results(self, dataset_name: str, results: List[Dict[str, Any]], accuracy: float, total_time: float, avg_time: float):
        """ä¿å­˜ç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{self.ablation_type}_{dataset_name}_{timestamp}.json"
        filepath = self.output_dir / filename
        
        error_count = sum(1 for r in results if r.get('error'))
        
        output = {
            'ablation_type': self.ablation_type,
            'description': self._get_ablation_description(),
            'dataset': dataset_name,
            'timestamp': timestamp,
            'statistics': {
                'total_problems': len(results),
                'correct': sum(1 for r in results if r.get('is_correct', False)),
                'wrong': len(results) - sum(1 for r in results if r.get('is_correct', False)) - error_count,
                'errors': error_count,
                'accuracy': accuracy,
                'total_time': total_time,
                'avg_time': avg_time
            },
            'results': results
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ Results saved: {filepath}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="Ablation Study Runner for CFGO Framework"
    )
    
    parser.add_argument(
        '--ablation',
        type=str,
        required=True,
        choices=AblationRunner.VALID_ABLATIONS,
        help='Ablation type: full (å®Œæ•´), woGRPO (æ— GRPO), woMultiAgent (æ— å¤šæ™ºèƒ½ä½“), woEnhancement (æ— å¢å¼º)'
    )
    
    parser.add_argument(
        '--dataset',
        type=str,
        required=True,
        choices=['gsm8k', 'math', 'mydata'],
        help='Dataset to use'
    )
    
    parser.add_argument(
        '--limit',
        type=int,
        default=None,
        help='Limit number of problems to test'
    )
    
    parser.add_argument(
        '--output-dir',
        type=str,
        default='results/ablation',
        help='Output directory for results'
    )
    
    parser.add_argument(
        '--quiet',
        action='store_true',
        help='å‡å°‘è¾“å‡ºä¿¡æ¯ï¼ˆReduce output verbosityï¼‰'
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¿è¡Œå™¨å¹¶æ‰§è¡Œ
    runner = AblationRunner(
        ablation_type=args.ablation,
        output_dir=args.output_dir,
        verbose=not args.quiet
    )
    
    runner.run_on_dataset(args.dataset, args.limit)


if __name__ == "__main__":
    main()
