"""
Main Orchestrator for Causal Reasoning Engine
ä¸»è¦å› æœæ¨ç†å¼•æ“ç¼–æ’å™¨

Pipeline Architecture (based on design diagram):
æµæ°´çº¿æ¶æ„ï¼ˆåŸºäºè®¾è®¡å›¾ï¼‰ï¼š

Step1: Multi-Agent Generator for DAG of SCM
    - 3 parallel generators independently create causal DAGs
    - 1 critic agent fuses and refines the proposals
    - Output: Fixed DAG
    ç¬¬1æ­¥ï¼šå¤šæ™ºèƒ½ä½“ç”Ÿæˆå™¨ç”ŸæˆSCMçš„DAG
    - 3ä¸ªå¹¶è¡Œç”Ÿæˆå™¨ç‹¬ç«‹åˆ›å»ºå› æœDAG
    - 1ä¸ªæ‰¹åˆ¤è€…æ™ºèƒ½ä½“èåˆå¹¶ç²¾ç‚¼ææ¡ˆ
    - è¾“å‡ºï¼šFixed DAG

Step2: Post-Enhancement of the DAG
    - Domain Expert Review (Math/Physics experts)
    - RAG Knowledge Enhancement (knowledge gap filling)
    - Causal Structure Optimization (chain/fork/collider patterns)
    - Output: Enhanced DAG
    ç¬¬2æ­¥ï¼šDAGåå¢å¼º
    - é¢†åŸŸä¸“å®¶å®¡æŸ¥ï¼ˆæ•°å­¦/ç‰©ç†ä¸“å®¶ï¼‰
    - RAGçŸ¥è¯†å¢å¼ºï¼ˆå¡«è¡¥çŸ¥è¯†ç¼ºå£ï¼‰
    - å› æœç»“æ„ä¼˜åŒ–ï¼ˆé“¾/å‰/å¯¹æ’ç»“æ„æ¨¡å¼ï¼‰
    - è¾“å‡ºï¼šEnhanced DAG

Step3: LLM-Based Computation
    - LLM computes the final answer based on Enhanced DAG
    - Output: Final Answer + Reasoning
    ç¬¬3æ­¥ï¼šåŸºäºLLMçš„è®¡ç®—
    - LLMåŸºäºEnhanced DAGè®¡ç®—æœ€ç»ˆç­”æ¡ˆ
    - è¾“å‡ºï¼šæœ€ç»ˆç­”æ¡ˆ + æ¨ç†è¿‡ç¨‹
"""

import sys
import json
import argparse
from pathlib import Path
from typing import Optional, Dict, Any

# Import engine components /
from engine import (
    KnowledgeRetriever,
    AIKnowledgeRetriever,
    VectorKnowledgeRetriever,
    CausalScaffolder,
    LLMComputer,  # LLM-based computation / åŸºäºLLMçš„è®¡ç®—
    # Step2 Enhancement modules
    DomainExpertReviewer,
    RAGKnowledgeEnhancer,
    CausalStructureOptimizer,
    DAGEnhancementPipeline,
    ProblemType
)
# Import multi-agent scaffolder / å¯¼å…¥å¤šæ™ºèƒ½ä½“è„šæ‰‹æ¶å™¨
from engine.multi_agent_scaffolder import MultiAgentScaffolder


class CausalReasoningEngine:
    """
    Main orchestrator for the causal reasoning pipeline.
    ä¸»è¦å› æœæ¨ç†æµæ°´çº¿ç¼–æ’å™¨
    
    Coordinates three main steps:
    åè°ƒä¸‰ä¸ªä¸»è¦æ­¥éª¤ï¼š
    - Step1: Multi-agent generator creates Fixed DAG
    - Step2: Post-enhancement pipeline improves DAG
    - Step3: LLM-based computation produces final answer
    
    - ç¬¬1æ­¥ï¼šå¤šæ™ºèƒ½ä½“ç”Ÿæˆå™¨åˆ›å»ºFixed DAG
    - ç¬¬2æ­¥ï¼šåå¢å¼ºæµæ°´çº¿æ”¹è¿›DAG
    - ç¬¬3æ­¥ï¼šåŸºäºLLMçš„è®¡ç®—äº§ç”Ÿæœ€ç»ˆç­”æ¡ˆ
    """

    def __init__(
        self,
        knowledge_base_path: str = "data/knowledge_base.json", #çŸ¥è¯†åº“çš„ä½ç½®
        verbose: bool = True, # æ˜¯å¦æ‰“å°è¯¦ç»†è¿›åº¦ä¿¡æ¯
        use_ai_retriever: bool = True,  # æ˜¯å¦ä½¿ç”¨AIæ£€ç´¢å™¨ä½œä¸ºå›é€€
        auto_enrich_kb: bool = True, # æ˜¯å¦è‡ªåŠ¨ä¿å­˜AIç”Ÿæˆçš„è§„åˆ™åˆ°çŸ¥è¯†åº“
        min_rules_threshold: int = 5, # æœ€å°è§„åˆ™æ•°
        use_multi_agent: bool = True,  # é»˜è®¤ä½¿ç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
        num_generators: int = 3,  # æ–°å¢ï¼šç”Ÿæˆå™¨æ•°é‡
        generator_temperature: float = 0.3,  # æ–°å¢ï¼šç”Ÿæˆå™¨æ¸©åº¦
        critic_temperature: float = 0.0,  # æ–°å¢ï¼šæ‰¹åˆ¤è€…æ¸©åº¦
        use_vector_retriever: bool = False,  # æ–°å¢ï¼šå‘é‡æ£€ç´¢ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦RAGï¼‰
        use_grpo_experience: bool = True,  # æ–°å¢ï¼šæ˜¯å¦åŠ è½½GRPOç»éªŒï¼ˆç”¨äºæ¶ˆèå®éªŒï¼‰
        # Step2 Enhancement options / Step2å¢å¼ºé€‰é¡¹
        enable_step2_enhancement: bool = True,  # æ˜¯å¦å¯ç”¨Step2å¢å¼º
        use_expert_review: bool = True,  # æ˜¯å¦ä½¿ç”¨ä¸“å®¶å®¡æŸ¥
        use_rag_enhancement: bool = True,  # æ˜¯å¦ä½¿ç”¨RAGçŸ¥è¯†å¢å¼º
        use_structure_optimization: bool = True  # æ˜¯å¦ä½¿ç”¨ç»“æ„ä¼˜åŒ–
    ):
        """
        Initialize the causal reasoning engine.
        åˆå§‹åŒ–å› æœæ¨ç†å¼•æ“

        Args:
            knowledge_base_path: Path to knowledge base JSON file
                                 çŸ¥è¯†åº“JSONæ–‡ä»¶è·¯å¾„
            verbose: Print detailed progress information
                    æ‰“å°è¯¦ç»†è¿›åº¦ä¿¡æ¯
            use_ai_retriever: Use AI retriever for knowledge generation
                             ä½¿ç”¨AIæ£€ç´¢å™¨ç”ŸæˆçŸ¥è¯†
            auto_enrich_kb: Automatically save AI-generated rules
                           è‡ªåŠ¨ä¿å­˜AIç”Ÿæˆçš„è§„åˆ™
            min_rules_threshold: Minimum rules threshold
                                æœ€å°è§„åˆ™é˜ˆå€¼
            use_multi_agent: Use multi-agent scaffolder (3 generators + 1 critic)
                            ä½¿ç”¨å¤šæ™ºèƒ½ä½“è„šæ‰‹æ¶å™¨ï¼ˆ3ä¸ªç”Ÿæˆå™¨ + 1ä¸ªæ‰¹åˆ¤è€…ï¼‰
            num_generators: Number of parallel generator agents
                           å¹¶è¡Œç”Ÿæˆå™¨æ•°é‡
            generator_temperature: Temperature for generator agents (for diversity)
                                  ç”Ÿæˆå™¨æ¸©åº¦ï¼ˆç”¨äºå¤šæ ·æ€§ï¼‰
            critic_temperature: Temperature for critic agent (for stability)
                               æ‰¹åˆ¤è€…æ¸©åº¦ï¼ˆç”¨äºç¨³å®šæ€§ï¼‰
            use_vector_retriever: Use vector-based semantic retrieval
                                 ä½¿ç”¨åŸºäºå‘é‡çš„è¯­ä¹‰æ£€ç´¢
            enable_step2_enhancement: Enable Step2 DAG enhancement
                                     å¯ç”¨ç¬¬2æ­¥DAGå¢å¼º
            use_expert_review: Use domain expert review
                              ä½¿ç”¨é¢†åŸŸä¸“å®¶å®¡æŸ¥
            use_rag_enhancement: Use RAG knowledge enhancement
                                ä½¿ç”¨RAGçŸ¥è¯†å¢å¼º
            use_structure_optimization: Use causal structure optimization
                                       ä½¿ç”¨å› æœç»“æ„ä¼˜åŒ–
        """
        self.verbose = verbose
        self.use_ai_retriever = use_ai_retriever
        self.auto_enrich_kb = auto_enrich_kb
        self.min_rules_threshold = min_rules_threshold
        self.knowledge_base_path = knowledge_base_path
        self.use_multi_agent = use_multi_agent
        self.use_grpo_experience = use_grpo_experience  # æ–°å¢ï¼šå­˜å‚¨æ˜¯å¦ä½¿ç”¨GRPOç»éªŒ
        self.use_vector_retriever = use_vector_retriever
        
        # Step2 Enhancement options / Step2å¢å¼ºé€‰é¡¹
        self.enable_step2_enhancement = enable_step2_enhancement
        self.use_expert_review = use_expert_review
        self.use_rag_enhancement = use_rag_enhancement
        self.use_structure_optimization = use_structure_optimization

        # Initialize components / åˆå§‹åŒ–ç»„ä»¶
        self._print("Initializing Causal Reasoning Engine...")
        self._print("åˆå§‹åŒ–å› æœæ¨ç†å¼•æ“...")

        try:
            # Knowledge retriever selectionï¼ˆRAGæ£€ç´¢å™¨é€‰æ‹©ï¼‰
            if self.use_vector_retriever:
                # True RAG: semantic similarity  è¿™ä¸ªå°±æ˜¯ä»æˆ‘æœ¬åœ°åŠ è½½è¿™ä¸ªç¼–ç å™¨ è½¬åŒ–æˆ384ç»´åº¦
                self.retriever = VectorKnowledgeRetriever(
                    knowledge_base_path=knowledge_base_path,
                    model_name="all-MiniLM-L6-v2",
                    cache_path="data/knowledge_embeddings.pkl",
                    use_cache=True,
                )
                self._print(" ğŸ” Using VectorKnowledgeRetriever (semantic RAG)")
                self._print(" ğŸ” ä½¿ç”¨å‘é‡æ£€ç´¢ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦RAGï¼‰")
            else:
                # Keyword-based retriever
                self.retriever = KnowledgeRetriever(knowledge_base_path)

            # AI-enhanced retriever / AI 
            if use_ai_retriever:
                self.ai_retriever = AIKnowledgeRetriever(
                    knowledge_base_path=knowledge_base_path,
                    auto_enrich_kb=auto_enrich_kb,
                    max_rules=5, #TODO è¿™ä¸ªåœ°æ–¹è·Ÿå‰é¢é‚£ä¸ªå­—æ®µè¦åŒºåˆ†ä¸€ä¸‹
                    enable_cache=True
                )
                self._print(" AI Knowledge Retriever enabled")
                self._print(" AI ")
            else:
                self.ai_retriever = None

            # Other components /
            # æ–°å¢ï¼šæ ¹æ®é€‰é¡¹åˆå§‹åŒ–å•æ™ºèƒ½ä½“æˆ–å¤šæ™ºèƒ½ä½“è„šæ‰‹æ¶å™¨
            if use_multi_agent:# è¿™ä¸ªåœ°æ–¹å°±æ˜¯åŠ è½½å› æœå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ å…¶å®å°±æ˜¯åŠ è½½å¯¹åº”çš„prompt
                # å¦‚æœå¯ç”¨GRPOç»éªŒï¼ŒåŠ è½½ç»éªŒç®¡ç†å™¨
                experience_manager = None
                if use_grpo_experience:
                    try:
                        from engine import GRPOExperienceManager
                        experience_manager = GRPOExperienceManager(
                            experience_dir="data/grpo_experiences",
                            verbose=False
                        )
                        self._print(" âœ“ GRPO Experience loaded")
                        self._print(" âœ“ GRPOç»éªŒå·²åŠ è½½")
                    except Exception as e:
                        self._print(f" âš ï¸  Failed to load GRPO experiences: {e}")
                        self._print(f" âš ï¸  GRPOç»éªŒåŠ è½½å¤±è´¥ï¼š{e}")
                
                self.scaffolder = MultiAgentScaffolder(
                    num_generators=num_generators,
                    generator_temperature=generator_temperature,
                    critic_temperature=critic_temperature,
                    experience_manager=experience_manager,  # ä¼ é€’ç»éªŒç®¡ç†å™¨ï¼ˆå¯èƒ½ä¸ºNoneï¼‰
                    use_separate_apis=True  # Use separate API for each generator and critic
                )
                self._print(f" ğŸ¤– Using Multi-Agent Scaffolder ({num_generators} generators + 1 critic)")
                self._print(f" ğŸ¤– ä½¿ç”¨å¤šæ™ºèƒ½ä½“è„šæ‰‹æ¶å™¨ï¼ˆ{num_generators}ä¸ªç”Ÿæˆå™¨ + 1ä¸ªæ‰¹åˆ¤è€…ï¼‰")
            else:
                self.scaffolder = CausalScaffolder()  # ç”Ÿæˆå› æœå›¾
                self._print(" ğŸ¤– Using Single-Agent Scaffolder")
                self._print(" ğŸ¤– ä½¿ç”¨å•æ™ºèƒ½ä½“è„šæ‰‹æ¶å™¨")

            # Initialize LLM Computer / åˆå§‹åŒ–LLMè®¡ç®—å™¨
            self.llm_computer = LLMComputer(verbose=verbose)
            self._print(" âš™ï¸ LLM Computer initialized")
            self._print(" âš™ï¸ LLMè®¡ç®—å™¨å·²åˆå§‹åŒ–")
            
            # Initialize Step2 Enhancement Pipeline / åˆå§‹åŒ–Step2å¢å¼ºæµæ°´çº¿
            self._initialize_step2_enhancement()

            self._print("âœ… All components initialized successfully.")
            self._print("âœ… æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ\n")
        except Exception as e:
            self._print(f"âŒ Error during initialization: {e}")
            raise

    def _print(self, message: str) -> None:
        """Print message if verbose mode enabled / å¦‚æœå¯ç”¨è¯¦ç»†æ¨¡å¼åˆ™æ‰“å°æ¶ˆæ¯"""
        if self.verbose:
            print(message)
    
    def _initialize_step2_enhancement(self) -> None:
        """
        Initialize Step2 DAG Enhancement Pipeline.
        åˆå§‹åŒ–Step2 DAGå¢å¼ºæµæ°´çº¿
        
        This method sets up:
        1. Domain Expert Reviewer (Math & Physics experts)
        2. RAG Knowledge Enhancer  
        3. Causal Structure Optimizer
        4. DAG Enhancement Pipeline (orchestrator)
        """
        if not self.enable_step2_enhancement:
            self._print(" â­ï¸  Step2 Enhancement disabled")
            self._print(" â­ï¸  Step2å¢å¼ºå·²ç¦ç”¨")
            self.enhancement_pipeline = None
            return
        
        self._print("\n ğŸ”§ Initializing Step2 Enhancement Pipeline...")
        self._print(" ğŸ”§ åˆå§‹åŒ–Step2å¢å¼ºæµæ°´çº¿...")
        
        try:
            # Load API configuration for experts
            from engine.api_manager import APIKeyManager
            api_manager = APIKeyManager()
            
            # Initialize unified expert LLM client (handles both math and physics)
            expert_client = None
            causal_expert_client = None
            
            if self.use_expert_review:
                try:
                    # Try to get expert API key (use math_expert as unified expert)
                    expert_key = api_manager.get_api_key('math_expert')
                    
                    # Create LLM client for unified expert
                    from engine.scaffolder import LLMClient
                    if expert_key:
                        expert_client = LLMClient()  # Unified expert (Math+Physics)
                    
                    self._print("   âœ“ Unified expert client initialized (Math+Physics)")
                except Exception as e:
                    self._print(f"   âš ï¸  Expert client initialization skipped: {e}")
            
            # Initialize causal expert client
            if self.use_structure_optimization:
                try:
                    causal_key = api_manager.get_api_key('causal_knowledge')
                    if causal_key:
                        from engine.scaffolder import LLMClient
                        causal_expert_client = LLMClient()
                        # Set API key
                        if hasattr(causal_expert_client, 'client'):
                            causal_expert_client.client.api_key = causal_key
                        self._print("   âœ“ Causal expert client initialized")
                    else:
                        self._print("   âš ï¸  No 'causal_knowledge' API key found, structure optimization will be skipped")
                        self._print("   âš ï¸  Tip: Add CAUSAL_KNOWLEDGE_API=your_key to .env file")
                except Exception as e:
                    self._print(f"   âš ï¸  Causal expert client initialization failed: {e}")
            
            # Initialize Stage 1: Domain Expert Reviewer (Unified Math+Physics Expert)
            expert_reviewer = None
            if self.use_expert_review:
                expert_reviewer = DomainExpertReviewer(
                    math_expert_client=expert_client,
                    physics_expert_client=expert_client,  # Same client for both
                    verbose=self.verbose
                )
                self._print("   âœ“ Domain Expert Reviewer ready (Unified Math+Physics)")
            
            # Initialize Stage 2: RAG Knowledge Enhancer
            rag_enhancer = None
            if self.use_rag_enhancement:
                rag_enhancer = RAGKnowledgeEnhancer(
                    ai_retriever=self.ai_retriever if hasattr(self, 'ai_retriever') else None,
                    vector_retriever=self.retriever if self.use_vector_retriever else None,
                    verbose=self.verbose
                )
                self._print("   âœ“ RAG Knowledge Enhancer ready")
            
            # Initialize Stage 3: Causal Structure Optimizer
            structure_optimizer = None
            if self.use_structure_optimization:
                structure_optimizer = CausalStructureOptimizer(
                    causal_expert_client=causal_expert_client,
                    verbose=self.verbose
                )
                self._print("   âœ“ Causal Structure Optimizer ready")
            
            # Initialize Pipeline Orchestrator
            self.enhancement_pipeline = DAGEnhancementPipeline(
                expert_reviewer=expert_reviewer,
                rag_enhancer=rag_enhancer,
                structure_optimizer=structure_optimizer,
                verbose=self.verbose
            )
            
            self._print(" âœ… Step2 Enhancement Pipeline initialized successfully")
            self._print(" âœ… Step2å¢å¼ºæµæ°´çº¿åˆå§‹åŒ–æˆåŠŸ\n")
            
        except Exception as e:
            self._print(f" âš ï¸  Step2 Enhancement initialization failed: {e}")
            self._print(f" âš ï¸  Step2å¢å¼ºåˆå§‹åŒ–å¤±è´¥: {e}")
            self.enhancement_pipeline = None

    def solve_problem(
        self,
        problem_text: str,
        include_validation: bool = True,
        save_output: Optional[str] = None,
        problem_id: Optional[str] = None,
        method_name: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Solve a problem using the causal reasoning pipeline.
        ä½¿ç”¨å› æœæ¨ç†æµæ°´çº¿è§£å†³é—®é¢˜

        Execution Flow:
        æ‰§è¡Œæµç¨‹ï¼š
        
        Step1: Multi-Agent Causal Scaffolding
            - 3 generators create diverse causal DAGs in parallel
            - Critic fuses proposals into Fixed DAG
            - 3ä¸ªç”Ÿæˆå™¨å¹¶è¡Œåˆ›å»ºå¤šæ ·åŒ–çš„å› æœDAG
            - æ‰¹åˆ¤è€…å°†ææ¡ˆèåˆä¸ºFixed DAG
        
        Step2: DAG Enhancement
            - Domain expert reviews reasoning chains
            - RAG retrieves and fills knowledge gaps
            - Causal structure optimizer applies patterns
            - Result: Enhanced DAG
            - é¢†åŸŸä¸“å®¶å®¡æŸ¥æ¨ç†é“¾
            - RAGæ£€ç´¢å¹¶å¡«è¡¥çŸ¥è¯†ç¼ºå£
            - å› æœç»“æ„ä¼˜åŒ–å™¨åº”ç”¨æ¨¡å¼
            - ç»“æœï¼šEnhanced DAG
        
        Step3: LLM-Based Computation
            - LLM computes final answer from Enhanced DAG
            - LLMä»Enhanced DAGè®¡ç®—æœ€ç»ˆç­”æ¡ˆ

        Args:
            problem_text: Problem statement in natural language
                         è‡ªç„¶è¯­è¨€é—®é¢˜é™ˆè¿°
            include_validation: Include validation (reserved)
                               åŒ…å«éªŒè¯ï¼ˆä¿ç•™ï¼‰
            save_output: Path to save output JSON
                        ä¿å­˜è¾“å‡ºJSONçš„è·¯å¾„
            problem_id: Problem identifier
                       é—®é¢˜æ ‡è¯†ç¬¦
            method_name: Method name
                        æ–¹æ³•åç§°

        Returns:
            Dictionary with results and outputs
            ç»“æœå’Œè¾“å‡ºçš„å­—å…¸
        """
        self._print("STARTING CAUSAL REASONING PIPELINE")
        results = {
            "problem": problem_text,
            "success": False,
            "error": None
        }

        try:
            # Step1: Multi-Agent Causal Scaffolding / ç¬¬1æ­¥ï¼šå¤šæ™ºèƒ½ä½“å› æœè„šæ‰‹æ¶
            self._print("\n--- STEP 1: MULTI-AGENT CAUSAL SCAFFOLDING ---")
            self._print("--- ç¬¬1æ­¥ï¼šå¤šæ™ºèƒ½ä½“å› æœè„šæ‰‹æ¶ ---")

            if self.use_multi_agent:
                # Multi-agent: each generator loads its own experiences internally
                # å¤šæ™ºèƒ½ä½“ï¼šæ¯ä¸ªgeneratorå†…éƒ¨åŠ è½½è‡ªå·±çš„ç»éªŒ
                causal_plan = self.scaffolder.generate_scaffold_parallel(
                    problem_text=problem_text,
                    retrieved_knowledge=[]  # RAG knowledge (currently disabled)
                )
            else:
                # Single agent mode: no retrieved knowledge or experiences (for now)
                # å•æ™ºèƒ½ä½“æ¨¡å¼ï¼šæš‚æ— æ£€ç´¢çŸ¥è¯†æˆ–ç»éªŒ
                causal_plan = self.scaffolder.generate_scaffold(
                    problem_text=problem_text,
                    retrieved_knowledge=[],
                    experiences=[]
                )
            
            
            if not causal_plan:
                results["error"] = "Failed to generate causal scaffold"
                return results

            if not self.scaffolder.validate_scaffold(causal_plan):
                results["error"] = "Invalid scaffold structure"
                return results

            results["causal_scaffold"] = causal_plan
            
            # Step2: DAG Enhancement / ç¬¬2æ­¥ï¼šDAGå¢å¼º
            if self.enable_step2_enhancement and hasattr(self, 'enhancement_pipeline') and self.enhancement_pipeline:
                self._print("\n--- STEP 2: DAG ENHANCEMENT ---")
                self._print("--- ç¬¬2æ­¥ï¼šDAGå¢å¼º ---")
                
                try:
                    enhanced_dag, enhancement_report = self.enhancement_pipeline.enhance_dag(
                        fixed_dag=causal_plan,
                        problem_text=problem_text
                    )
                    
                    # Use enhanced DAG for subsequent stages
                    causal_plan = enhanced_dag
                    results["enhanced_dag"] = enhanced_dag
                    results["enhancement_report"] = enhancement_report
                    
                    self._print(f"   âœ… DAG Enhancement completed (Quality: {enhancement_report.get('summary', {}).get('quality_score', 0):.2f})")
                    
                except Exception as e:
                    self._print(f"   âš ï¸  DAG Enhancement failed: {e}")
                    self._print("   Continuing with original DAG...")
                    results["enhancement_error"] = str(e)
            else:
                self._print("\n--- STEP 2: DAG ENHANCEMENT (Skipped) ---")
                self._print("--- ç¬¬2æ­¥ï¼šDAGå¢å¼ºï¼ˆå·²è·³è¿‡ï¼‰---")

            # Step3: LLM-Based Computation / ç¬¬3æ­¥ï¼šåŸºäºLLMçš„è®¡ç®—
            self._print("\n--- STEP 3: LLM-BASED COMPUTATION ---")
            self._print("--- ç¬¬3æ­¥ï¼šåŸºäºLLMçš„è®¡ç®— ---")

            computation_result = self.llm_computer.compute_from_scaffold(
                causal_scaffold=causal_plan,
                problem_text=problem_text
            )

            if not computation_result['success']:
                results["error"] = f"Failed during LLM computation: {computation_result.get('error', 'Unknown error')}"
                results["computation_result"] = computation_result
                return results

            # Store computation results / å­˜å‚¨è®¡ç®—ç»“æœ
            results["final_answer"] = computation_result['result']
            results["computation_result"] = computation_result
            results["reasoning"] = computation_result.get('reasoning', '')

            # Finalization / æœ€ç»ˆåŒ–
            results["success"] = True

            if save_output:
                self._save_results(results, save_output)

        except Exception as e:
            self._print("\n" + "="*70)
            self._print("âŒ ERROR DURING PIPELINE EXECUTION")
            self._print("âŒ æµæ°´çº¿æ‰§è¡Œé”™è¯¯")
            self._print("="*70)
            self._print(f"\nError: {e}")

            import traceback
            tb = traceback.format_exc()
            results["error"] = str(e)
            results["traceback"] = tb
            self._print(tb)
            self._print("="*70)

        return results

    def _save_results(self, results: Dict[str, Any], output_path: str) -> None:
        """
        Save results to JSON file.
        ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
        """
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        self._print(f"\nResults saved to: {output_file}")

    def display_results(self, results: Dict[str, Any]) -> None:
        """
        Display results in formatted output.
        æ ¼å¼åŒ–æ˜¾ç¤ºç»“æœ
        """
        print("\n" + "=" * 70)
        print("FINAL RESULTS / æœ€ç»ˆç»“æœ")
        print("=" * 70)

        if not results.get("success"):
            print(f"\nâŒ Error: {results.get('error')}")
            if results.get("traceback"):
                print(results.get("traceback"))
            return

        print(f"\nProblem / é—®é¢˜:")
        print(f"   {results['problem']}")

        print(f"\nFinal Answer / æœ€ç»ˆç­”æ¡ˆ:")
        print(f"   {results.get('final_answer')}")

        print("\n" + "=" * 70)


def main():
    """
    Command-line entry point.
    å‘½ä»¤è¡Œå…¥å£ç‚¹
    """
    parser = argparse.ArgumentParser(
        description="Causal Reasoning Engine / å› æœæ¨ç†å¼•æ“"
    )

    parser.add_argument("-p", "--problem", type=str, help="Problem text")
    parser.add_argument("-f", "--file", type=str, help="Problem file path")
    parser.add_argument("-o", "--output", type=str, help="Output JSON path")
    parser.add_argument("-q", "--quiet", action="store_true", help="Quiet mode")
    parser.add_argument("--kb", type=str, default="data/knowledge_base.json", help="Knowledge base path")
    parser.add_argument("--multi-agent", action="store_true", help="Use multi-agent scaffolder")
    parser.add_argument("--num-generators", type=int, default=3, help="Number of generators")
    parser.add_argument("--generator-temp", type=float, default=0.3, help="Generator temperature")
    parser.add_argument("--critic-temp", type=float, default=0.0, help="Critic temperature")

    args = parser.parse_args()

    if args.problem:
        problem_text = args.problem
    elif args.file:
        with open(args.file, 'r', encoding='utf-8') as f:
            problem_text = f.read()
    else:
        print("Enter problem (Ctrl+D or Ctrl+Z to finish):")
        problem_text = sys.stdin.read()

    engine = CausalReasoningEngine(
        knowledge_base_path=args.kb,
        verbose=not args.quiet,
        use_multi_agent=args.multi_agent,
        num_generators=args.num_generators,
        generator_temperature=args.generator_temp,
        critic_temperature=args.critic_temp
    )

    results = engine.solve_problem(problem_text, save_output=args.output)
    engine.display_results(results)
    sys.exit(0 if results.get("success") else 1)


if __name__ == "__main__":
    if len(sys.argv) == 1:
        print("Running demo...\n")
        demo_problem = """
         "å°†ç”µåŠ¨åŠ¿ä¸º3.0 Vçš„ç”µæºæ¥å…¥ç”µè·¯ä¸­,æµ‹å¾—ç”µæºä¸¤æé—´çš„ç”µå‹ä¸º2.4 V,å½“ç”µè·¯ä¸­æœ‰6 Cçš„ç”µè·æµè¿‡æ—¶,æ±‚ï¼š\nå¤–ç”µè·¯ä¸­æœ‰å¤šå°‘ç”µèƒ½è½¬åŒ–ä¸ºå…¶ä»–å½¢å¼çš„èƒ½ï¼›
        """
        engine = CausalReasoningEngine()
        results = engine.solve_problem(demo_problem)
        engine.display_results(results)
    else:
        main()
